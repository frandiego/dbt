2021-01-19 10:48:27.230273 (MainThread): Running with dbt=0.18.1
2021-01-19 10:48:27.303204 (MainThread): Loading KWallet
2021-01-19 10:48:27.303753 (MainThread): Loading SecretService
2021-01-19 10:48:27.304191 (MainThread): Loading Windows
2021-01-19 10:48:27.304756 (MainThread): Loading chainer
2021-01-19 10:48:27.305040 (MainThread): Loading macOS
2021-01-19 10:48:27.568924 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 10:48:27.570371 (MainThread): Tracking: tracking
2021-01-19 10:48:27.570634 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d67ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f76040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f76d90>]}
2021-01-19 10:48:27.598057 (MainThread): Parsing macros/catalog.sql
2021-01-19 10:48:27.600682 (MainThread): Parsing macros/adapters.sql
2021-01-19 10:48:27.631722 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 10:48:27.636496 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 10:48:27.639449 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 10:48:27.644776 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 10:48:27.658462 (MainThread): Parsing macros/core.sql
2021-01-19 10:48:27.663514 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 10:48:27.672901 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 10:48:27.675177 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 10:48:27.692437 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 10:48:27.723582 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 10:48:27.743508 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 10:48:27.745409 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 10:48:27.751459 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 10:48:27.765184 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 10:48:27.772193 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 10:48:27.778538 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 10:48:27.783300 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 10:48:27.784392 (MainThread): Parsing macros/etc/query.sql
2021-01-19 10:48:27.785599 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 10:48:27.787348 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 10:48:27.796248 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 10:48:27.798854 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 10:48:27.800804 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 10:48:27.842310 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 10:48:27.844405 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 10:48:27.846162 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 10:48:27.848261 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 10:48:27.891078 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:48:27.911727 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 10:48:28.118696 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 10:48:28.120684 (MainThread): 
2021-01-19 10:48:28.121385 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:48:28.124637 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 10:48:28.139077 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 10:48:28.139216 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 10:48:28.139313 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 10:48:29.343965 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.20 seconds
2021-01-19 10:48:29.348806 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 10:48:29.625123 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 10:48:29.625462 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 10:48:29.625666 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 10:48:29.631589 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:48:29.631703 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 10:48:29.631820 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 10:48:30.837507 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.21 seconds
2021-01-19 10:48:30.837826 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:48:30.837975 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 10:48:31.172243 (ThreadPoolExecutor-0_0): Snowflake query id: 0199b648-06f9-6fd3-0000-0039890320ad
2021-01-19 10:48:31.172473 (ThreadPoolExecutor-0_0): Snowflake error: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
2021-01-19 10:48:31.172687 (ThreadPoolExecutor-0_0): Error running SQL: macro create_schema
2021-01-19 10:48:31.172825 (ThreadPoolExecutor-0_0): Rolling back transaction.
2021-01-19 10:48:31.172975 (ThreadPoolExecutor-0_0): On create_analytics_dbt: ROLLBACK
2021-01-19 10:48:31.328855 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 10:48:31.789793 (MainThread): Connection 'master' was properly closed.
2021-01-19 10:48:31.789971 (MainThread): Connection 'create_analytics_dbt' was properly closed.
2021-01-19 10:48:31.790182 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bcea30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d11b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cc3f10>]}
2021-01-19 10:48:31.790429 (MainThread): Flushing usage events
2021-01-19 10:48:32.419198 (MainThread): Encountered an error:
2021-01-19 10:48:32.419436 (MainThread): Database Error
  003041 (42710): SQL compilation error:
  Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
2021-01-19 10:48:32.431631 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/impl.py", line 182, in create_schema
    self.execute_macro(CREATE_SCHEMA_MACRO_NAME, kwargs=kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 984, in execute_macro
    result = macro_function(**kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 28, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  003041 (42710): SQL compilation error:
  Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.

2021-01-19 10:51:51.740207 (MainThread): Running with dbt=0.18.1
2021-01-19 10:51:51.820272 (MainThread): Loading KWallet
2021-01-19 10:51:51.820791 (MainThread): Loading SecretService
2021-01-19 10:51:51.821250 (MainThread): Loading Windows
2021-01-19 10:51:51.821870 (MainThread): Loading chainer
2021-01-19 10:51:51.822175 (MainThread): Loading macOS
2021-01-19 10:51:52.121350 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 10:51:52.122362 (MainThread): Tracking: tracking
2021-01-19 10:51:52.122616 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f76ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107185040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107185d90>]}
2021-01-19 10:51:52.161375 (MainThread): Got an acceptable cached parse result
2021-01-19 10:51:52.314763 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 10:51:52.316309 (MainThread): 
2021-01-19 10:51:52.316859 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:51:52.320018 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 10:51:52.335789 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 10:51:52.335937 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 10:51:52.336035 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 10:51:53.579972 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.24 seconds
2021-01-19 10:51:53.584420 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 10:51:53.849874 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 10:51:53.858053 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 10:51:53.858186 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 10:51:53.858291 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 10:51:54.675721 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.82 seconds
2021-01-19 10:51:54.676377 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 10:51:54.968616 (MainThread): Using snowflake connection "master".
2021-01-19 10:51:54.968796 (MainThread): On master: BEGIN
2021-01-19 10:51:54.968914 (MainThread): Opening a new connection, currently in state init
2021-01-19 10:51:56.113346 (MainThread): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 10:51:56.113549 (MainThread): On master: COMMIT
2021-01-19 10:51:56.113726 (MainThread): Using snowflake connection "master".
2021-01-19 10:51:56.113826 (MainThread): On master: COMMIT
2021-01-19 10:51:56.346295 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 10:51:56.346508 (MainThread): On master: Close
2021-01-19 10:51:56.620085 (MainThread): 11:51:56 | Concurrency: 1 threads (target='dev')
2021-01-19 10:51:56.620297 (MainThread): 11:51:56 | 
2021-01-19 10:51:56.623088 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:51:56.624415 (Thread-1): 11:51:56 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 10:51:56.624742 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:51:56.624884 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 10:51:56.655988 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:51:56.656753 (Thread-1): finished collecting timing info
2021-01-19 10:51:56.692798 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:51:56.694212 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:51:56.694321 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 10:51:56.694417 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 10:51:57.830605 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 10:51:57.830861 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:51:57.831005 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 10:51:58.005997 (Thread-1): Snowflake query id: 0199b64b-06de-3f59-0000-003989032115
2021-01-19 10:51:58.006227 (Thread-1): Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on schema 'DBT'
2021-01-19 10:51:58.006465 (Thread-1): finished collecting timing info
2021-01-19 10:51:58.006912 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 10:51:58.213375 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 10:51:58.464916 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on schema 'DBT'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 003001 (42501): SQL access control error:
Insufficient privileges to operate on schema 'DBT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on schema 'DBT'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:51:58.470029 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18029e9b-f5d0-4838-8e52-b2fcad492897', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e126430>]}
2021-01-19 10:51:58.471364 (Thread-1): 11:51:58 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 1.85s]
2021-01-19 10:51:58.471523 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:51:58.472282 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:51:58.472572 (Thread-1): 11:51:58 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 10:51:58.472878 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:51:58.473881 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:51:58.474114 (MainThread): Using snowflake connection "master".
2021-01-19 10:51:58.474217 (MainThread): On master: BEGIN
2021-01-19 10:51:58.474315 (MainThread): Opening a new connection, currently in state closed
2021-01-19 10:51:59.543724 (MainThread): SQL status: SUCCESS 1 in 1.07 seconds
2021-01-19 10:51:59.543926 (MainThread): On master: COMMIT
2021-01-19 10:51:59.544098 (MainThread): Using snowflake connection "master".
2021-01-19 10:51:59.544197 (MainThread): On master: COMMIT
2021-01-19 10:51:59.755435 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 10:51:59.755641 (MainThread): On master: Close
2021-01-19 10:52:00.016668 (MainThread): 11:52:00 | 
2021-01-19 10:52:00.016868 (MainThread): 11:52:00 | Finished running 1 table model, 1 view model in 7.70s.
2021-01-19 10:52:00.017067 (MainThread): Connection 'master' was properly closed.
2021-01-19 10:52:00.017230 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 10:52:00.025234 (MainThread): 
2021-01-19 10:52:00.025428 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 10:52:00.025565 (MainThread): 
2021-01-19 10:52:00.025686 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 10:52:00.025817 (MainThread):   003001 (42501): SQL access control error:
2021-01-19 10:52:00.025975 (MainThread):   Insufficient privileges to operate on schema 'DBT'
2021-01-19 10:52:00.026085 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:52:00.026237 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 10:52:00.026468 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1557c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e155040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e155790>]}
2021-01-19 10:52:00.026697 (MainThread): Flushing usage events
2021-01-19 10:52:37.901639 (MainThread): Running with dbt=0.18.1
2021-01-19 10:52:37.978574 (MainThread): Loading KWallet
2021-01-19 10:52:37.979205 (MainThread): Loading SecretService
2021-01-19 10:52:37.979682 (MainThread): Loading Windows
2021-01-19 10:52:37.980376 (MainThread): Loading chainer
2021-01-19 10:52:37.980725 (MainThread): Loading macOS
2021-01-19 10:52:38.269192 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 10:52:38.270251 (MainThread): Tracking: tracking
2021-01-19 10:52:38.270537 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111282850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111491040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111491d90>]}
2021-01-19 10:52:38.308888 (MainThread): Got an acceptable cached parse result
2021-01-19 10:52:38.457366 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 10:52:38.459468 (MainThread): 
2021-01-19 10:52:38.460463 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:52:38.463847 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 10:52:38.477120 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 10:52:38.477261 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 10:52:38.477336 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 10:52:39.652844 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.18 seconds
2021-01-19 10:52:39.656949 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 10:52:39.930059 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 10:52:39.930342 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 10:52:39.930510 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 10:52:39.936388 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:52:39.936535 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 10:52:39.936636 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 10:52:41.141646 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.20 seconds
2021-01-19 10:52:41.141832 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:52:41.141928 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 10:52:41.419818 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 10:52:41.421127 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 10:52:41.421311 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:52:41.421413 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 10:52:41.576026 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 10:52:41.576230 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 10:52:41.880622 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 10:52:41.888694 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 10:52:41.888838 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 10:52:41.888962 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 10:52:42.710556 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.82 seconds
2021-01-19 10:52:42.711212 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 10:52:42.967200 (MainThread): Using snowflake connection "master".
2021-01-19 10:52:42.967358 (MainThread): On master: BEGIN
2021-01-19 10:52:42.967482 (MainThread): Opening a new connection, currently in state init
2021-01-19 10:52:44.080552 (MainThread): SQL status: SUCCESS 1 in 1.11 seconds
2021-01-19 10:52:44.080827 (MainThread): On master: COMMIT
2021-01-19 10:52:44.081026 (MainThread): Using snowflake connection "master".
2021-01-19 10:52:44.081147 (MainThread): On master: COMMIT
2021-01-19 10:52:44.409915 (MainThread): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 10:52:44.410118 (MainThread): On master: Close
2021-01-19 10:52:44.697092 (MainThread): 11:52:44 | Concurrency: 1 threads (target='dev')
2021-01-19 10:52:44.697305 (MainThread): 11:52:44 | 
2021-01-19 10:52:44.699284 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:52:44.700673 (Thread-1): 11:52:44 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 10:52:44.701027 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:52:44.701167 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 10:52:44.732073 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:52:44.732600 (Thread-1): finished collecting timing info
2021-01-19 10:52:44.770236 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:52:44.771433 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:52:44.771550 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 10:52:44.771655 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 10:52:45.800601 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-01-19 10:52:45.800846 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:52:45.800998 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 10:52:46.149987 (Thread-1): Snowflake query id: 0199b64c-06bd-e968-0000-00398903510d
2021-01-19 10:52:46.150203 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 10:52:46.150431 (Thread-1): finished collecting timing info
2021-01-19 10:52:46.150851 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 10:52:46.393890 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 10:52:46.675686 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:52:46.678664 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b456d151-9238-4a85-bf47-f75ffc89fbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f7b940>]}
2021-01-19 10:52:46.680102 (Thread-1): 11:52:46 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 1.98s]
2021-01-19 10:52:46.680269 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:52:46.681170 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:52:46.681455 (Thread-1): 11:52:46 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 10:52:46.681734 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:52:46.682734 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:52:46.682951 (MainThread): Using snowflake connection "master".
2021-01-19 10:52:46.683054 (MainThread): On master: BEGIN
2021-01-19 10:52:46.683154 (MainThread): Opening a new connection, currently in state closed
2021-01-19 10:52:47.514893 (MainThread): SQL status: SUCCESS 1 in 0.83 seconds
2021-01-19 10:52:47.515146 (MainThread): On master: COMMIT
2021-01-19 10:52:47.515339 (MainThread): Using snowflake connection "master".
2021-01-19 10:52:47.515450 (MainThread): On master: COMMIT
2021-01-19 10:52:47.765427 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 10:52:47.765665 (MainThread): On master: Close
2021-01-19 10:52:48.085425 (MainThread): 11:52:48 | 
2021-01-19 10:52:48.085621 (MainThread): 11:52:48 | Finished running 1 table model, 1 view model in 9.63s.
2021-01-19 10:52:48.085746 (MainThread): Connection 'master' was properly closed.
2021-01-19 10:52:48.085882 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 10:52:48.093990 (MainThread): 
2021-01-19 10:52:48.094171 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 10:52:48.094298 (MainThread): 
2021-01-19 10:52:48.094416 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 10:52:48.094591 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 10:52:48.094705 (MainThread):   
2021-01-19 10:52:48.094802 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:52:48.094907 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 10:52:48.095085 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11240c4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112437610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124377c0>]}
2021-01-19 10:52:48.095289 (MainThread): Flushing usage events
2021-01-19 10:53:37.706932 (MainThread): Running with dbt=0.18.1
2021-01-19 10:53:37.773434 (MainThread): Loading KWallet
2021-01-19 10:53:37.773879 (MainThread): Loading SecretService
2021-01-19 10:53:37.774358 (MainThread): Loading Windows
2021-01-19 10:53:37.774958 (MainThread): Loading chainer
2021-01-19 10:53:37.775461 (MainThread): Loading macOS
2021-01-19 10:53:38.033327 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 10:53:38.034210 (MainThread): Tracking: tracking
2021-01-19 10:53:38.034447 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0625e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e26f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e26f040>]}
2021-01-19 10:53:38.067149 (MainThread): Got an acceptable cached parse result
2021-01-19 10:53:38.205758 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 10:53:38.207056 (MainThread): 
2021-01-19 10:53:38.207933 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:53:38.210449 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 10:53:38.225937 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 10:53:38.226054 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 10:53:38.226130 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 10:53:39.454328 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.23 seconds
2021-01-19 10:53:39.459023 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 10:53:39.732062 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 10:53:39.732412 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 10:53:39.732617 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 10:53:39.738772 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:53:39.738884 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 10:53:39.738988 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 10:53:40.792836 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.05 seconds
2021-01-19 10:53:40.793079 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:53:40.793224 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 10:53:41.139074 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.35 seconds
2021-01-19 10:53:41.140180 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 10:53:41.140362 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 10:53:41.140464 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 10:53:41.308562 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 10:53:41.308850 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 10:53:41.577971 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 10:53:41.585986 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 10:53:41.586122 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 10:53:41.586230 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 10:53:42.417264 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.83 seconds
2021-01-19 10:53:42.417933 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 10:53:42.680293 (MainThread): Using snowflake connection "master".
2021-01-19 10:53:42.680480 (MainThread): On master: BEGIN
2021-01-19 10:53:42.680610 (MainThread): Opening a new connection, currently in state init
2021-01-19 10:53:43.893432 (MainThread): SQL status: SUCCESS 1 in 1.21 seconds
2021-01-19 10:53:43.893705 (MainThread): On master: COMMIT
2021-01-19 10:53:43.893951 (MainThread): Using snowflake connection "master".
2021-01-19 10:53:43.894094 (MainThread): On master: COMMIT
2021-01-19 10:53:44.211524 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 10:53:44.211804 (MainThread): On master: Close
2021-01-19 10:53:44.464237 (MainThread): 11:53:44 | Concurrency: 1 threads (target='dev')
2021-01-19 10:53:44.464470 (MainThread): 11:53:44 | 
2021-01-19 10:53:44.466509 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:53:44.467824 (Thread-1): 11:53:44 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 10:53:44.468170 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:53:44.468312 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 10:53:44.499159 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:53:44.499659 (Thread-1): finished collecting timing info
2021-01-19 10:53:44.534113 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:53:44.535134 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:53:44.535234 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 10:53:44.535324 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 10:53:45.425325 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2021-01-19 10:53:45.425577 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:53:45.425725 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 10:53:45.665381 (Thread-1): Snowflake query id: 0199b64d-06ac-0824-0000-00398903212d
2021-01-19 10:53:45.665606 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 10:53:45.665835 (Thread-1): finished collecting timing info
2021-01-19 10:53:45.666291 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 10:53:45.888380 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 10:53:46.148086 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:53:46.151428 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c46cd26-f43f-467c-b43d-162bc55d2729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f182f40>]}
2021-01-19 10:53:46.152767 (Thread-1): 11:53:46 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 1.68s]
2021-01-19 10:53:46.152928 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:53:46.153691 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:53:46.153967 (Thread-1): 11:53:46 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 10:53:46.154246 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:53:46.155352 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:53:46.155570 (MainThread): Using snowflake connection "master".
2021-01-19 10:53:46.155674 (MainThread): On master: BEGIN
2021-01-19 10:53:46.155775 (MainThread): Opening a new connection, currently in state closed
2021-01-19 10:53:46.983750 (MainThread): SQL status: SUCCESS 1 in 0.83 seconds
2021-01-19 10:53:46.984035 (MainThread): On master: COMMIT
2021-01-19 10:53:46.984278 (MainThread): Using snowflake connection "master".
2021-01-19 10:53:46.984421 (MainThread): On master: COMMIT
2021-01-19 10:53:47.197439 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 10:53:47.197664 (MainThread): On master: Close
2021-01-19 10:53:47.474650 (MainThread): 11:53:47 | 
2021-01-19 10:53:47.474873 (MainThread): 11:53:47 | Finished running 1 table model, 1 view model in 9.27s.
2021-01-19 10:53:47.475020 (MainThread): Connection 'master' was properly closed.
2021-01-19 10:53:47.475145 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 10:53:47.483108 (MainThread): 
2021-01-19 10:53:47.483284 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 10:53:47.483413 (MainThread): 
2021-01-19 10:53:47.483533 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 10:53:47.483644 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 10:53:47.483815 (MainThread):   
2021-01-19 10:53:47.484012 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:53:47.484147 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 10:53:47.484346 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1826a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2137c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f213b50>]}
2021-01-19 10:53:47.484567 (MainThread): Flushing usage events
2021-01-19 10:56:44.445147 (MainThread): Running with dbt=0.18.1
2021-01-19 10:56:44.511026 (MainThread): Loading KWallet
2021-01-19 10:56:44.511492 (MainThread): Loading SecretService
2021-01-19 10:56:44.511856 (MainThread): Loading Windows
2021-01-19 10:56:44.512332 (MainThread): Loading chainer
2021-01-19 10:56:44.512574 (MainThread): Loading macOS
2021-01-19 10:56:44.770934 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 10:56:44.771874 (MainThread): Tracking: tracking
2021-01-19 10:56:44.772124 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11110e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131d040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131dd90>]}
2021-01-19 10:56:44.793108 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 10:56:44.794120 (MainThread): Parsing macros/catalog.sql
2021-01-19 10:56:44.796110 (MainThread): Parsing macros/adapters.sql
2021-01-19 10:56:44.823127 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 10:56:44.824989 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 10:56:44.826322 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 10:56:44.829943 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 10:56:44.839480 (MainThread): Parsing macros/core.sql
2021-01-19 10:56:44.842779 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 10:56:44.850907 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 10:56:44.852638 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 10:56:44.867920 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 10:56:44.895503 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 10:56:44.915068 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 10:56:44.916811 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 10:56:44.922514 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 10:56:44.935532 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 10:56:44.941895 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 10:56:44.947753 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 10:56:44.952395 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 10:56:44.953250 (MainThread): Parsing macros/etc/query.sql
2021-01-19 10:56:44.954203 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 10:56:44.955679 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 10:56:44.964112 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 10:56:44.965916 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 10:56:44.967500 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 10:56:45.007033 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 10:56:45.008739 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 10:56:45.010137 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 10:56:45.011620 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 10:56:45.019401 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 10:56:45.052047 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:56:45.070768 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 10:56:45.262776 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 10:56:45.264148 (MainThread): 
2021-01-19 10:56:45.264953 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:56:45.268269 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 10:56:45.280666 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 10:56:45.280776 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 10:56:45.280851 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 10:56:46.550486 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.27 seconds
2021-01-19 10:56:46.555294 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 10:56:46.841767 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 10:56:46.850011 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 10:56:46.850136 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 10:56:46.850260 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 10:56:48.193153 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.34 seconds
2021-01-19 10:56:48.193767 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 10:56:48.463202 (MainThread): Using snowflake connection "master".
2021-01-19 10:56:48.463381 (MainThread): On master: BEGIN
2021-01-19 10:56:48.463520 (MainThread): Opening a new connection, currently in state init
2021-01-19 10:56:49.444680 (MainThread): SQL status: SUCCESS 1 in 0.98 seconds
2021-01-19 10:56:49.444953 (MainThread): On master: COMMIT
2021-01-19 10:56:49.445206 (MainThread): Using snowflake connection "master".
2021-01-19 10:56:49.445352 (MainThread): On master: COMMIT
2021-01-19 10:56:49.665755 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 10:56:49.666030 (MainThread): On master: Close
2021-01-19 10:56:49.927436 (MainThread): 11:56:49 | Concurrency: 1 threads (target='dev')
2021-01-19 10:56:49.927665 (MainThread): 11:56:49 | 
2021-01-19 10:56:49.929766 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:56:49.931180 (Thread-1): 11:56:49 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 10:56:49.931491 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:56:49.931622 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 10:56:49.953899 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:56:49.954433 (Thread-1): finished collecting timing info
2021-01-19 10:56:49.990899 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:56:49.992022 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:56:49.992135 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 10:56:49.992232 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 10:56:51.079228 (Thread-1): SQL status: SUCCESS 1 in 1.09 seconds
2021-01-19 10:56:51.079485 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:56:51.079633 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 10:56:51.812642 (Thread-1): Snowflake query id: 0199b650-06cc-3d41-0000-003989037139
2021-01-19 10:56:51.812863 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 10:56:51.813093 (Thread-1): finished collecting timing info
2021-01-19 10:56:51.813550 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 10:56:52.032003 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 10:56:52.380351 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:56:52.383548 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba959a97-8b36-4db1-9c88-a93e6e2872e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112366910>]}
2021-01-19 10:56:52.384884 (Thread-1): 11:56:52 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.45s]
2021-01-19 10:56:52.385040 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:56:52.385834 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:56:52.386152 (Thread-1): 11:56:52 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 10:56:52.386307 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:56:52.387408 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:56:52.387638 (MainThread): Using snowflake connection "master".
2021-01-19 10:56:52.387743 (MainThread): On master: BEGIN
2021-01-19 10:56:52.387847 (MainThread): Opening a new connection, currently in state closed
2021-01-19 10:56:53.923495 (MainThread): SQL status: SUCCESS 1 in 1.54 seconds
2021-01-19 10:56:53.923766 (MainThread): On master: COMMIT
2021-01-19 10:56:53.924004 (MainThread): Using snowflake connection "master".
2021-01-19 10:56:53.924143 (MainThread): On master: COMMIT
2021-01-19 10:56:54.139348 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 10:56:54.139534 (MainThread): On master: Close
2021-01-19 10:56:54.400762 (MainThread): 11:56:54 | 
2021-01-19 10:56:54.400977 (MainThread): 11:56:54 | Finished running 1 table model, 1 view model in 9.14s.
2021-01-19 10:56:54.401121 (MainThread): Connection 'master' was properly closed.
2021-01-19 10:56:54.401230 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 10:56:54.409004 (MainThread): 
2021-01-19 10:56:54.409165 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 10:56:54.409293 (MainThread): 
2021-01-19 10:56:54.409414 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 10:56:54.409523 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 10:56:54.409676 (MainThread):   
2021-01-19 10:56:54.409864 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:56:54.409995 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 10:56:54.410192 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123db100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112e8f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f80a60>]}
2021-01-19 10:56:54.410411 (MainThread): Flushing usage events
2021-01-19 10:59:23.179626 (MainThread): Running with dbt=0.18.1
2021-01-19 10:59:23.248897 (MainThread): Loading KWallet
2021-01-19 10:59:23.249684 (MainThread): Loading SecretService
2021-01-19 10:59:23.250181 (MainThread): Loading Windows
2021-01-19 10:59:23.250819 (MainThread): Loading chainer
2021-01-19 10:59:23.251140 (MainThread): Loading macOS
2021-01-19 10:59:23.512135 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 10:59:23.513181 (MainThread): Tracking: tracking
2021-01-19 10:59:23.513431 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109fc190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c0ad60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c0adf0>]}
2021-01-19 10:59:23.546458 (MainThread): Got an acceptable cached parse result
2021-01-19 10:59:23.681293 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 10:59:23.682640 (MainThread): 
2021-01-19 10:59:23.683391 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:59:23.686419 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 10:59:23.699504 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 10:59:23.699646 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 10:59:23.699723 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 10:59:25.050047 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.35 seconds
2021-01-19 10:59:25.054914 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 10:59:25.346657 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 10:59:25.354923 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 10:59:25.355065 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 10:59:25.355172 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 10:59:26.365387 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.01 seconds
2021-01-19 10:59:26.366048 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 10:59:26.731877 (MainThread): Using snowflake connection "master".
2021-01-19 10:59:26.732068 (MainThread): On master: BEGIN
2021-01-19 10:59:26.732202 (MainThread): Opening a new connection, currently in state init
2021-01-19 10:59:28.039765 (MainThread): SQL status: SUCCESS 1 in 1.31 seconds
2021-01-19 10:59:28.040047 (MainThread): On master: COMMIT
2021-01-19 10:59:28.040306 (MainThread): Using snowflake connection "master".
2021-01-19 10:59:28.040457 (MainThread): On master: COMMIT
2021-01-19 10:59:28.277904 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 10:59:28.278109 (MainThread): On master: Close
2021-01-19 10:59:28.561743 (MainThread): 11:59:28 | Concurrency: 1 threads (target='dev')
2021-01-19 10:59:28.561985 (MainThread): 11:59:28 | 
2021-01-19 10:59:28.564066 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:59:28.565534 (Thread-1): 11:59:28 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 10:59:28.565885 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:59:28.566033 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 10:59:28.597755 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:59:28.598260 (Thread-1): finished collecting timing info
2021-01-19 10:59:28.633826 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 10:59:28.634937 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:59:28.635047 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 10:59:28.635147 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 10:59:29.752765 (Thread-1): SQL status: SUCCESS 1 in 1.12 seconds
2021-01-19 10:59:29.752984 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 10:59:29.753108 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 10:59:29.993993 (Thread-1): Snowflake query id: 0199b653-0694-866b-0000-00398903714d
2021-01-19 10:59:29.994221 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 10:59:29.994452 (Thread-1): finished collecting timing info
2021-01-19 10:59:29.994896 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 10:59:30.213559 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 10:59:30.579514 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:59:30.582597 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb517e35-0ab6-46d4-9c53-638a2d2f0999', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d31490>]}
2021-01-19 10:59:30.583955 (Thread-1): 11:59:30 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.02s]
2021-01-19 10:59:30.584130 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 10:59:30.584897 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:59:30.585343 (Thread-1): 11:59:30 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 10:59:30.585663 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 10:59:30.586764 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 10:59:30.586997 (MainThread): Using snowflake connection "master".
2021-01-19 10:59:30.587107 (MainThread): On master: BEGIN
2021-01-19 10:59:30.587214 (MainThread): Opening a new connection, currently in state closed
2021-01-19 10:59:31.453673 (MainThread): SQL status: SUCCESS 1 in 0.87 seconds
2021-01-19 10:59:31.453878 (MainThread): On master: COMMIT
2021-01-19 10:59:31.454050 (MainThread): Using snowflake connection "master".
2021-01-19 10:59:31.454151 (MainThread): On master: COMMIT
2021-01-19 10:59:31.663764 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 10:59:31.664051 (MainThread): On master: Close
2021-01-19 10:59:31.943961 (MainThread): 11:59:31 | 
2021-01-19 10:59:31.944199 (MainThread): 11:59:31 | Finished running 1 table model, 1 view model in 8.26s.
2021-01-19 10:59:31.944389 (MainThread): Connection 'master' was properly closed.
2021-01-19 10:59:31.944581 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 10:59:31.952622 (MainThread): 
2021-01-19 10:59:31.952784 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 10:59:31.952920 (MainThread): 
2021-01-19 10:59:31.953064 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 10:59:31.953244 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 10:59:31.953368 (MainThread):   
2021-01-19 10:59:31.953474 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 10:59:31.953592 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 10:59:31.953781 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e48490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e48430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e48df0>]}
2021-01-19 10:59:31.954064 (MainThread): Flushing usage events
2021-01-19 11:00:10.648796 (MainThread): Running with dbt=0.18.1
2021-01-19 11:00:10.718876 (MainThread): Loading KWallet
2021-01-19 11:00:10.719322 (MainThread): Loading SecretService
2021-01-19 11:00:10.719677 (MainThread): Loading Windows
2021-01-19 11:00:10.720144 (MainThread): Loading chainer
2021-01-19 11:00:10.720377 (MainThread): Loading macOS
2021-01-19 11:00:10.973481 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 11:00:10.974664 (MainThread): Tracking: tracking
2021-01-19 11:00:10.974912 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111193760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113a2d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113a22e0>]}
2021-01-19 11:00:10.996728 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 11:00:10.997725 (MainThread): Parsing macros/catalog.sql
2021-01-19 11:00:10.999717 (MainThread): Parsing macros/adapters.sql
2021-01-19 11:00:11.026768 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 11:00:11.028615 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 11:00:11.029978 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 11:00:11.033606 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 11:00:11.043164 (MainThread): Parsing macros/core.sql
2021-01-19 11:00:11.046512 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 11:00:11.054693 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 11:00:11.056330 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 11:00:11.071714 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 11:00:11.099561 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 11:00:11.119067 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 11:00:11.120757 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 11:00:11.126484 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 11:00:11.139586 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 11:00:11.146344 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 11:00:11.152228 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 11:00:11.156794 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 11:00:11.157661 (MainThread): Parsing macros/etc/query.sql
2021-01-19 11:00:11.158634 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 11:00:11.160145 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 11:00:11.168134 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 11:00:11.169846 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 11:00:11.171300 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 11:00:11.209723 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 11:00:11.211390 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 11:00:11.212737 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 11:00:11.214235 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 11:00:11.222258 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 11:00:11.257193 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:00:11.275692 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 11:00:11.467277 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 11:00:11.468826 (MainThread): 
2021-01-19 11:00:11.469608 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 11:00:11.472581 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 11:00:11.485483 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 11:00:11.485606 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 11:00:11.485683 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 11:00:12.776532 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.29 seconds
2021-01-19 11:00:12.781378 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 11:00:13.670286 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 11:00:13.678601 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 11:00:13.678734 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 11:00:13.678848 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 11:00:15.809551 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 2.13 seconds
2021-01-19 11:00:15.810173 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 11:00:16.103509 (MainThread): Using snowflake connection "master".
2021-01-19 11:00:16.103699 (MainThread): On master: BEGIN
2021-01-19 11:00:16.103830 (MainThread): Opening a new connection, currently in state init
2021-01-19 11:00:17.866565 (MainThread): SQL status: SUCCESS 1 in 1.76 seconds
2021-01-19 11:00:17.866843 (MainThread): On master: COMMIT
2021-01-19 11:00:17.867103 (MainThread): Using snowflake connection "master".
2021-01-19 11:00:17.867256 (MainThread): On master: COMMIT
2021-01-19 11:00:18.251283 (MainThread): SQL status: SUCCESS 1 in 0.38 seconds
2021-01-19 11:00:18.251567 (MainThread): On master: Close
2021-01-19 11:00:18.539421 (MainThread): 12:00:18 | Concurrency: 1 threads (target='dev')
2021-01-19 11:00:18.539657 (MainThread): 12:00:18 | 
2021-01-19 11:00:18.541772 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 11:00:18.543239 (Thread-1): 12:00:18 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 11:00:18.543622 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:00:18.543770 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 11:00:18.566353 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 11:00:18.566897 (Thread-1): finished collecting timing info
2021-01-19 11:00:18.603228 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 11:00:18.604233 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:00:18.604333 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 11:00:18.604423 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 11:00:20.672150 (Thread-1): SQL status: SUCCESS 1 in 2.07 seconds
2021-01-19 11:00:20.672401 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:00:20.672556 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 11:00:20.904606 (Thread-1): Snowflake query id: 0199b654-0658-02a6-0000-003989032165
2021-01-19 11:00:20.904839 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 11:00:20.905077 (Thread-1): finished collecting timing info
2021-01-19 11:00:20.905530 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 11:00:21.322978 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 11:00:21.590658 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 11:00:21.593862 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa3671e-e97b-44ca-83da-20ee0ec86c0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121424f0>]}
2021-01-19 11:00:21.595217 (Thread-1): 12:00:21 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 3.05s]
2021-01-19 11:00:21.595378 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 11:00:21.596131 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 11:00:21.596516 (Thread-1): 12:00:21 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 11:00:21.596743 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 11:00:21.597737 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 11:00:21.597963 (MainThread): Using snowflake connection "master".
2021-01-19 11:00:21.598069 (MainThread): On master: BEGIN
2021-01-19 11:00:21.598174 (MainThread): Opening a new connection, currently in state closed
2021-01-19 11:00:23.685003 (MainThread): SQL status: SUCCESS 1 in 2.09 seconds
2021-01-19 11:00:23.685272 (MainThread): On master: COMMIT
2021-01-19 11:00:23.685516 (MainThread): Using snowflake connection "master".
2021-01-19 11:00:23.685664 (MainThread): On master: COMMIT
2021-01-19 11:00:23.898987 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 11:00:23.899270 (MainThread): On master: Close
2021-01-19 11:00:24.160551 (MainThread): 12:00:24 | 
2021-01-19 11:00:24.160793 (MainThread): 12:00:24 | Finished running 1 table model, 1 view model in 12.69s.
2021-01-19 11:00:24.160947 (MainThread): Connection 'master' was properly closed.
2021-01-19 11:00:24.161146 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 11:00:24.168928 (MainThread): 
2021-01-19 11:00:24.169092 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 11:00:24.169289 (MainThread): 
2021-01-19 11:00:24.169460 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 11:00:24.169585 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 11:00:24.169694 (MainThread):   
2021-01-19 11:00:24.169801 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 11:00:24.169913 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 11:00:24.170097 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112006460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112044c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e7ca30>]}
2021-01-19 11:00:24.170314 (MainThread): Flushing usage events
2021-01-19 11:29:11.754149 (MainThread): Running with dbt=0.18.1
2021-01-19 11:29:11.836092 (MainThread): Loading KWallet
2021-01-19 11:29:11.836752 (MainThread): Loading SecretService
2021-01-19 11:29:11.837246 (MainThread): Loading Windows
2021-01-19 11:29:11.837881 (MainThread): Loading chainer
2021-01-19 11:29:11.838195 (MainThread): Loading macOS
2021-01-19 11:29:12.103715 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 11:29:12.104706 (MainThread): Tracking: tracking
2021-01-19 11:29:12.104973 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ec850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bfb040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bfbd90>]}
2021-01-19 11:29:12.138222 (MainThread): Got an acceptable cached parse result
2021-01-19 11:29:12.282268 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 11:29:12.283976 (MainThread): 
2021-01-19 11:29:12.284804 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 11:29:12.287602 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 11:29:12.301855 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 11:29:12.302070 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 11:29:12.302192 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 11:29:13.622329 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.32 seconds
2021-01-19 11:29:13.627370 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 11:29:13.929391 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 11:29:13.937848 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 11:29:13.937978 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 11:29:13.938085 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 11:29:15.378478 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.44 seconds
2021-01-19 11:29:15.379159 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 11:29:15.653839 (MainThread): Using snowflake connection "master".
2021-01-19 11:29:15.654028 (MainThread): On master: BEGIN
2021-01-19 11:29:15.654162 (MainThread): Opening a new connection, currently in state init
2021-01-19 11:29:16.675862 (MainThread): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-19 11:29:16.676145 (MainThread): On master: COMMIT
2021-01-19 11:29:16.676393 (MainThread): Using snowflake connection "master".
2021-01-19 11:29:16.676541 (MainThread): On master: COMMIT
2021-01-19 11:29:16.889537 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 11:29:16.889746 (MainThread): On master: Close
2021-01-19 11:29:17.160383 (MainThread): 12:29:17 | Concurrency: 1 threads (target='dev')
2021-01-19 11:29:17.160628 (MainThread): 12:29:17 | 
2021-01-19 11:29:17.162684 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 11:29:17.164153 (Thread-1): 12:29:17 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 11:29:17.164478 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:29:17.164635 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 11:29:17.195699 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 11:29:17.196230 (Thread-1): finished collecting timing info
2021-01-19 11:29:17.231222 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 11:29:17.232269 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:29:17.232385 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 11:29:17.232480 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 11:29:18.081462 (Thread-1): SQL status: SUCCESS 1 in 0.85 seconds
2021-01-19 11:29:18.081732 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 11:29:18.081889 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 11:29:18.324200 (Thread-1): Snowflake query id: 0199b671-06cd-e2c2-0000-003989034135
2021-01-19 11:29:18.324365 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 11:29:18.324535 (Thread-1): finished collecting timing info
2021-01-19 11:29:18.324850 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 11:29:18.525924 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 11:29:18.788962 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 11:29:18.792401 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '381718db-b3aa-4f3b-9735-945fc90a2956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b9d430>]}
2021-01-19 11:29:18.793834 (Thread-1): 12:29:18 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 1.63s]
2021-01-19 11:29:18.794010 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 11:29:18.794959 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 11:29:18.795377 (Thread-1): 12:29:18 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 11:29:18.795673 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 11:29:18.796655 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 11:29:18.796887 (MainThread): Using snowflake connection "master".
2021-01-19 11:29:18.797001 (MainThread): On master: BEGIN
2021-01-19 11:29:18.797112 (MainThread): Opening a new connection, currently in state closed
2021-01-19 11:29:19.614401 (MainThread): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 11:29:19.614683 (MainThread): On master: COMMIT
2021-01-19 11:29:19.614934 (MainThread): Using snowflake connection "master".
2021-01-19 11:29:19.615085 (MainThread): On master: COMMIT
2021-01-19 11:29:19.889617 (MainThread): SQL status: SUCCESS 1 in 0.27 seconds
2021-01-19 11:29:19.889908 (MainThread): On master: Close
2021-01-19 11:29:20.148099 (MainThread): 12:29:20 | 
2021-01-19 11:29:20.148348 (MainThread): 12:29:20 | Finished running 1 table model, 1 view model in 7.86s.
2021-01-19 11:29:20.148679 (MainThread): Connection 'master' was properly closed.
2021-01-19 11:29:20.148862 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 11:29:20.156382 (MainThread): 
2021-01-19 11:29:20.156551 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 11:29:20.156694 (MainThread): 
2021-01-19 11:29:20.156819 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 11:29:20.156932 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 11:29:20.157037 (MainThread):   
2021-01-19 11:29:20.157136 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 11:29:20.157243 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 11:29:20.157426 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9d4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d06910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d06040>]}
2021-01-19 11:29:20.157642 (MainThread): Flushing usage events
2021-01-19 13:02:16.782867 (MainThread): Running with dbt=0.18.1
2021-01-19 13:02:16.881243 (MainThread): Loading KWallet
2021-01-19 13:02:16.881942 (MainThread): Loading SecretService
2021-01-19 13:02:16.882467 (MainThread): Loading Windows
2021-01-19 13:02:16.883150 (MainThread): Loading chainer
2021-01-19 13:02:16.883497 (MainThread): Loading macOS
2021-01-19 13:02:17.310661 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:02:17.312136 (MainThread): Tracking: tracking
2021-01-19 13:02:17.312478 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f30ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10713f040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10713fd90>]}
2021-01-19 13:02:17.364882 (MainThread): Got an acceptable cached parse result
2021-01-19 13:02:17.541787 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:02:17.543538 (MainThread): 
2021-01-19 13:02:17.544095 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:02:17.548282 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:02:17.565514 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:02:17.565666 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:02:17.565769 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:02:19.410679 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.84 seconds
2021-01-19 13:02:19.415282 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:02:19.728030 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:02:19.736070 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:02:19.736203 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:02:19.736310 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:02:21.250641 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.51 seconds
2021-01-19 13:02:21.251422 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:02:22.484900 (MainThread): Using snowflake connection "master".
2021-01-19 13:02:22.485099 (MainThread): On master: BEGIN
2021-01-19 13:02:22.485236 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:02:24.019253 (MainThread): SQL status: SUCCESS 1 in 1.53 seconds
2021-01-19 13:02:24.019532 (MainThread): On master: COMMIT
2021-01-19 13:02:24.019784 (MainThread): Using snowflake connection "master".
2021-01-19 13:02:24.019934 (MainThread): On master: COMMIT
2021-01-19 13:02:24.352867 (MainThread): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 13:02:24.353163 (MainThread): On master: Close
2021-01-19 13:02:24.836964 (MainThread): 14:02:24 | Concurrency: 1 threads (target='dev')
2021-01-19 13:02:24.837218 (MainThread): 14:02:24 | 
2021-01-19 13:02:24.840614 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:02:24.842578 (Thread-1): 14:02:24 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:02:24.843096 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:02:24.843272 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:02:24.875339 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:02:24.877142 (Thread-1): finished collecting timing info
2021-01-19 13:02:24.913539 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:02:24.914973 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:02:24.915089 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:02:24.915188 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:02:26.065295 (Thread-1): SQL status: SUCCESS 1 in 1.15 seconds
2021-01-19 13:02:26.065480 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:02:26.065583 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:02:26.778200 (Thread-1): Snowflake query id: 0199b6ce-06b0-3d6e-0000-003989034159
2021-01-19 13:02:26.778373 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:02:26.778568 (Thread-1): finished collecting timing info
2021-01-19 13:02:26.778928 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:02:27.333484 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:02:28.011756 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:02:28.021287 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7590a25-f590-4909-b35f-d4dda422a3c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0ef430>]}
2021-01-19 13:02:28.022546 (Thread-1): 14:02:28 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 3.18s]
2021-01-19 13:02:28.022695 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:02:28.023612 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:02:28.023899 (Thread-1): 14:02:28 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:02:28.024175 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:02:28.025466 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:02:28.025701 (MainThread): Using snowflake connection "master".
2021-01-19 13:02:28.025838 (MainThread): On master: BEGIN
2021-01-19 13:02:28.025947 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:02:30.911867 (MainThread): SQL status: SUCCESS 1 in 2.89 seconds
2021-01-19 13:02:30.912043 (MainThread): On master: COMMIT
2021-01-19 13:02:30.912182 (MainThread): Using snowflake connection "master".
2021-01-19 13:02:30.912261 (MainThread): On master: COMMIT
2021-01-19 13:02:32.102255 (MainThread): SQL status: SUCCESS 1 in 1.19 seconds
2021-01-19 13:02:32.102423 (MainThread): On master: Close
2021-01-19 13:02:32.514923 (MainThread): 14:02:32 | 
2021-01-19 13:02:32.520059 (MainThread): 14:02:32 | Finished running 1 table model, 1 view model in 14.97s.
2021-01-19 13:02:32.542538 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:02:32.563498 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:02:32.570351 (MainThread): 
2021-01-19 13:02:32.570487 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:02:32.570594 (MainThread): 
2021-01-19 13:02:32.570694 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:02:32.570786 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:02:32.570877 (MainThread):   
2021-01-19 13:02:32.570957 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:02:32.571046 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:02:32.571200 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1284c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e25a910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e25a040>]}
2021-01-19 13:02:32.571388 (MainThread): Flushing usage events
2021-01-19 13:05:09.422871 (MainThread): Running with dbt=0.18.1
2021-01-19 13:05:09.511589 (MainThread): Loading KWallet
2021-01-19 13:05:09.512258 (MainThread): Loading SecretService
2021-01-19 13:05:09.512772 (MainThread): Loading Windows
2021-01-19 13:05:09.513428 (MainThread): Loading chainer
2021-01-19 13:05:09.513761 (MainThread): Loading macOS
2021-01-19 13:05:09.844321 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:05:09.845490 (MainThread): Tracking: tracking
2021-01-19 13:05:09.845777 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9905e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb9e0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb9e040>]}
2021-01-19 13:05:09.895978 (MainThread): Got an acceptable cached parse result
2021-01-19 13:05:10.078287 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:05:10.079226 (MainThread): 
2021-01-19 13:05:10.079591 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:05:10.082651 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:05:10.099112 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:05:10.099274 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:05:10.099390 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:05:12.137003 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 2.04 seconds
2021-01-19 13:05:12.141510 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:05:12.547319 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:05:12.547619 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:05:12.547795 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 13:05:12.554169 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:05:12.554335 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 13:05:12.554444 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 13:05:13.771789 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.22 seconds
2021-01-19 13:05:13.771985 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:05:13.772083 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 13:05:14.081712 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 13:05:14.083077 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:05:14.083311 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:05:14.083450 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:05:14.247364 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 13:05:14.247601 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 13:05:14.650162 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:05:14.658769 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:05:14.658941 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:05:14.659052 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:05:15.847862 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.19 seconds
2021-01-19 13:05:15.848601 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:05:16.228439 (MainThread): Using snowflake connection "master".
2021-01-19 13:05:16.228602 (MainThread): On master: BEGIN
2021-01-19 13:05:16.228716 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:05:17.290334 (MainThread): SQL status: SUCCESS 1 in 1.06 seconds
2021-01-19 13:05:17.290548 (MainThread): On master: COMMIT
2021-01-19 13:05:17.290724 (MainThread): Using snowflake connection "master".
2021-01-19 13:05:17.290822 (MainThread): On master: COMMIT
2021-01-19 13:05:17.583743 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2021-01-19 13:05:17.583956 (MainThread): On master: Close
2021-01-19 13:05:18.589907 (MainThread): 14:05:18 | Concurrency: 1 threads (target='dev')
2021-01-19 13:05:18.590116 (MainThread): 14:05:18 | 
2021-01-19 13:05:18.592052 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:05:18.593330 (Thread-1): 14:05:18 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:05:18.593653 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:05:18.593789 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:05:18.626371 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:05:18.626908 (Thread-1): finished collecting timing info
2021-01-19 13:05:18.666731 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:05:18.667913 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:05:18.668059 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:05:18.668168 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:05:20.210212 (Thread-1): SQL status: SUCCESS 1 in 1.54 seconds
2021-01-19 13:05:20.210477 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:05:20.210712 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:05:20.634829 (Thread-1): Snowflake query id: 0199b6d1-0666-04a4-0000-003989036199
2021-01-19 13:05:20.635076 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:05:20.635326 (Thread-1): finished collecting timing info
2021-01-19 13:05:20.635787 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:05:21.073624 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:05:21.367016 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:05:21.370158 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63ab1f1e-5d8d-45d9-bbdd-25a76f13e9b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b140d0>]}
2021-01-19 13:05:21.371661 (Thread-1): 14:05:21 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.78s]
2021-01-19 13:05:21.371852 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:05:21.372597 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:05:21.372913 (Thread-1): 14:05:21 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:05:21.373092 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:05:21.374092 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:05:21.374309 (MainThread): Using snowflake connection "master".
2021-01-19 13:05:21.374413 (MainThread): On master: BEGIN
2021-01-19 13:05:21.374513 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:05:22.351623 (MainThread): SQL status: SUCCESS 1 in 0.98 seconds
2021-01-19 13:05:22.351980 (MainThread): On master: COMMIT
2021-01-19 13:05:22.352186 (MainThread): Using snowflake connection "master".
2021-01-19 13:05:22.352294 (MainThread): On master: COMMIT
2021-01-19 13:05:22.631020 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 13:05:22.631307 (MainThread): On master: Close
2021-01-19 13:05:22.941568 (MainThread): 14:05:22 | 
2021-01-19 13:05:22.941776 (MainThread): 14:05:22 | Finished running 1 table model, 1 view model in 12.86s.
2021-01-19 13:05:22.941961 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:05:22.942091 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:05:22.949744 (MainThread): 
2021-01-19 13:05:22.949904 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:05:22.950073 (MainThread): 
2021-01-19 13:05:22.950370 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:05:22.950587 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:05:22.950737 (MainThread):   
2021-01-19 13:05:22.950867 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:05:22.950997 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:05:22.951262 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110855ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cc5100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cc53d0>]}
2021-01-19 13:05:22.951494 (MainThread): Flushing usage events
2021-01-19 13:06:47.742797 (MainThread): Running with dbt=0.18.1
2021-01-19 13:06:47.822442 (MainThread): Loading KWallet
2021-01-19 13:06:47.823179 (MainThread): Loading SecretService
2021-01-19 13:06:47.823702 (MainThread): Loading Windows
2021-01-19 13:06:47.824516 (MainThread): Loading chainer
2021-01-19 13:06:47.824876 (MainThread): Loading macOS
2021-01-19 13:06:48.127161 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:06:48.128177 (MainThread): Tracking: tracking
2021-01-19 13:06:48.128414 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104c6ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106d5310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106d50d0>]}
2021-01-19 13:06:48.169030 (MainThread): Got an acceptable cached parse result
2021-01-19 13:06:48.325419 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:06:48.326710 (MainThread): 
2021-01-19 13:06:48.327298 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:06:48.329796 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:06:48.344736 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:06:48.344859 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:06:48.344938 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:06:50.885717 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.54 seconds
2021-01-19 13:06:50.890315 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:06:53.236210 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:06:53.244394 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:06:53.244528 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:06:53.244635 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:06:54.147983 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.90 seconds
2021-01-19 13:06:54.148673 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:06:54.897784 (MainThread): Using snowflake connection "master".
2021-01-19 13:06:54.898067 (MainThread): On master: BEGIN
2021-01-19 13:06:54.898204 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:06:56.807280 (MainThread): SQL status: SUCCESS 1 in 1.91 seconds
2021-01-19 13:06:56.807556 (MainThread): On master: COMMIT
2021-01-19 13:06:56.807801 (MainThread): Using snowflake connection "master".
2021-01-19 13:06:56.807949 (MainThread): On master: COMMIT
2021-01-19 13:06:57.256091 (MainThread): SQL status: SUCCESS 1 in 0.45 seconds
2021-01-19 13:06:57.256382 (MainThread): On master: Close
2021-01-19 13:06:57.546825 (MainThread): 14:06:57 | Concurrency: 1 threads (target='dev')
2021-01-19 13:06:57.547054 (MainThread): 14:06:57 | 
2021-01-19 13:06:57.549809 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:06:57.551148 (Thread-1): 14:06:57 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:06:57.551478 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:06:57.551614 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:06:57.583405 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:06:57.583910 (Thread-1): finished collecting timing info
2021-01-19 13:06:57.623805 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:06:57.625009 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:06:57.625130 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:06:57.625242 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:06:58.548646 (Thread-1): SQL status: SUCCESS 1 in 0.92 seconds
2021-01-19 13:06:58.548903 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:06:58.549064 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:06:58.855405 (Thread-1): Snowflake query id: 0199b6d2-06d3-5fb3-0000-0039890361a1
2021-01-19 13:06:58.855637 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:06:58.855877 (Thread-1): finished collecting timing info
2021-01-19 13:06:58.856319 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:06:59.162594 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:06:59.573539 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:06:59.576809 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '064a6164-c58a-4533-b0a1-f56559e5c058', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112e4370>]}
2021-01-19 13:06:59.578157 (Thread-1): 14:06:59 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.03s]
2021-01-19 13:06:59.578318 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:06:59.578919 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:06:59.579318 (Thread-1): 14:06:59 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:06:59.579644 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:06:59.581364 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:06:59.581852 (MainThread): Using snowflake connection "master".
2021-01-19 13:06:59.582062 (MainThread): On master: BEGIN
2021-01-19 13:06:59.582328 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:07:00.903159 (MainThread): SQL status: SUCCESS 1 in 1.32 seconds
2021-01-19 13:07:00.903383 (MainThread): On master: COMMIT
2021-01-19 13:07:00.903587 (MainThread): Using snowflake connection "master".
2021-01-19 13:07:00.903715 (MainThread): On master: COMMIT
2021-01-19 13:07:01.961850 (MainThread): SQL status: SUCCESS 1 in 1.06 seconds
2021-01-19 13:07:01.962137 (MainThread): On master: Close
2021-01-19 13:07:02.341601 (MainThread): 14:07:02 | 
2021-01-19 13:07:02.341831 (MainThread): 14:07:02 | Finished running 1 table model, 1 view model in 14.01s.
2021-01-19 13:07:02.341993 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:07:02.342103 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:07:02.349658 (MainThread): 
2021-01-19 13:07:02.349838 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:07:02.349975 (MainThread): 
2021-01-19 13:07:02.350097 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:07:02.350208 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:07:02.350311 (MainThread):   
2021-01-19 13:07:02.350407 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:07:02.350553 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:07:02.350781 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11167b3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11167b340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11167b370>]}
2021-01-19 13:07:02.351003 (MainThread): Flushing usage events
2021-01-19 13:09:00.377919 (MainThread): Running with dbt=0.18.1
2021-01-19 13:09:00.460079 (MainThread): Loading KWallet
2021-01-19 13:09:00.461115 (MainThread): Loading SecretService
2021-01-19 13:09:00.461684 (MainThread): Loading Windows
2021-01-19 13:09:00.462426 (MainThread): Loading chainer
2021-01-19 13:09:00.462782 (MainThread): Loading macOS
2021-01-19 13:09:00.778598 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:09:00.779805 (MainThread): Tracking: tracking
2021-01-19 13:09:00.780112 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e16970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046b17c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f480a0>]}
2021-01-19 13:09:00.819659 (MainThread): Got an acceptable cached parse result
2021-01-19 13:09:00.983418 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:09:00.985190 (MainThread): 
2021-01-19 13:09:00.986225 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:09:00.989590 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:09:01.006710 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:09:01.006869 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:09:01.006972 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:09:02.773140 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.77 seconds
2021-01-19 13:09:02.778535 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:09:03.204579 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:09:03.204934 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:09:03.205146 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 13:09:03.211587 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:09:03.211728 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 13:09:03.211840 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 13:09:04.834658 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.62 seconds
2021-01-19 13:09:04.834909 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:09:04.835061 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 13:09:05.627410 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.79 seconds
2021-01-19 13:09:05.629145 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:09:05.629380 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:09:05.629508 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:09:06.046646 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.42 seconds
2021-01-19 13:09:06.046889 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 13:09:06.371992 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:09:06.380693 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:09:06.380868 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:09:06.380982 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:09:07.688275 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.31 seconds
2021-01-19 13:09:07.688949 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:09:08.064582 (MainThread): Using snowflake connection "master".
2021-01-19 13:09:08.064762 (MainThread): On master: BEGIN
2021-01-19 13:09:08.064881 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:09:09.414099 (MainThread): SQL status: SUCCESS 1 in 1.35 seconds
2021-01-19 13:09:09.414333 (MainThread): On master: COMMIT
2021-01-19 13:09:09.414531 (MainThread): Using snowflake connection "master".
2021-01-19 13:09:09.414630 (MainThread): On master: COMMIT
2021-01-19 13:09:10.130747 (MainThread): SQL status: SUCCESS 1 in 0.72 seconds
2021-01-19 13:09:10.130971 (MainThread): On master: Close
2021-01-19 13:09:10.446036 (MainThread): 14:09:10 | Concurrency: 1 threads (target='dev')
2021-01-19 13:09:10.446286 (MainThread): 14:09:10 | 
2021-01-19 13:09:10.448920 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:09:10.450244 (Thread-1): 14:09:10 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:09:10.450577 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:09:10.450717 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:09:10.484001 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:09:10.484564 (Thread-1): finished collecting timing info
2021-01-19 13:09:10.532909 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:09:10.534415 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:09:10.534574 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:09:10.534692 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:09:11.694449 (Thread-1): SQL status: SUCCESS 1 in 1.16 seconds
2021-01-19 13:09:11.694659 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:09:11.694792 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:09:12.123988 (Thread-1): Snowflake query id: 0199b6d5-066a-32a4-0000-0039890361b5
2021-01-19 13:09:12.124223 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:09:12.124456 (Thread-1): finished collecting timing info
2021-01-19 13:09:12.124901 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:09:12.400887 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:09:12.898199 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:09:12.901084 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f0eeb2c-1cad-40c1-95a6-256cedb1a501', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1901c0>]}
2021-01-19 13:09:12.902422 (Thread-1): 14:09:12 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.45s]
2021-01-19 13:09:12.902584 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:09:12.903395 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:09:12.903737 (Thread-1): 14:09:12 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:09:12.903952 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:09:12.905145 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:09:12.905365 (MainThread): Using snowflake connection "master".
2021-01-19 13:09:12.905469 (MainThread): On master: BEGIN
2021-01-19 13:09:12.905572 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:09:14.038073 (MainThread): SQL status: SUCCESS 1 in 1.13 seconds
2021-01-19 13:09:14.038278 (MainThread): On master: COMMIT
2021-01-19 13:09:14.038451 (MainThread): Using snowflake connection "master".
2021-01-19 13:09:14.038549 (MainThread): On master: COMMIT
2021-01-19 13:09:14.329624 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2021-01-19 13:09:14.329889 (MainThread): On master: Close
2021-01-19 13:09:14.643707 (MainThread): 14:09:14 | 
2021-01-19 13:09:14.643932 (MainThread): 14:09:14 | Finished running 1 table model, 1 view model in 13.66s.
2021-01-19 13:09:14.644188 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:09:14.644418 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:09:14.652636 (MainThread): 
2021-01-19 13:09:14.652826 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:09:14.652960 (MainThread): 
2021-01-19 13:09:14.653091 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:09:14.653225 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:09:14.653331 (MainThread):   
2021-01-19 13:09:14.653433 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:09:14.653544 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:09:14.653733 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4da90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4dfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4d4f0>]}
2021-01-19 13:09:14.653948 (MainThread): Flushing usage events
2021-01-19 13:13:08.627630 (MainThread): Running with dbt=0.18.1
2021-01-19 13:13:08.708828 (MainThread): Loading KWallet
2021-01-19 13:13:08.709531 (MainThread): Loading SecretService
2021-01-19 13:13:08.710040 (MainThread): Loading Windows
2021-01-19 13:13:08.710707 (MainThread): Loading chainer
2021-01-19 13:13:08.711044 (MainThread): Loading macOS
2021-01-19 13:13:09.014341 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:13:09.015356 (MainThread): Tracking: tracking
2021-01-19 13:13:09.015646 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da83880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc92d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc92df0>]}
2021-01-19 13:13:09.059001 (MainThread): Got an acceptable cached parse result
2021-01-19 13:13:09.218254 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:13:09.219715 (MainThread): 
2021-01-19 13:13:09.220281 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:13:09.223497 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:13:09.239309 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:13:09.239465 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:13:09.239578 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:13:10.921596 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.68 seconds
2021-01-19 13:13:10.926023 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:13:11.286244 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:13:11.286558 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:13:11.286739 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 13:13:11.292614 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:13:11.292740 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 13:13:11.292850 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 13:13:12.614937 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.32 seconds
2021-01-19 13:13:12.615204 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:13:12.615359 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 13:13:13.023598 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.41 seconds
2021-01-19 13:13:13.024899 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:13:13.025124 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:13:13.025247 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:13:13.438037 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.41 seconds
2021-01-19 13:13:13.438291 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 13:13:14.404168 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:13:14.412316 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:13:14.412453 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:13:14.412562 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:13:15.703032 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.29 seconds
2021-01-19 13:13:15.703808 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:13:15.998373 (MainThread): Using snowflake connection "master".
2021-01-19 13:13:15.998559 (MainThread): On master: BEGIN
2021-01-19 13:13:15.998693 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:13:17.327374 (MainThread): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-19 13:13:17.327640 (MainThread): On master: COMMIT
2021-01-19 13:13:17.327891 (MainThread): Using snowflake connection "master".
2021-01-19 13:13:17.328047 (MainThread): On master: COMMIT
2021-01-19 13:13:17.853231 (MainThread): SQL status: SUCCESS 1 in 0.52 seconds
2021-01-19 13:13:17.853634 (MainThread): On master: Close
2021-01-19 13:13:18.146907 (MainThread): 14:13:18 | Concurrency: 1 threads (target='dev')
2021-01-19 13:13:18.147132 (MainThread): 14:13:18 | 
2021-01-19 13:13:18.149344 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:13:18.151095 (Thread-1): 14:13:18 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:13:18.151658 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:13:18.151887 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:13:18.183871 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:13:18.184696 (Thread-1): finished collecting timing info
2021-01-19 13:13:18.223287 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:13:18.224385 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:13:18.224492 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:13:18.224608 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:13:19.490551 (Thread-1): SQL status: SUCCESS 1 in 1.27 seconds
2021-01-19 13:13:19.490752 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:13:19.490877 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:13:19.782503 (Thread-1): Snowflake query id: 0199b6d9-0666-f44f-0000-0039890321f1
2021-01-19 13:13:19.782737 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:13:19.783007 (Thread-1): finished collecting timing info
2021-01-19 13:13:19.783443 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:13:20.000837 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:13:20.468404 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:13:20.471465 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58ae867c-8acf-4870-9ae6-e56251e8cb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed14850>]}
2021-01-19 13:13:20.472798 (Thread-1): 14:13:20 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.32s]
2021-01-19 13:13:20.472955 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:13:20.473713 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:13:20.474042 (Thread-1): 14:13:20 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:13:20.474267 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:13:20.475341 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:13:20.475559 (MainThread): Using snowflake connection "master".
2021-01-19 13:13:20.475659 (MainThread): On master: BEGIN
2021-01-19 13:13:20.475758 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:13:21.635952 (MainThread): SQL status: SUCCESS 1 in 1.16 seconds
2021-01-19 13:13:21.636263 (MainThread): On master: COMMIT
2021-01-19 13:13:21.636515 (MainThread): Using snowflake connection "master".
2021-01-19 13:13:21.636635 (MainThread): On master: COMMIT
2021-01-19 13:13:22.149698 (MainThread): SQL status: SUCCESS 1 in 0.51 seconds
2021-01-19 13:13:22.149990 (MainThread): On master: Close
2021-01-19 13:13:22.447441 (MainThread): 14:13:22 | 
2021-01-19 13:13:22.447665 (MainThread): 14:13:22 | Finished running 1 table model, 1 view model in 13.23s.
2021-01-19 13:13:22.447870 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:13:22.447991 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:13:22.456657 (MainThread): 
2021-01-19 13:13:22.456847 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:13:22.456977 (MainThread): 
2021-01-19 13:13:22.457098 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:13:22.457207 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:13:22.457310 (MainThread):   
2021-01-19 13:13:22.457510 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:13:22.457638 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:13:22.457830 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d857df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e769ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e77c3d0>]}
2021-01-19 13:13:22.458044 (MainThread): Flushing usage events
2021-01-19 13:35:41.064823 (MainThread): Running with dbt=0.18.1
2021-01-19 13:35:41.160096 (MainThread): Loading KWallet
2021-01-19 13:35:41.160785 (MainThread): Loading SecretService
2021-01-19 13:35:41.161399 (MainThread): Loading Windows
2021-01-19 13:35:41.162092 (MainThread): Loading chainer
2021-01-19 13:35:41.162600 (MainThread): Loading macOS
2021-01-19 13:35:41.525656 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:35:41.526817 (MainThread): Tracking: tracking
2021-01-19 13:35:41.527116 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10387e9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1021187f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039b00d0>]}
2021-01-19 13:35:41.560017 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 13:35:41.561545 (MainThread): Parsing macros/catalog.sql
2021-01-19 13:35:41.565873 (MainThread): Parsing macros/adapters.sql
2021-01-19 13:35:41.604078 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 13:35:41.606508 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 13:35:41.608248 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 13:35:41.613622 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 13:35:41.627271 (MainThread): Parsing macros/core.sql
2021-01-19 13:35:41.633295 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 13:35:41.643956 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 13:35:41.646659 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 13:35:41.667764 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 13:35:41.704515 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 13:35:41.730674 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 13:35:41.733771 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 13:35:41.741215 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 13:35:41.758707 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 13:35:41.767687 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 13:35:41.774977 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 13:35:41.781344 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 13:35:41.782883 (MainThread): Parsing macros/etc/query.sql
2021-01-19 13:35:41.784244 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 13:35:41.786323 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 13:35:41.795813 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 13:35:41.800129 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 13:35:41.802374 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 13:35:41.854901 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 13:35:41.857116 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 13:35:41.858830 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 13:35:41.860750 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 13:35:41.872630 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 13:35:41.919552 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:35:41.947735 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 13:35:42.221921 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:35:42.223004 (MainThread): 
2021-01-19 13:35:42.223403 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:35:42.226555 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:35:42.246024 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:35:42.246286 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:35:42.246413 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:35:44.770245 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 2.52 seconds
2021-01-19 13:35:44.774216 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:35:45.467735 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:35:45.468047 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:35:45.468227 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 13:35:45.473901 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:35:45.474052 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 13:35:45.474161 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 13:35:46.737361 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 1.26 seconds
2021-01-19 13:35:46.737544 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:35:46.737645 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 13:35:47.639254 (ThreadPoolExecutor-0_0): Snowflake query id: 0199b6ef-06ec-058e-0000-0039890352d5
2021-01-19 13:35:47.639440 (ThreadPoolExecutor-0_0): Snowflake error: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
2021-01-19 13:35:47.639610 (ThreadPoolExecutor-0_0): Error running SQL: macro create_schema
2021-01-19 13:35:47.639722 (ThreadPoolExecutor-0_0): Rolling back transaction.
2021-01-19 13:35:47.639848 (ThreadPoolExecutor-0_0): On create_analytics_dbt: ROLLBACK
2021-01-19 13:35:48.027390 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 13:35:48.405091 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:35:48.405277 (MainThread): Connection 'create_analytics_dbt' was properly closed.
2021-01-19 13:35:48.405464 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10490ec70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104826250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045aacd0>]}
2021-01-19 13:35:48.405698 (MainThread): Flushing usage events
2021-01-19 13:35:49.078325 (MainThread): Encountered an error:
2021-01-19 13:35:49.078665 (MainThread): Database Error
  003041 (42710): SQL compilation error:
  Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
2021-01-19 13:35:49.087137 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/impl.py", line 182, in create_schema
    self.execute_macro(CREATE_SCHEMA_MACRO_NAME, kwargs=kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 984, in execute_macro
    result = macro_function(**kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 28, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error
  003041 (42710): SQL compilation error:
  Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.

2021-01-19 13:43:36.474459 (MainThread): Running with dbt=0.18.1
2021-01-19 13:43:36.558776 (MainThread): Loading KWallet
2021-01-19 13:43:36.559419 (MainThread): Loading SecretService
2021-01-19 13:43:36.559914 (MainThread): Loading Windows
2021-01-19 13:43:36.560551 (MainThread): Loading chainer
2021-01-19 13:43:36.560875 (MainThread): Loading macOS
2021-01-19 13:43:36.890650 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:43:36.891794 (MainThread): Tracking: tracking
2021-01-19 13:43:36.892124 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088d9ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ae8040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ae8d90>]}
2021-01-19 13:43:36.936498 (MainThread): Got an acceptable cached parse result
2021-01-19 13:43:37.107053 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:43:37.109177 (MainThread): 
2021-01-19 13:43:37.109973 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:43:37.115384 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:43:37.135985 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:43:37.136176 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:43:37.136295 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:43:38.862869 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.73 seconds
2021-01-19 13:43:38.867859 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:43:39.425253 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:43:39.433434 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:43:39.433575 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:43:39.433685 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:43:40.622810 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.19 seconds
2021-01-19 13:43:40.623289 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:43:40.934574 (MainThread): Using snowflake connection "master".
2021-01-19 13:43:40.934780 (MainThread): On master: BEGIN
2021-01-19 13:43:40.934921 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:43:42.572198 (MainThread): SQL status: SUCCESS 1 in 1.64 seconds
2021-01-19 13:43:42.572430 (MainThread): On master: COMMIT
2021-01-19 13:43:42.572643 (MainThread): Using snowflake connection "master".
2021-01-19 13:43:42.572767 (MainThread): On master: COMMIT
2021-01-19 13:43:42.800927 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 13:43:42.801186 (MainThread): On master: Close
2021-01-19 13:43:43.216574 (MainThread): 14:43:43 | Concurrency: 1 threads (target='dev')
2021-01-19 13:43:43.216846 (MainThread): 14:43:43 | 
2021-01-19 13:43:43.219693 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:43:43.221572 (Thread-1): 14:43:43 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:43:43.221939 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:43:43.222090 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:43:43.254204 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:43:43.254705 (Thread-1): finished collecting timing info
2021-01-19 13:43:43.292785 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:43:43.294064 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:43:43.294200 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:43:43.294315 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:43:44.414371 (Thread-1): SQL status: SUCCESS 1 in 1.12 seconds
2021-01-19 13:43:44.414557 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:43:44.414659 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:43:44.619147 (Thread-1): Snowflake query id: 0199b6f7-064f-5adf-0000-003989037409
2021-01-19 13:43:44.619441 (Thread-1): Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on schema 'DBT'
2021-01-19 13:43:44.619655 (Thread-1): finished collecting timing info
2021-01-19 13:43:44.620031 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:43:45.701139 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:43:46.291093 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on schema 'DBT'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 003001 (42501): SQL access control error:
Insufficient privileges to operate on schema 'DBT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on schema 'DBT'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:43:46.294213 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'db3209d4-105f-4d9d-bd6d-163f37ce47e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a8a670>]}
2021-01-19 13:43:46.295553 (Thread-1): 14:43:46 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 3.07s]
2021-01-19 13:43:46.295717 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:43:46.296525 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:43:46.296791 (Thread-1): 14:43:46 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:43:46.297102 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:43:46.298162 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:43:46.298383 (MainThread): Using snowflake connection "master".
2021-01-19 13:43:46.298491 (MainThread): On master: BEGIN
2021-01-19 13:43:46.298592 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:43:47.588352 (MainThread): SQL status: SUCCESS 1 in 1.29 seconds
2021-01-19 13:43:47.588583 (MainThread): On master: COMMIT
2021-01-19 13:43:47.588788 (MainThread): Using snowflake connection "master".
2021-01-19 13:43:47.588905 (MainThread): On master: COMMIT
2021-01-19 13:43:47.824432 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 13:43:47.824713 (MainThread): On master: Close
2021-01-19 13:43:48.142513 (MainThread): 14:43:48 | 
2021-01-19 13:43:48.142748 (MainThread): 14:43:48 | Finished running 1 table model, 1 view model in 11.03s.
2021-01-19 13:43:48.142921 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:43:48.143132 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:43:48.150984 (MainThread): 
2021-01-19 13:43:48.151220 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:43:48.151365 (MainThread): 
2021-01-19 13:43:48.151489 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:43:48.151609 (MainThread):   003001 (42501): SQL access control error:
2021-01-19 13:43:48.151716 (MainThread):   Insufficient privileges to operate on schema 'DBT'
2021-01-19 13:43:48.151813 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:43:48.151919 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:43:48.152112 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b8a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bf2910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bf2040>]}
2021-01-19 13:43:48.152335 (MainThread): Flushing usage events
2021-01-19 13:44:50.521732 (MainThread): Running with dbt=0.18.1
2021-01-19 13:44:50.606524 (MainThread): Loading KWallet
2021-01-19 13:44:50.607202 (MainThread): Loading SecretService
2021-01-19 13:44:50.607775 (MainThread): Loading Windows
2021-01-19 13:44:50.608468 (MainThread): Loading chainer
2021-01-19 13:44:50.608798 (MainThread): Loading macOS
2021-01-19 13:44:50.934804 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:44:50.935839 (MainThread): Tracking: tracking
2021-01-19 13:44:50.936206 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060f04c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062ffd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062ff2e0>]}
2021-01-19 13:44:50.979981 (MainThread): Got an acceptable cached parse result
2021-01-19 13:44:51.146318 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:44:51.147849 (MainThread): 
2021-01-19 13:44:51.148697 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:44:51.153865 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:44:51.167868 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:44:51.168420 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:44:51.168615 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:44:53.102684 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.93 seconds
2021-01-19 13:44:53.106735 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:44:53.463158 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:44:53.463461 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "create_analytics_dbt".
2021-01-19 13:44:53.463649 (ThreadPoolExecutor-0_0): Creating schema "analytics.dbt"
2021-01-19 13:44:53.470073 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:44:53.470236 (ThreadPoolExecutor-0_0): On create_analytics_dbt: BEGIN
2021-01-19 13:44:53.470347 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-01-19 13:44:56.629327 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 3.16 seconds
2021-01-19 13:44:56.629588 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:44:56.629738 (ThreadPoolExecutor-0_0): On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
2021-01-19 13:44:56.913353 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 13:44:56.914510 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:44:56.914712 (ThreadPoolExecutor-0_0): Using snowflake connection "create_analytics_dbt".
2021-01-19 13:44:56.914816 (ThreadPoolExecutor-0_0): On create_analytics_dbt: COMMIT
2021-01-19 13:44:57.324863 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 1 in 0.41 seconds
2021-01-19 13:44:57.325074 (ThreadPoolExecutor-0_0): On create_analytics_dbt: Close
2021-01-19 13:44:57.646182 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:44:57.654555 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:44:57.654726 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:44:57.654840 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:44:58.978143 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.32 seconds
2021-01-19 13:44:58.978819 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:44:59.231668 (MainThread): Using snowflake connection "master".
2021-01-19 13:44:59.231861 (MainThread): On master: BEGIN
2021-01-19 13:44:59.231993 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:45:00.367907 (MainThread): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 13:45:00.368246 (MainThread): On master: COMMIT
2021-01-19 13:45:00.368439 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:00.368544 (MainThread): On master: COMMIT
2021-01-19 13:45:00.707032 (MainThread): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 13:45:00.707331 (MainThread): On master: Close
2021-01-19 13:45:01.576730 (MainThread): 14:45:01 | Concurrency: 1 threads (target='dev')
2021-01-19 13:45:01.576971 (MainThread): 14:45:01 | 
2021-01-19 13:45:01.579163 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:45:01.580470 (Thread-1): 14:45:01 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:45:01.580785 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:45:01.580925 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:45:01.613304 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:45:01.613808 (Thread-1): finished collecting timing info
2021-01-19 13:45:01.654980 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:45:01.656277 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:45:01.656419 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:45:01.656536 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:45:03.451487 (Thread-1): SQL status: SUCCESS 1 in 1.79 seconds
2021-01-19 13:45:03.451717 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:45:03.451846 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:45:05.157692 (Thread-1): Snowflake query id: 0199b6f9-069b-83e0-0000-0039890363d9
2021-01-19 13:45:05.157930 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:45:05.158165 (Thread-1): finished collecting timing info
2021-01-19 13:45:05.158558 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:45:05.723630 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:45:06.109816 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:45:06.112460 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bbbdb186-317c-4d54-a8c8-e2625de09ba5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d829d0>]}
2021-01-19 13:45:06.113775 (Thread-1): 14:45:06 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 4.53s]
2021-01-19 13:45:06.113934 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:45:06.114901 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:45:06.115157 (Thread-1): 14:45:06 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:45:06.115401 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:45:06.116881 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:45:06.117295 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:06.117453 (MainThread): On master: BEGIN
2021-01-19 13:45:06.117612 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:45:07.462564 (MainThread): SQL status: SUCCESS 1 in 1.34 seconds
2021-01-19 13:45:07.462796 (MainThread): On master: COMMIT
2021-01-19 13:45:07.463002 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:07.463120 (MainThread): On master: COMMIT
2021-01-19 13:45:07.769274 (MainThread): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 13:45:07.769491 (MainThread): On master: Close
2021-01-19 13:45:08.077628 (MainThread): 14:45:08 | 
2021-01-19 13:45:08.077861 (MainThread): 14:45:08 | Finished running 1 table model, 1 view model in 16.93s.
2021-01-19 13:45:08.078016 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:45:08.078212 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:45:08.086675 (MainThread): 
2021-01-19 13:45:08.086872 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:45:08.087012 (MainThread): 
2021-01-19 13:45:08.087137 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:45:08.087248 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:45:08.087351 (MainThread):   
2021-01-19 13:45:08.087524 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:45:08.087674 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:45:08.087875 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071e7070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071e7a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071e79d0>]}
2021-01-19 13:45:08.088098 (MainThread): Flushing usage events
2021-01-19 13:45:42.120876 (MainThread): Running with dbt=0.18.1
2021-01-19 13:45:42.195534 (MainThread): Loading KWallet
2021-01-19 13:45:42.196200 (MainThread): Loading SecretService
2021-01-19 13:45:42.196690 (MainThread): Loading Windows
2021-01-19 13:45:42.197318 (MainThread): Loading chainer
2021-01-19 13:45:42.197645 (MainThread): Loading macOS
2021-01-19 13:45:42.493484 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:45:42.494405 (MainThread): Tracking: tracking
2021-01-19 13:45:42.494657 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b197760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3a6d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3a62e0>]}
2021-01-19 13:45:42.534459 (MainThread): Got an acceptable cached parse result
2021-01-19 13:45:42.690081 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:45:42.691274 (MainThread): 
2021-01-19 13:45:42.691956 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:45:42.694816 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:45:42.710045 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:45:42.710211 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:45:42.710290 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:45:44.773677 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.06 seconds
2021-01-19 13:45:44.778157 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:45:45.056730 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:45:45.064859 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:45:45.064996 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:45:45.065107 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:45:46.156770 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.09 seconds
2021-01-19 13:45:46.157428 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:45:46.481846 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:46.482044 (MainThread): On master: BEGIN
2021-01-19 13:45:46.482179 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:45:48.016284 (MainThread): SQL status: SUCCESS 1 in 1.53 seconds
2021-01-19 13:45:48.016574 (MainThread): On master: COMMIT
2021-01-19 13:45:48.016835 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:48.016988 (MainThread): On master: COMMIT
2021-01-19 13:45:48.319706 (MainThread): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 13:45:48.320094 (MainThread): On master: Close
2021-01-19 13:45:48.652882 (MainThread): 14:45:48 | Concurrency: 1 threads (target='dev')
2021-01-19 13:45:48.653127 (MainThread): 14:45:48 | 
2021-01-19 13:45:48.655379 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:45:48.656835 (Thread-1): 14:45:48 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:45:48.657191 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:45:48.657347 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:45:48.689421 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:45:48.690013 (Thread-1): finished collecting timing info
2021-01-19 13:45:48.729713 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:45:48.730769 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:45:48.730875 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:45:48.730974 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:45:50.061296 (Thread-1): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-19 13:45:50.061485 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:45:50.061588 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:45:50.368822 (Thread-1): Snowflake query id: 0199b6f9-06d2-b63b-0000-00398903241d
2021-01-19 13:45:50.369065 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:45:50.369402 (Thread-1): finished collecting timing info
2021-01-19 13:45:50.370160 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:45:50.810038 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:45:51.128969 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:45:51.132340 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8ff0d8f-7407-4f0b-9ff4-824c0dff101a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3932e0>]}
2021-01-19 13:45:51.133664 (Thread-1): 14:45:51 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.48s]
2021-01-19 13:45:51.133835 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:45:51.134718 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:45:51.134995 (Thread-1): 14:45:51 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:45:51.135325 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:45:51.136341 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:45:51.136557 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:51.136667 (MainThread): On master: BEGIN
2021-01-19 13:45:51.136768 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:45:52.109770 (MainThread): SQL status: SUCCESS 1 in 0.97 seconds
2021-01-19 13:45:52.110038 (MainThread): On master: COMMIT
2021-01-19 13:45:52.110283 (MainThread): Using snowflake connection "master".
2021-01-19 13:45:52.110427 (MainThread): On master: COMMIT
2021-01-19 13:45:52.330852 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 13:45:52.331133 (MainThread): On master: Close
2021-01-19 13:45:52.702452 (MainThread): 14:45:52 | 
2021-01-19 13:45:52.702697 (MainThread): 14:45:52 | Finished running 1 table model, 1 view model in 10.01s.
2021-01-19 13:45:52.702895 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:45:52.703147 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:45:52.710628 (MainThread): 
2021-01-19 13:45:52.710823 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:45:52.711021 (MainThread): 
2021-01-19 13:45:52.711186 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:45:52.711307 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:45:52.711413 (MainThread):   
2021-01-19 13:45:52.711511 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:45:52.711618 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:45:52.711801 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c347cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c347850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c347b20>]}
2021-01-19 13:45:52.712012 (MainThread): Flushing usage events
2021-01-19 13:46:48.875156 (MainThread): Running with dbt=0.18.1
2021-01-19 13:46:48.952789 (MainThread): Loading KWallet
2021-01-19 13:46:48.953419 (MainThread): Loading SecretService
2021-01-19 13:46:48.953901 (MainThread): Loading Windows
2021-01-19 13:46:48.954531 (MainThread): Loading chainer
2021-01-19 13:46:48.954841 (MainThread): Loading macOS
2021-01-19 13:46:49.250843 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:46:49.252574 (MainThread): Tracking: tracking
2021-01-19 13:46:49.252831 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a157970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088d87c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2890a0>]}
2021-01-19 13:46:49.291416 (MainThread): Got an acceptable cached parse result
2021-01-19 13:46:49.445925 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:46:49.447255 (MainThread): 
2021-01-19 13:46:49.447958 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:46:49.452215 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:46:49.465120 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:46:49.465240 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:46:49.465403 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:46:51.057255 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.59 seconds
2021-01-19 13:46:51.061672 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:46:51.338736 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:46:51.346836 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:46:51.346974 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:46:51.347083 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:46:52.743614 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.40 seconds
2021-01-19 13:46:52.744158 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:46:53.039221 (MainThread): Using snowflake connection "master".
2021-01-19 13:46:53.039414 (MainThread): On master: BEGIN
2021-01-19 13:46:53.039544 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:46:54.366612 (MainThread): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-19 13:46:54.366965 (MainThread): On master: COMMIT
2021-01-19 13:46:54.367320 (MainThread): Using snowflake connection "master".
2021-01-19 13:46:54.367558 (MainThread): On master: COMMIT
2021-01-19 13:46:55.138950 (MainThread): SQL status: SUCCESS 1 in 0.77 seconds
2021-01-19 13:46:55.139195 (MainThread): On master: Close
2021-01-19 13:46:55.464128 (MainThread): 14:46:55 | Concurrency: 1 threads (target='dev')
2021-01-19 13:46:55.464404 (MainThread): 14:46:55 | 
2021-01-19 13:46:55.467267 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:46:55.469244 (Thread-1): 14:46:55 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:46:55.469616 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:46:55.469769 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:46:55.500636 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:46:55.501144 (Thread-1): finished collecting timing info
2021-01-19 13:46:55.536570 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:46:55.537605 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:46:55.537708 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:46:55.537802 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:46:56.750342 (Thread-1): SQL status: SUCCESS 1 in 1.21 seconds
2021-01-19 13:46:56.750610 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:46:56.750765 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:46:57.053037 (Thread-1): Snowflake query id: 0199b6fa-06b9-7e96-0000-00398903742d
2021-01-19 13:46:57.053227 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:46:57.053424 (Thread-1): finished collecting timing info
2021-01-19 13:46:57.053786 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:46:57.275360 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:46:57.583954 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:46:57.587648 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cd2403c-b2e7-4ea5-99f4-13a65b71b561', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1d0190>]}
2021-01-19 13:46:57.589032 (Thread-1): 14:46:57 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 2.12s]
2021-01-19 13:46:57.589203 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:46:57.590377 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:46:57.590640 (Thread-1): 14:46:57 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:46:57.590939 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:46:57.592199 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:46:57.592428 (MainThread): Using snowflake connection "master".
2021-01-19 13:46:57.592538 (MainThread): On master: BEGIN
2021-01-19 13:46:57.592763 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:46:58.648307 (MainThread): SQL status: SUCCESS 1 in 1.06 seconds
2021-01-19 13:46:58.648594 (MainThread): On master: COMMIT
2021-01-19 13:46:58.648845 (MainThread): Using snowflake connection "master".
2021-01-19 13:46:58.648993 (MainThread): On master: COMMIT
2021-01-19 13:46:58.884773 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 13:46:58.885147 (MainThread): On master: Close
2021-01-19 13:46:59.853206 (MainThread): 14:46:59 | 
2021-01-19 13:46:59.853444 (MainThread): 14:46:59 | Finished running 1 table model, 1 view model in 10.41s.
2021-01-19 13:46:59.853644 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:46:59.853764 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:46:59.861297 (MainThread): 
2021-01-19 13:46:59.861470 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:46:59.861607 (MainThread): 
2021-01-19 13:46:59.861730 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:46:59.861843 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:46:59.862026 (MainThread):   
2021-01-19 13:46:59.862154 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:46:59.862277 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:46:59.862471 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1d0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b273fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b273310>]}
2021-01-19 13:46:59.862689 (MainThread): Flushing usage events
2021-01-19 13:48:34.705083 (MainThread): Running with dbt=0.18.1
2021-01-19 13:48:34.782190 (MainThread): Loading KWallet
2021-01-19 13:48:34.782939 (MainThread): Loading SecretService
2021-01-19 13:48:34.783692 (MainThread): Loading Windows
2021-01-19 13:48:34.784574 (MainThread): Loading chainer
2021-01-19 13:48:34.784942 (MainThread): Loading macOS
2021-01-19 13:48:35.077058 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:48:35.078090 (MainThread): Tracking: tracking
2021-01-19 13:48:35.078372 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc96850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dea4040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dea4d90>]}
2021-01-19 13:48:35.117738 (MainThread): Got an acceptable cached parse result
2021-01-19 13:48:35.272955 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:48:35.274390 (MainThread): 
2021-01-19 13:48:35.275218 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:48:35.277795 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:48:35.291682 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:48:35.291805 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:48:35.291889 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:48:37.452487 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.16 seconds
2021-01-19 13:48:37.456952 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:48:38.318737 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:48:38.326935 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:48:38.327078 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:48:38.327189 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:48:39.831882 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 1.50 seconds
2021-01-19 13:48:39.832651 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:48:40.186372 (MainThread): Using snowflake connection "master".
2021-01-19 13:48:40.186542 (MainThread): On master: BEGIN
2021-01-19 13:48:40.186659 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:48:42.454429 (MainThread): SQL status: SUCCESS 1 in 2.27 seconds
2021-01-19 13:48:42.454708 (MainThread): On master: COMMIT
2021-01-19 13:48:42.454968 (MainThread): Using snowflake connection "master".
2021-01-19 13:48:42.455121 (MainThread): On master: COMMIT
2021-01-19 13:48:43.067346 (MainThread): SQL status: SUCCESS 1 in 0.61 seconds
2021-01-19 13:48:43.067582 (MainThread): On master: Close
2021-01-19 13:48:43.633966 (MainThread): 14:48:43 | Concurrency: 1 threads (target='dev')
2021-01-19 13:48:43.634212 (MainThread): 14:48:43 | 
2021-01-19 13:48:43.636290 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:48:43.637657 (Thread-1): 14:48:43 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:48:43.637990 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:48:43.638144 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:48:43.670811 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:48:43.671377 (Thread-1): finished collecting timing info
2021-01-19 13:48:43.709484 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:48:43.710547 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:48:43.710657 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:48:43.710758 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:48:45.884042 (Thread-1): SQL status: SUCCESS 1 in 2.17 seconds
2021-01-19 13:48:45.884255 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:48:45.884377 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:48:46.319974 (Thread-1): Snowflake query id: 0199b6fc-06a2-1b61-0000-003989035445
2021-01-19 13:48:46.320213 (Thread-1): Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

2021-01-19 13:48:46.320455 (Thread-1): finished collecting timing info
2021-01-19 13:48:46.320891 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 13:48:46.600408 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:48:46.909848 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:48:46.913100 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '463404be-1fe0-4438-9c9a-99a339d0a2e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee45c40>]}
2021-01-19 13:48:46.914570 (Thread-1): 14:48:46 | 1 of 2 ERROR creating table model dbt.my_first_dbt_model............. [ERROR in 3.28s]
2021-01-19 13:48:46.914795 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:48:46.915725 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:48:46.916117 (Thread-1): 14:48:46 | 2 of 2 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 13:48:46.916367 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:48:46.917365 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:48:46.917584 (MainThread): Using snowflake connection "master".
2021-01-19 13:48:46.917689 (MainThread): On master: BEGIN
2021-01-19 13:48:46.917792 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:48:48.854259 (MainThread): SQL status: SUCCESS 1 in 1.94 seconds
2021-01-19 13:48:48.854531 (MainThread): On master: COMMIT
2021-01-19 13:48:48.854783 (MainThread): Using snowflake connection "master".
2021-01-19 13:48:48.854936 (MainThread): On master: COMMIT
2021-01-19 13:48:49.082142 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 13:48:49.082386 (MainThread): On master: Close
2021-01-19 13:48:49.369309 (MainThread): 14:48:49 | 
2021-01-19 13:48:49.369541 (MainThread): 14:48:49 | Finished running 1 table model, 1 view model in 14.09s.
2021-01-19 13:48:49.369779 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:48:49.369961 (MainThread): Connection 'model.dbt_learn.my_first_dbt_model' was properly closed.
2021-01-19 13:48:49.377116 (MainThread): 
2021-01-19 13:48:49.377290 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 13:48:49.377426 (MainThread): 
2021-01-19 13:48:49.377549 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 13:48:49.377662 (MainThread):   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
2021-01-19 13:48:49.377767 (MainThread):   
2021-01-19 13:48:49.377864 (MainThread):   compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 13:48:49.378040 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-01-19 13:48:49.378256 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee4a2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee4af40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee4ac10>]}
2021-01-19 13:48:49.378481 (MainThread): Flushing usage events
2021-01-19 13:51:57.663751 (MainThread): Running with dbt=0.18.1
2021-01-19 13:51:57.734671 (MainThread): Loading KWallet
2021-01-19 13:51:57.735187 (MainThread): Loading SecretService
2021-01-19 13:51:57.735589 (MainThread): Loading Windows
2021-01-19 13:51:57.736190 (MainThread): Loading chainer
2021-01-19 13:51:57.736536 (MainThread): Loading macOS
2021-01-19 13:51:58.024628 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 13:51:58.026500 (MainThread): Tracking: tracking
2021-01-19 13:51:58.027161 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106241880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106450d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106450df0>]}
2021-01-19 13:51:58.061538 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 13:51:58.062566 (MainThread): Parsing macros/catalog.sql
2021-01-19 13:51:58.064654 (MainThread): Parsing macros/adapters.sql
2021-01-19 13:51:58.093136 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 13:51:58.095760 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 13:51:58.097170 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 13:51:58.100891 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 13:51:58.112496 (MainThread): Parsing macros/core.sql
2021-01-19 13:51:58.116155 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 13:51:58.125010 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 13:51:58.128014 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 13:51:58.145173 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 13:51:58.173387 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 13:51:58.195298 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 13:51:58.197081 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 13:51:58.202896 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 13:51:58.217119 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 13:51:58.223795 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 13:51:58.230925 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 13:51:58.235582 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 13:51:58.236457 (MainThread): Parsing macros/etc/query.sql
2021-01-19 13:51:58.237430 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 13:51:58.238931 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 13:51:58.249171 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 13:51:58.251055 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 13:51:58.252632 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 13:51:58.294863 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 13:51:58.296630 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 13:51:58.298021 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 13:51:58.299613 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 13:51:58.308069 (MainThread): profile hash mismatch, cache invalidated
2021-01-19 13:51:58.346756 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:51:58.366539 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 13:51:58.578687 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 13:51:58.580820 (MainThread): 
2021-01-19 13:51:58.581874 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:51:58.587325 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 13:51:58.603571 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 13:51:58.603732 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 13:51:58.603832 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 13:52:00.527466 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.92 seconds
2021-01-19 13:52:00.532098 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 13:52:00.978565 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 13:52:00.986408 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 13:52:00.986535 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 13:52:00.986639 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 13:52:03.263889 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 2.28 seconds
2021-01-19 13:52:03.264477 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 13:52:03.868128 (MainThread): Using snowflake connection "master".
2021-01-19 13:52:03.868318 (MainThread): On master: BEGIN
2021-01-19 13:52:03.868449 (MainThread): Opening a new connection, currently in state init
2021-01-19 13:52:04.950416 (MainThread): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 13:52:04.950684 (MainThread): On master: COMMIT
2021-01-19 13:52:04.950944 (MainThread): Using snowflake connection "master".
2021-01-19 13:52:04.951090 (MainThread): On master: COMMIT
2021-01-19 13:52:05.256767 (MainThread): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 13:52:05.257057 (MainThread): On master: Close
2021-01-19 13:52:05.590832 (MainThread): 14:52:05 | Concurrency: 1 threads (target='dev')
2021-01-19 13:52:05.591085 (MainThread): 14:52:05 | 
2021-01-19 13:52:05.594756 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:52:05.596199 (Thread-1): 14:52:05 | 1 of 2 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 13:52:05.596555 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:52:05.596694 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 13:52:05.619293 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:52:05.619822 (Thread-1): finished collecting timing info
2021-01-19 13:52:05.656401 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 13:52:05.657461 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:52:05.657565 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 13:52:05.657661 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:52:06.792638 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2021-01-19 13:52:06.792897 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:52:06.793044 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 13:52:09.865038 (Thread-1): SQL status: SUCCESS 1 in 3.07 seconds
2021-01-19 13:52:09.866738 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 13:52:09.866972 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 13:52:09.867094 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 13:52:10.069801 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 13:52:10.085503 (Thread-1): finished collecting timing info
2021-01-19 13:52:10.085811 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 13:52:10.480300 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a488cb9-ecf1-406e-adb9-4c8ea4e741e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070a2730>]}
2021-01-19 13:52:10.481848 (Thread-1): 14:52:10 | 1 of 2 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 4.88s]
2021-01-19 13:52:10.482043 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 13:52:10.482753 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:52:10.484252 (Thread-1): 14:52:10 | 2 of 2 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 13:52:10.484648 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 13:52:10.484779 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 13:52:10.493526 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 13:52:10.493969 (Thread-1): finished collecting timing info
2021-01-19 13:52:10.516372 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 13:52:10.517228 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 13:52:10.517335 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 13:52:10.517427 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 13:52:11.708274 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-01-19 13:52:11.708597 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 13:52:11.708821 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 13:52:12.475985 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2021-01-19 13:52:12.477547 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 13:52:12.477819 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 13:52:12.477964 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 13:52:12.875596 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2021-01-19 13:52:12.880523 (Thread-1): finished collecting timing info
2021-01-19 13:52:12.880881 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 13:52:13.182825 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a488cb9-ecf1-406e-adb9-4c8ea4e741e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d34c0>]}
2021-01-19 13:52:13.184363 (Thread-1): 14:52:13 | 2 of 2 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.70s]
2021-01-19 13:52:13.184528 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 13:52:13.185859 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 13:52:13.186127 (MainThread): Using snowflake connection "master".
2021-01-19 13:52:13.186255 (MainThread): On master: BEGIN
2021-01-19 13:52:13.186369 (MainThread): Opening a new connection, currently in state closed
2021-01-19 13:52:15.003038 (MainThread): SQL status: SUCCESS 1 in 1.82 seconds
2021-01-19 13:52:15.003263 (MainThread): On master: COMMIT
2021-01-19 13:52:15.003465 (MainThread): Using snowflake connection "master".
2021-01-19 13:52:15.003582 (MainThread): On master: COMMIT
2021-01-19 13:52:15.547474 (MainThread): SQL status: SUCCESS 1 in 0.54 seconds
2021-01-19 13:52:15.547713 (MainThread): On master: Close
2021-01-19 13:52:15.948256 (MainThread): 14:52:15 | 
2021-01-19 13:52:15.948499 (MainThread): 14:52:15 | Finished running 1 table model, 1 view model in 17.37s.
2021-01-19 13:52:15.948698 (MainThread): Connection 'master' was properly closed.
2021-01-19 13:52:15.949072 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 13:52:15.957116 (MainThread): 
2021-01-19 13:52:15.957289 (MainThread): Completed successfully
2021-01-19 13:52:15.957421 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-01-19 13:52:15.957620 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106450550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107114220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107114b50>]}
2021-01-19 13:52:15.957844 (MainThread): Flushing usage events
2021-01-19 14:02:18.889607 (MainThread): Running with dbt=0.18.1
2021-01-19 14:02:18.965971 (MainThread): Loading KWallet
2021-01-19 14:02:18.966639 (MainThread): Loading SecretService
2021-01-19 14:02:18.967130 (MainThread): Loading Windows
2021-01-19 14:02:18.967759 (MainThread): Loading chainer
2021-01-19 14:02:18.968077 (MainThread): Loading macOS
2021-01-19 14:02:19.260635 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:02:19.261537 (MainThread): Tracking: tracking
2021-01-19 14:02:19.262003 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109919760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b28d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b282e0>]}
2021-01-19 14:02:19.300553 (MainThread): Got an acceptable cached parse result
2021-01-19 14:02:19.338392 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:02:19.598617 (MainThread): Found 3 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:02:19.600903 (MainThread): 
2021-01-19 14:02:19.601588 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:02:19.605222 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:02:19.620068 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:02:19.620222 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:02:19.620326 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:02:21.651756 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.03 seconds
2021-01-19 14:02:21.656269 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:02:22.179571 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:02:22.187841 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:02:22.187989 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:02:22.188099 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:02:23.473474 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 2 in 1.29 seconds
2021-01-19 14:02:23.477107 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:02:23.748846 (MainThread): Using snowflake connection "master".
2021-01-19 14:02:23.749040 (MainThread): On master: BEGIN
2021-01-19 14:02:23.749168 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:02:25.550436 (MainThread): SQL status: SUCCESS 1 in 1.80 seconds
2021-01-19 14:02:25.550635 (MainThread): On master: COMMIT
2021-01-19 14:02:25.550813 (MainThread): Using snowflake connection "master".
2021-01-19 14:02:25.550911 (MainThread): On master: COMMIT
2021-01-19 14:02:26.415147 (MainThread): SQL status: SUCCESS 1 in 0.86 seconds
2021-01-19 14:02:26.415447 (MainThread): On master: Close
2021-01-19 14:02:26.716236 (MainThread): 15:02:26 | Concurrency: 1 threads (target='dev')
2021-01-19 14:02:26.716475 (MainThread): 15:02:26 | 
2021-01-19 14:02:26.718763 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:02:26.720400 (Thread-1): 15:02:26 | 1 of 3 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:02:26.720753 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:02:26.720892 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:02:26.744018 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:02:26.744517 (Thread-1): finished collecting timing info
2021-01-19 14:02:26.780895 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:02:26.781963 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:02:26.782070 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:02:26.782167 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:02:27.617703 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-01-19 14:02:27.617902 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:02:27.618006 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:02:29.745769 (Thread-1): SQL status: SUCCESS 1 in 2.13 seconds
2021-01-19 14:02:29.747141 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:02:29.747353 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:02:29.747472 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:02:29.919713 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:02:29.934089 (Thread-1): finished collecting timing info
2021-01-19 14:02:29.934415 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:02:30.198185 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31fd5ed-182d-40e8-a0c4-32d8b2fbe37f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5d0700>]}
2021-01-19 14:02:30.199489 (Thread-1): 15:02:30 | 1 of 3 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 3.48s]
2021-01-19 14:02:30.199652 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:02:30.199806 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:02:30.201346 (Thread-1): 15:02:30 | 2 of 3 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:02:30.201785 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:02:30.201915 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:02:30.210707 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:02:30.211163 (Thread-1): finished collecting timing info
2021-01-19 14:02:30.216045 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:02:30.217303 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:02:30.217427 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:02:30.217537 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:02:31.687569 (Thread-1): SQL status: SUCCESS 1 in 1.47 seconds
2021-01-19 14:02:31.687828 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:02:31.687981 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:02:34.967617 (Thread-1): SQL status: SUCCESS 1 in 3.28 seconds
2021-01-19 14:02:34.969087 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:02:34.969294 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:02:34.969414 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:02:35.134697 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:02:35.137681 (Thread-1): finished collecting timing info
2021-01-19 14:02:35.138015 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:02:35.398020 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31fd5ed-182d-40e8-a0c4-32d8b2fbe37f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5d0a90>]}
2021-01-19 14:02:35.399496 (Thread-1): 15:02:35 | 2 of 3 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 5.20s]
2021-01-19 14:02:35.399665 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:02:35.399828 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:02:35.401619 (Thread-1): 15:02:35 | 3 of 3 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 14:02:35.402004 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:02:35.402137 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:02:35.411876 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:02:35.412392 (Thread-1): finished collecting timing info
2021-01-19 14:02:35.436354 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:02:35.437276 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:02:35.437391 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:02:35.437496 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:02:36.690641 (Thread-1): SQL status: SUCCESS 1 in 1.25 seconds
2021-01-19 14:02:36.690923 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:02:36.691081 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 14:02:37.223918 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-01-19 14:02:37.225527 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:02:37.225797 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:02:37.225919 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:02:37.524347 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 14:02:37.529254 (Thread-1): finished collecting timing info
2021-01-19 14:02:37.529576 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:02:37.859365 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c31fd5ed-182d-40e8-a0c4-32d8b2fbe37f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aacea00>]}
2021-01-19 14:02:37.860696 (Thread-1): 15:02:37 | 3 of 3 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.46s]
2021-01-19 14:02:37.860882 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:02:37.862357 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:02:37.862618 (MainThread): Using snowflake connection "master".
2021-01-19 14:02:37.862730 (MainThread): On master: BEGIN
2021-01-19 14:02:37.862837 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:02:39.650227 (MainThread): SQL status: SUCCESS 1 in 1.79 seconds
2021-01-19 14:02:39.650434 (MainThread): On master: COMMIT
2021-01-19 14:02:39.650612 (MainThread): Using snowflake connection "master".
2021-01-19 14:02:39.650712 (MainThread): On master: COMMIT
2021-01-19 14:02:39.981619 (MainThread): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 14:02:39.981922 (MainThread): On master: Close
2021-01-19 14:02:40.247250 (MainThread): 15:02:40 | 
2021-01-19 14:02:40.247458 (MainThread): 15:02:40 | Finished running 2 table models, 1 view model in 20.65s.
2021-01-19 14:02:40.247591 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:02:40.247750 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:02:40.260016 (MainThread): 
2021-01-19 14:02:40.260199 (MainThread): Completed successfully
2021-01-19 14:02:40.260331 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-01-19 14:02:40.260524 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a625fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a817340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a817880>]}
2021-01-19 14:02:40.260736 (MainThread): Flushing usage events
2021-01-19 14:17:01.195845 (MainThread): Running with dbt=0.18.1
2021-01-19 14:17:01.271304 (MainThread): Loading KWallet
2021-01-19 14:17:01.271910 (MainThread): Loading SecretService
2021-01-19 14:17:01.272360 (MainThread): Loading Windows
2021-01-19 14:17:01.272965 (MainThread): Loading chainer
2021-01-19 14:17:01.273277 (MainThread): Loading macOS
2021-01-19 14:17:01.561492 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:17:01.562519 (MainThread): Tracking: tracking
2021-01-19 14:17:01.562795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113f7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc8f7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115290a0>]}
2021-01-19 14:17:01.602875 (MainThread): Got an acceptable cached parse result
2021-01-19 14:17:01.640343 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_cumulative_orders_by_date".
2021-01-19 14:17:01.932728 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:17:01.935134 (MainThread): 
2021-01-19 14:17:01.936035 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:17:01.941366 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:17:01.956412 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:17:01.956534 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:17:01.956613 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:17:04.748070 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.79 seconds
2021-01-19 14:17:04.753402 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:17:05.386645 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:17:05.438270 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:17:05.438441 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:17:05.438553 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:17:07.180338 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 3 in 1.74 seconds
2021-01-19 14:17:07.185658 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:17:07.464308 (MainThread): Using snowflake connection "master".
2021-01-19 14:17:07.464508 (MainThread): On master: BEGIN
2021-01-19 14:17:07.464644 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:17:08.304737 (MainThread): SQL status: SUCCESS 1 in 0.84 seconds
2021-01-19 14:17:08.304929 (MainThread): On master: COMMIT
2021-01-19 14:17:08.305096 (MainThread): Using snowflake connection "master".
2021-01-19 14:17:08.305193 (MainThread): On master: COMMIT
2021-01-19 14:17:08.696093 (MainThread): SQL status: SUCCESS 1 in 0.39 seconds
2021-01-19 14:17:08.696373 (MainThread): On master: Close
2021-01-19 14:17:09.029958 (MainThread): 15:17:09 | Concurrency: 1 threads (target='dev')
2021-01-19 14:17:09.030201 (MainThread): 15:17:09 | 
2021-01-19 14:17:09.033061 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:17:09.035234 (Thread-1): 15:17:09 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:17:09.035609 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:17:09.035749 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:17:09.059003 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:17:09.059497 (Thread-1): finished collecting timing info
2021-01-19 14:17:09.095195 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:17:09.096223 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:17:09.096324 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:17:09.096430 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:17:09.978681 (Thread-1): SQL status: SUCCESS 1 in 0.88 seconds
2021-01-19 14:17:09.978944 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:17:09.979100 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:17:11.560973 (Thread-1): SQL status: SUCCESS 1 in 1.58 seconds
2021-01-19 14:17:11.562851 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:17:11.563132 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:17:11.563261 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:17:11.735966 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:17:11.750425 (Thread-1): finished collecting timing info
2021-01-19 14:17:11.750879 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:17:12.039504 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3880a151-8697-4d64-88c9-3f54b020b054', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11238aeb0>]}
2021-01-19 14:17:12.040859 (Thread-1): 15:17:12 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 3.00s]
2021-01-19 14:17:12.041034 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:17:12.041199 (Thread-1): Began running node model.dbt_learn.snowflake_cumulative_orders_by_date
2021-01-19 14:17:12.042953 (Thread-1): 15:17:12 | 2 of 4 START table model dbt.snowflake_cumulative_orders_by_date..... [RUN]
2021-01-19 14:17:12.043418 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_cumulative_orders_by_date".
2021-01-19 14:17:12.043559 (Thread-1): Compiling model.dbt_learn.snowflake_cumulative_orders_by_date
2021-01-19 14:17:12.052763 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_cumulative_orders_by_date"
2021-01-19 14:17:12.053255 (Thread-1): finished collecting timing info
2021-01-19 14:17:12.058080 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_cumulative_orders_by_date"
2021-01-19 14:17:12.059278 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_cumulative_orders_by_date".
2021-01-19 14:17:12.059390 (Thread-1): On model.dbt_learn.snowflake_cumulative_orders_by_date: BEGIN
2021-01-19 14:17:12.059496 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:17:13.084323 (Thread-1): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-19 14:17:13.084544 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_cumulative_orders_by_date".
2021-01-19 14:17:13.084670 (Thread-1): On model.dbt_learn.snowflake_cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_orders_by_date  as
      (

WITH AUXILIAR AS (
SELECT o_orderdate as date, sum(o_totalprice) as orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
GROUP BY o_orderdate)

SELECT
  date,
  sum(orders) over (partition by NULL order by date ASC rows unbounded preceding) as cumulative_orders
  FROM auxiliar
  order by date desc
      );
2021-01-19 14:17:14.622699 (Thread-1): SQL status: SUCCESS 1 in 1.54 seconds
2021-01-19 14:17:14.624243 (Thread-1): On model.dbt_learn.snowflake_cumulative_orders_by_date: COMMIT
2021-01-19 14:17:14.624511 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_cumulative_orders_by_date".
2021-01-19 14:17:14.624632 (Thread-1): On model.dbt_learn.snowflake_cumulative_orders_by_date: COMMIT
2021-01-19 14:17:15.134341 (Thread-1): SQL status: SUCCESS 1 in 0.51 seconds
2021-01-19 14:17:15.137121 (Thread-1): finished collecting timing info
2021-01-19 14:17:15.137482 (Thread-1): On model.dbt_learn.snowflake_cumulative_orders_by_date: Close
2021-01-19 14:17:15.393522 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3880a151-8697-4d64-88c9-3f54b020b054', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125ecdf0>]}
2021-01-19 14:17:15.395056 (Thread-1): 15:17:15 | 2 of 4 OK created table model dbt.snowflake_cumulative_orders_by_date [SUCCESS 1 in 3.35s]
2021-01-19 14:17:15.395253 (Thread-1): Finished running node model.dbt_learn.snowflake_cumulative_orders_by_date
2021-01-19 14:17:15.395443 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:17:15.397297 (Thread-1): 15:17:15 | 3 of 4 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:17:15.397630 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:17:15.397757 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:17:15.406529 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:17:15.407048 (Thread-1): finished collecting timing info
2021-01-19 14:17:15.412033 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:17:15.413262 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:17:15.413382 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:17:15.413491 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:17:16.431793 (Thread-1): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-19 14:17:16.432068 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:17:16.432237 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:17:18.515531 (Thread-1): SQL status: SUCCESS 1 in 2.08 seconds
2021-01-19 14:17:18.517164 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:17:18.517424 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:17:18.517545 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:17:18.667853 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:17:18.670668 (Thread-1): finished collecting timing info
2021-01-19 14:17:18.671010 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:17:18.930682 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3880a151-8697-4d64-88c9-3f54b020b054', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11233d250>]}
2021-01-19 14:17:18.933449 (Thread-1): 15:17:18 | 3 of 4 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.53s]
2021-01-19 14:17:18.933669 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:17:18.933832 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:17:18.935438 (Thread-1): 15:17:18 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 14:17:18.935891 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:17:18.936036 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:17:18.945905 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:17:18.946389 (Thread-1): finished collecting timing info
2021-01-19 14:17:18.971517 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:17:18.972433 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:17:18.972551 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:17:18.972662 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:17:19.982204 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-01-19 14:17:19.982560 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:17:19.982731 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 14:17:21.281119 (Thread-1): SQL status: SUCCESS 1 in 1.30 seconds
2021-01-19 14:17:21.282973 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:17:21.283233 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:17:21.283507 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:17:21.484767 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 14:17:21.488967 (Thread-1): finished collecting timing info
2021-01-19 14:17:21.489254 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:17:21.801174 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3880a151-8697-4d64-88c9-3f54b020b054', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122eefa0>]}
2021-01-19 14:17:21.802727 (Thread-1): 15:17:21 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.87s]
2021-01-19 14:17:21.802928 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:17:21.804488 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:17:21.804721 (MainThread): Using snowflake connection "master".
2021-01-19 14:17:21.804825 (MainThread): On master: BEGIN
2021-01-19 14:17:21.804928 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:17:23.941616 (MainThread): SQL status: SUCCESS 1 in 2.14 seconds
2021-01-19 14:17:23.941897 (MainThread): On master: COMMIT
2021-01-19 14:17:23.942147 (MainThread): Using snowflake connection "master".
2021-01-19 14:17:23.942298 (MainThread): On master: COMMIT
2021-01-19 14:17:24.384691 (MainThread): SQL status: SUCCESS 1 in 0.44 seconds
2021-01-19 14:17:24.384927 (MainThread): On master: Close
2021-01-19 14:17:24.685566 (MainThread): 15:17:24 | 
2021-01-19 14:17:24.685805 (MainThread): 15:17:24 | Finished running 3 table models, 1 view model in 22.75s.
2021-01-19 14:17:24.686000 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:17:24.686121 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:17:24.700920 (MainThread): 
2021-01-19 14:17:24.701110 (MainThread): Completed successfully
2021-01-19 14:17:24.701248 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:17:24.701444 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11263bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11208e370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122f9490>]}
2021-01-19 14:17:24.701666 (MainThread): Flushing usage events
2021-01-19 14:18:10.355107 (MainThread): Running with dbt=0.18.1
2021-01-19 14:18:10.430211 (MainThread): Loading KWallet
2021-01-19 14:18:10.431035 (MainThread): Loading SecretService
2021-01-19 14:18:10.431584 (MainThread): Loading Windows
2021-01-19 14:18:10.432294 (MainThread): Loading chainer
2021-01-19 14:18:10.432626 (MainThread): Loading macOS
2021-01-19 14:18:10.726927 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:18:10.727882 (MainThread): Tracking: tracking
2021-01-19 14:18:10.728160 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a68eee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a89d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a89d0d0>]}
2021-01-19 14:18:10.768143 (MainThread): Got an acceptable cached parse result
2021-01-19 14:18:10.805248 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:10.881014 (MainThread): WARNING: Found documentation for resource "snowflake_cumulative_orders_by_date" which was not found or is disabled
2021-01-19 14:18:10.881622 (MainThread): [WARNING]: Test 'test.dbt_learn.unique_snowflake_cumulative_orders_by_date_date' (models/example/schema.yml) depends on a node named 'snowflake_cumulative_orders_by_date' which was not found
2021-01-19 14:18:10.881867 (MainThread): [WARNING]: Test 'test.dbt_learn.not_null_snowflake_cumulative_orders_by_date_date' (models/example/schema.yml) depends on a node named 'snowflake_cumulative_orders_by_date' which was not found
2021-01-19 14:18:10.982023 (MainThread): Found 4 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:18:10.982974 (MainThread): 
2021-01-19 14:18:10.983277 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:18:10.988337 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:18:11.003086 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:18:11.003218 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:18:11.003310 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:18:12.444206 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.44 seconds
2021-01-19 14:18:12.449668 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:18:13.241552 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:18:13.250329 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:18:13.250499 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:18:13.250611 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:18:14.667918 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.42 seconds
2021-01-19 14:18:14.672585 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:18:15.144568 (MainThread): Using snowflake connection "master".
2021-01-19 14:18:15.144762 (MainThread): On master: BEGIN
2021-01-19 14:18:15.144893 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:18:15.998093 (MainThread): SQL status: SUCCESS 1 in 0.85 seconds
2021-01-19 14:18:15.998377 (MainThread): On master: COMMIT
2021-01-19 14:18:15.998626 (MainThread): Using snowflake connection "master".
2021-01-19 14:18:15.998815 (MainThread): On master: COMMIT
2021-01-19 14:18:16.512283 (MainThread): SQL status: SUCCESS 1 in 0.51 seconds
2021-01-19 14:18:16.512567 (MainThread): On master: Close
2021-01-19 14:18:16.811011 (MainThread): 15:18:16 | Concurrency: 1 threads (target='dev')
2021-01-19 14:18:16.811248 (MainThread): 15:18:16 | 
2021-01-19 14:18:16.813546 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:18:16.815380 (Thread-1): 15:18:16 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:18:16.815750 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:16.815903 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:18:16.839813 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:18:16.840319 (Thread-1): finished collecting timing info
2021-01-19 14:18:16.877240 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:18:16.878248 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:16.878354 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:18:16.878446 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:18:17.931334 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-01-19 14:18:17.931599 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:17.931762 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:18:19.197732 (Thread-1): SQL status: SUCCESS 1 in 1.27 seconds
2021-01-19 14:18:19.199461 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:18:19.199736 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:19.199857 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:18:19.400604 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 14:18:19.415539 (Thread-1): finished collecting timing info
2021-01-19 14:18:19.415849 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:18:19.748974 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6b13121-7af9-4352-9b70-99315d65698d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6cd0a0>]}
2021-01-19 14:18:19.750671 (Thread-1): 15:18:19 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 2.93s]
2021-01-19 14:18:19.750879 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:18:19.751082 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:18:19.752759 (Thread-1): 15:18:19 | 2 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:18:19.753210 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:19.753355 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:18:19.760895 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:18:19.761342 (Thread-1): finished collecting timing info
2021-01-19 14:18:19.766630 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:18:19.768014 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:19.768145 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:18:19.768257 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:18:20.279804 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:18:20.280036 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:18:20.976064 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:18:20.976262 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 14:18:20.976384 (MainThread): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:18:21.087765 (Thread-1): SQL status: SUCCESS 1 in 1.32 seconds
2021-01-19 14:18:21.087943 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:21.088043 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

WITH AUXILIAR AS (
SELECT o_orderdate as date, sum(o_totalprice) as orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
GROUP BY o_orderdate)

SELECT
  date,
  sum(orders) over (partition by NULL order by date ASC rows unbounded preceding) as cumulative_orders
  FROM auxiliar
  order by date desc
      );
2021-01-19 14:18:21.334470 (MainThread): Flushing usage events
2021-01-19 14:18:21.585199 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:18:21.585407 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 14:18:21.585527 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 14:18:22.347311 (Thread-1): SQL status: SUCCESS 1 in 1.26 seconds
2021-01-19 14:18:45.086554 (MainThread): Running with dbt=0.18.1
2021-01-19 14:18:45.161320 (MainThread): Loading KWallet
2021-01-19 14:18:45.161882 (MainThread): Loading SecretService
2021-01-19 14:18:45.162300 (MainThread): Loading Windows
2021-01-19 14:18:45.162850 (MainThread): Loading chainer
2021-01-19 14:18:45.163163 (MainThread): Loading macOS
2021-01-19 14:18:45.456405 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:18:45.457331 (MainThread): Tracking: tracking
2021-01-19 14:18:45.457563 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b722760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b931d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9312e0>]}
2021-01-19 14:18:45.494658 (MainThread): Got an acceptable cached parse result
2021-01-19 14:18:45.811321 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:18:45.813501 (MainThread): 
2021-01-19 14:18:45.814443 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:18:45.823661 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:18:45.838666 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:18:45.838804 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:18:45.838893 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:18:48.527000 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.69 seconds
2021-01-19 14:18:48.532572 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:18:49.337385 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:18:49.386983 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:18:49.387157 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:18:49.387269 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:18:51.083934 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 1.70 seconds
2021-01-19 14:18:51.089657 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:18:51.367620 (MainThread): Using snowflake connection "master".
2021-01-19 14:18:51.367817 (MainThread): On master: BEGIN
2021-01-19 14:18:51.367948 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:18:53.101790 (MainThread): SQL status: SUCCESS 1 in 1.73 seconds
2021-01-19 14:18:53.102062 (MainThread): On master: COMMIT
2021-01-19 14:18:53.102321 (MainThread): Using snowflake connection "master".
2021-01-19 14:18:53.102457 (MainThread): On master: COMMIT
2021-01-19 14:18:53.382279 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 14:18:53.382568 (MainThread): On master: Close
2021-01-19 14:18:53.698155 (MainThread): 15:18:53 | Concurrency: 1 threads (target='dev')
2021-01-19 14:18:53.698396 (MainThread): 15:18:53 | 
2021-01-19 14:18:53.700478 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:18:53.701870 (Thread-1): 15:18:53 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:18:53.702203 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:53.702339 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:18:53.733820 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:18:53.734405 (Thread-1): finished collecting timing info
2021-01-19 14:18:53.771160 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:18:53.772319 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:53.772435 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:18:53.772539 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:18:54.957719 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-01-19 14:18:54.957980 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:54.958129 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:18:56.563129 (Thread-1): SQL status: SUCCESS 1 in 1.60 seconds
2021-01-19 14:18:56.564899 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:18:56.565166 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:18:56.565310 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:18:56.960850 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2021-01-19 14:18:56.976639 (Thread-1): finished collecting timing info
2021-01-19 14:18:56.976960 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:18:57.317020 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8a0a922-8148-4681-829a-0ecef30d9cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5fedf0>]}
2021-01-19 14:18:57.318602 (Thread-1): 15:18:57 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 3.61s]
2021-01-19 14:18:57.318795 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:18:57.318981 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:18:57.320733 (Thread-1): 15:18:57 | 2 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:18:57.321065 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:57.321194 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:18:57.329534 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:18:57.330015 (Thread-1): finished collecting timing info
2021-01-19 14:18:57.335306 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:18:57.336590 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:57.336708 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:18:57.336814 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:18:58.246901 (Thread-1): SQL status: SUCCESS 1 in 0.91 seconds
2021-01-19 14:18:58.247169 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:58.247355 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (

WITH AUXILIAR AS (
SELECT o_orderdate as date, sum(o_totalprice) as orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
GROUP BY o_orderdate)

SELECT
  date,
  sum(orders) over (partition by NULL order by date ASC rows unbounded preceding) as cumulative_orders
  FROM auxiliar
  order by date desc
      );
2021-01-19 14:18:59.378602 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2021-01-19 14:18:59.380220 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:18:59.380484 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:18:59.380613 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:18:59.537856 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:18:59.540900 (Thread-1): finished collecting timing info
2021-01-19 14:18:59.541237 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:18:59.805235 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8a0a922-8148-4681-829a-0ecef30d9cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7090d0>]}
2021-01-19 14:18:59.806768 (Thread-1): 15:18:59 | 2 of 4 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 2.48s]
2021-01-19 14:18:59.806933 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:18:59.807093 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:18:59.808585 (Thread-1): 15:18:59 | 3 of 4 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:18:59.809043 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:18:59.809183 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:18:59.818822 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:18:59.819316 (Thread-1): finished collecting timing info
2021-01-19 14:18:59.824182 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:18:59.825339 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:18:59.825453 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:18:59.825558 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:19:00.958064 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2021-01-19 14:19:00.958334 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:19:00.958489 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:19:02.565880 (Thread-1): SQL status: SUCCESS 1 in 1.61 seconds
2021-01-19 14:19:02.567001 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:19:02.567179 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:19:02.567276 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:19:02.723127 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:19:02.726184 (Thread-1): finished collecting timing info
2021-01-19 14:19:02.726506 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:19:03.037185 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8a0a922-8148-4681-829a-0ecef30d9cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c424790>]}
2021-01-19 14:19:03.038270 (Thread-1): 15:19:03 | 3 of 4 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.23s]
2021-01-19 14:19:03.038399 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:19:03.038524 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:19:03.039664 (Thread-1): 15:19:03 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 14:19:03.039958 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:19:03.040087 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:19:03.048579 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:19:03.048969 (Thread-1): finished collecting timing info
2021-01-19 14:19:03.068636 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:19:03.069290 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:19:03.069371 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:19:03.069445 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:19:04.003306 (Thread-1): SQL status: SUCCESS 1 in 0.93 seconds
2021-01-19 14:19:04.003516 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:19:04.003639 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 14:19:04.396917 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2021-01-19 14:19:04.398441 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:19:04.398712 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:19:04.398853 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:19:04.706262 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 14:19:04.710970 (Thread-1): finished collecting timing info
2021-01-19 14:19:04.711293 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:19:05.011406 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8a0a922-8148-4681-829a-0ecef30d9cb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6272e0>]}
2021-01-19 14:19:05.013030 (Thread-1): 15:19:05 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 1.97s]
2021-01-19 14:19:05.013318 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:19:05.015678 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:19:05.016046 (MainThread): Using snowflake connection "master".
2021-01-19 14:19:05.016338 (MainThread): On master: BEGIN
2021-01-19 14:19:05.016540 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:19:06.169525 (MainThread): SQL status: SUCCESS 1 in 1.15 seconds
2021-01-19 14:19:06.169755 (MainThread): On master: COMMIT
2021-01-19 14:19:06.169956 (MainThread): Using snowflake connection "master".
2021-01-19 14:19:06.170074 (MainThread): On master: COMMIT
2021-01-19 14:19:06.514011 (MainThread): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 14:19:06.514354 (MainThread): On master: Close
2021-01-19 14:19:06.845385 (MainThread): 15:19:06 | 
2021-01-19 14:19:06.845617 (MainThread): 15:19:06 | Finished running 3 table models, 1 view model in 21.03s.
2021-01-19 14:19:06.845772 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:19:06.845924 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:19:06.862089 (MainThread): 
2021-01-19 14:19:06.862291 (MainThread): Completed successfully
2021-01-19 14:19:06.862515 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:19:06.862801 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c725730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c471ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c471910>]}
2021-01-19 14:19:06.863117 (MainThread): Flushing usage events
2021-01-19 14:30:19.703675 (MainThread): Running with dbt=0.18.1
2021-01-19 14:30:19.791194 (MainThread): Loading KWallet
2021-01-19 14:30:19.791897 (MainThread): Loading SecretService
2021-01-19 14:30:19.792426 (MainThread): Loading Windows
2021-01-19 14:30:19.793093 (MainThread): Loading chainer
2021-01-19 14:30:19.793426 (MainThread): Loading macOS
2021-01-19 14:30:20.139705 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:30:20.141164 (MainThread): Tracking: tracking
2021-01-19 14:30:20.141490 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cadb850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccea040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccead90>]}
2021-01-19 14:30:20.198091 (MainThread): Got an acceptable cached parse result
2021-01-19 14:30:20.245976 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:30:20.270332 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:30:20.283933 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:30:20.297460 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:30:20.454735 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:30:20.456190 (MainThread): 
2021-01-19 14:30:20.456771 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:30:20.461769 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:30:20.474962 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:30:20.475115 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:30:20.475205 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:30:22.124486 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.65 seconds
2021-01-19 14:30:22.129433 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:30:22.759386 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:30:22.767430 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:30:22.767563 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:30:22.767673 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:30:25.441009 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 2.67 seconds
2021-01-19 14:30:25.445637 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:30:25.768544 (MainThread): Using snowflake connection "master".
2021-01-19 14:30:25.768723 (MainThread): On master: BEGIN
2021-01-19 14:30:25.768839 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:30:27.116808 (MainThread): SQL status: SUCCESS 1 in 1.35 seconds
2021-01-19 14:30:27.117093 (MainThread): On master: COMMIT
2021-01-19 14:30:27.117358 (MainThread): Using snowflake connection "master".
2021-01-19 14:30:27.117512 (MainThread): On master: COMMIT
2021-01-19 14:30:27.801491 (MainThread): SQL status: SUCCESS 1 in 0.68 seconds
2021-01-19 14:30:27.801769 (MainThread): On master: Close
2021-01-19 14:30:28.101471 (MainThread): 15:30:28 | Concurrency: 1 threads (target='dev')
2021-01-19 14:30:28.101830 (MainThread): 15:30:28 | 
2021-01-19 14:30:28.104343 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:30:28.105768 (Thread-1): 15:30:28 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-01-19 14:30:28.106145 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:30:28.106291 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:30:28.130188 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:30:28.130699 (Thread-1): finished collecting timing info
2021-01-19 14:30:28.213904 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:30:28.214076 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */
drop table if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
2021-01-19 14:30:28.214191 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:30:32.125055 (Thread-1): SQL status: SUCCESS 1 in 3.91 seconds
2021-01-19 14:30:32.132161 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:30:32.133307 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:30:32.133432 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:30:33.740384 (Thread-1): SQL status: SUCCESS 1 in 1.61 seconds
2021-01-19 14:30:33.740583 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:30:33.740690 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-01-19 14:30:34.604287 (Thread-1): SQL status: SUCCESS 1 in 0.86 seconds
2021-01-19 14:30:34.605343 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:30:34.605524 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:30:34.605626 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:30:34.780865 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 14:30:34.793514 (Thread-1): finished collecting timing info
2021-01-19 14:30:34.793843 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:30:35.229771 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6ebfbd8-fa9a-4fc6-af18-43f68b9fe50d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddc2640>]}
2021-01-19 14:30:35.231133 (Thread-1): 15:30:35 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 7.12s]
2021-01-19 14:30:35.231392 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:30:35.231611 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:30:35.233596 (Thread-1): 15:30:35 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-01-19 14:30:35.234246 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:30:35.234487 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:30:35.243549 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:30:35.244110 (Thread-1): finished collecting timing info
2021-01-19 14:30:35.251732 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:30:35.251924 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */
drop table if exists "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" cascade
2021-01-19 14:30:35.252199 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:30:37.813453 (Thread-1): SQL status: SUCCESS 1 in 2.56 seconds
2021-01-19 14:30:37.815270 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:30:37.816576 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:30:37.816715 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:30:38.348338 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-01-19 14:30:38.348542 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:30:38.348644 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
  );
2021-01-19 14:30:39.168116 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 14:30:39.169512 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:30:39.169766 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:30:39.169892 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:30:39.501268 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 14:30:39.505625 (Thread-1): finished collecting timing info
2021-01-19 14:30:39.505947 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:30:39.991292 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6ebfbd8-fa9a-4fc6-af18-43f68b9fe50d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da65ac0>]}
2021-01-19 14:30:39.992590 (Thread-1): 15:30:39 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 4.76s]
2021-01-19 14:30:39.992752 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:30:39.992907 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:30:39.994311 (Thread-1): 15:30:39 | 3 of 4 START view model dbt.snowflake_customer_purchases............. [RUN]
2021-01-19 14:30:39.994645 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:30:39.994776 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:30:40.003679 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:30:40.004158 (Thread-1): finished collecting timing info
2021-01-19 14:30:40.011166 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:30:40.011300 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */
drop table if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" cascade
2021-01-19 14:30:40.011410 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:30:41.737770 (Thread-1): SQL status: SUCCESS 1 in 1.73 seconds
2021-01-19 14:30:41.739344 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:30:41.740771 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:30:41.740907 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:30:41.957073 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 14:30:41.957294 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:30:41.957420 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */

  create or replace  view analytics.dbt.snowflake_customer_purchases  as (
    

SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
  );
2021-01-19 14:30:42.551403 (Thread-1): SQL status: SUCCESS 1 in 0.59 seconds
2021-01-19 14:30:42.552535 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:30:42.552715 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:30:42.552818 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:30:42.765921 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 14:30:42.770265 (Thread-1): finished collecting timing info
2021-01-19 14:30:42.770606 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:30:43.026749 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6ebfbd8-fa9a-4fc6-af18-43f68b9fe50d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da882b0>]}
2021-01-19 14:30:43.028343 (Thread-1): 15:30:43 | 3 of 4 OK created view model dbt.snowflake_customer_purchases........ [SUCCESS 1 in 3.03s]
2021-01-19 14:30:43.028554 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:30:43.028727 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:30:43.029970 (Thread-1): 15:30:43 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 14:30:43.030287 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:30:43.030413 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:30:43.041973 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:30:43.042501 (Thread-1): finished collecting timing info
2021-01-19 14:30:43.047510 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:30:43.048444 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:30:43.048577 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:30:43.048692 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:30:43.951837 (Thread-1): SQL status: SUCCESS 1 in 0.90 seconds
2021-01-19 14:30:43.952106 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:30:43.952342 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 14:30:45.212066 (Thread-1): SQL status: SUCCESS 1 in 1.26 seconds
2021-01-19 14:30:45.213540 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:30:45.213731 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:30:45.213838 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:30:45.397023 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 14:30:45.400711 (Thread-1): finished collecting timing info
2021-01-19 14:30:45.401007 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:30:45.672907 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6ebfbd8-fa9a-4fc6-af18-43f68b9fe50d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d89c760>]}
2021-01-19 14:30:45.674186 (Thread-1): 15:30:45 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.64s]
2021-01-19 14:30:45.674346 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:30:45.675932 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:30:45.676159 (MainThread): Using snowflake connection "master".
2021-01-19 14:30:45.676265 (MainThread): On master: BEGIN
2021-01-19 14:30:45.676370 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:30:47.051885 (MainThread): SQL status: SUCCESS 1 in 1.38 seconds
2021-01-19 14:30:47.052115 (MainThread): On master: COMMIT
2021-01-19 14:30:47.052312 (MainThread): Using snowflake connection "master".
2021-01-19 14:30:47.052442 (MainThread): On master: COMMIT
2021-01-19 14:30:47.373551 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 14:30:47.373767 (MainThread): On master: Close
2021-01-19 14:30:47.651190 (MainThread): 15:30:47 | 
2021-01-19 14:30:47.651435 (MainThread): 15:30:47 | Finished running 4 view models in 27.19s.
2021-01-19 14:30:47.651592 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:30:47.651714 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:30:47.666817 (MainThread): 
2021-01-19 14:30:47.666990 (MainThread): Completed successfully
2021-01-19 14:30:47.667126 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:30:47.667320 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10daba730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10daba340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de6c430>]}
2021-01-19 14:30:47.667550 (MainThread): Flushing usage events
2021-01-19 14:32:39.043987 (MainThread): Running with dbt=0.18.1
2021-01-19 14:32:39.128085 (MainThread): Loading KWallet
2021-01-19 14:32:39.128733 (MainThread): Loading SecretService
2021-01-19 14:32:39.129235 (MainThread): Loading Windows
2021-01-19 14:32:39.129878 (MainThread): Loading chainer
2021-01-19 14:32:39.130210 (MainThread): Loading macOS
2021-01-19 14:32:39.426315 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:32:39.427210 (MainThread): Tracking: tracking
2021-01-19 14:32:39.427485 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea6b040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea6bd90>]}
2021-01-19 14:32:39.453880 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='5f2526cceef209673e3fdd43f0d876f35f0465bc660c59947a03d68c6a0c66e7') -> FileHash(name='sha256', checksum='b17bc49c0e5698b8b3aa3772dc09e1ed6154bdd3305856dfaf0d6d59c0a13448')), cache invalidated
2021-01-19 14:32:39.455254 (MainThread): Parsing macros/catalog.sql
2021-01-19 14:32:39.457340 (MainThread): Parsing macros/adapters.sql
2021-01-19 14:32:39.487587 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 14:32:39.489574 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 14:32:39.490912 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 14:32:39.494473 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 14:32:39.505580 (MainThread): Parsing macros/core.sql
2021-01-19 14:32:39.509136 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 14:32:39.518482 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 14:32:39.520139 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 14:32:39.537111 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 14:32:39.568333 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 14:32:39.589422 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 14:32:39.591376 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 14:32:39.597388 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 14:32:39.611213 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 14:32:39.619037 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 14:32:39.624970 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 14:32:39.629528 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 14:32:39.630464 (MainThread): Parsing macros/etc/query.sql
2021-01-19 14:32:39.631761 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 14:32:39.633921 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 14:32:39.642604 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 14:32:39.644672 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 14:32:39.646223 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 14:32:39.690298 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 14:32:39.692071 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 14:32:39.693475 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 14:32:39.695069 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 14:32:39.704494 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='5f2526cceef209673e3fdd43f0d876f35f0465bc660c59947a03d68c6a0c66e7') -> FileHash(name='sha256', checksum='b17bc49c0e5698b8b3aa3772dc09e1ed6154bdd3305856dfaf0d6d59c0a13448')), cache invalidated
2021-01-19 14:32:39.742716 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:32:39.763495 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:32:39.776493 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:32:39.790102 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:32:40.080861 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:32:40.083919 (MainThread): 
2021-01-19 14:32:40.085257 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:32:40.091655 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:32:40.105248 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:32:40.105373 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:32:40.105540 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:32:42.651022 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.55 seconds
2021-01-19 14:32:42.655095 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:32:43.001932 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:32:43.010159 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:32:43.010306 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:32:43.010419 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:32:43.923963 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.91 seconds
2021-01-19 14:32:43.928285 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:32:44.184839 (MainThread): Using snowflake connection "master".
2021-01-19 14:32:44.185000 (MainThread): On master: BEGIN
2021-01-19 14:32:44.185109 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:32:45.069805 (MainThread): SQL status: SUCCESS 1 in 0.88 seconds
2021-01-19 14:32:45.070080 (MainThread): On master: COMMIT
2021-01-19 14:32:45.070289 (MainThread): Using snowflake connection "master".
2021-01-19 14:32:45.070405 (MainThread): On master: COMMIT
2021-01-19 14:32:45.350984 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 14:32:45.351200 (MainThread): On master: Close
2021-01-19 14:32:45.635098 (MainThread): 15:32:45 | Concurrency: 1 threads (target='dev')
2021-01-19 14:32:45.635311 (MainThread): 15:32:45 | 
2021-01-19 14:32:45.637482 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:32:45.638871 (Thread-1): 15:32:45 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-01-19 14:32:45.639212 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:32:45.639345 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:32:45.661968 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:32:45.662439 (Thread-1): finished collecting timing info
2021-01-19 14:32:45.695833 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:32:45.696936 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:32:45.697047 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:32:45.697147 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:32:48.825623 (Thread-1): SQL status: SUCCESS 1 in 3.13 seconds
2021-01-19 14:32:48.825879 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:32:48.826028 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-01-19 14:32:49.163781 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 14:32:49.165435 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:32:49.165645 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:32:49.165760 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:32:49.384343 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 14:32:49.396269 (Thread-1): finished collecting timing info
2021-01-19 14:32:49.396550 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:32:49.660034 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a72e935-5237-4856-9a76-639540fe547f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb2aa30>]}
2021-01-19 14:32:49.661148 (Thread-1): 15:32:49 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 4.02s]
2021-01-19 14:32:49.661295 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:32:49.661441 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:32:49.662988 (Thread-1): 15:32:49 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-01-19 14:32:49.663606 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:32:49.663814 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:32:49.673391 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:32:49.673863 (Thread-1): finished collecting timing info
2021-01-19 14:32:49.678765 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:32:49.679719 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:32:49.679879 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:32:49.679986 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:32:50.753717 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2021-01-19 14:32:50.753903 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:32:50.754000 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
  );
2021-01-19 14:32:52.299865 (Thread-1): SQL status: SUCCESS 1 in 1.55 seconds
2021-01-19 14:32:52.301311 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:32:52.301525 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:32:52.301641 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:32:52.449300 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:32:52.453656 (Thread-1): finished collecting timing info
2021-01-19 14:32:52.453955 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:32:52.844472 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a72e935-5237-4856-9a76-639540fe547f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f80f8e0>]}
2021-01-19 14:32:52.845791 (Thread-1): 15:32:52 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 3.18s]
2021-01-19 14:32:52.845947 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:32:52.846096 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:32:52.848048 (Thread-1): 15:32:52 | 3 of 4 START view model dbt.snowflake_customer_purchases............. [RUN]
2021-01-19 14:32:52.848749 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:32:52.848890 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:32:52.857516 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:32:52.858052 (Thread-1): finished collecting timing info
2021-01-19 14:32:52.863014 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:32:52.864298 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:32:52.864480 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:32:52.864597 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:32:54.044028 (Thread-1): SQL status: SUCCESS 1 in 1.18 seconds
2021-01-19 14:32:54.044296 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:32:54.044444 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */

  create or replace  view analytics.dbt.snowflake_customer_purchases  as (
    

SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
  );
2021-01-19 14:32:54.451868 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2021-01-19 14:32:54.453192 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:32:54.453403 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:32:54.453522 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:32:54.609581 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:32:54.613865 (Thread-1): finished collecting timing info
2021-01-19 14:32:54.614211 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:32:55.670123 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a72e935-5237-4856-9a76-639540fe547f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb2acd0>]}
2021-01-19 14:32:55.671584 (Thread-1): 15:32:55 | 3 of 4 OK created view model dbt.snowflake_customer_purchases........ [SUCCESS 1 in 2.82s]
2021-01-19 14:32:55.671770 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:32:55.671986 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:32:55.673571 (Thread-1): 15:32:55 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 14:32:55.673899 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:32:55.674026 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:32:55.684959 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:32:55.685454 (Thread-1): finished collecting timing info
2021-01-19 14:32:55.690433 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:32:55.691253 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:32:55.691363 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:32:55.691467 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:32:57.450782 (Thread-1): SQL status: SUCCESS 1 in 1.76 seconds
2021-01-19 14:32:57.450970 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:32:57.451072 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 14:32:57.877749 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-01-19 14:32:57.879007 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:32:57.879276 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:32:57.879439 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:32:58.025429 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:32:58.029146 (Thread-1): finished collecting timing info
2021-01-19 14:32:58.029438 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:32:58.308827 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a72e935-5237-4856-9a76-639540fe547f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb2a7c0>]}
2021-01-19 14:32:58.310406 (Thread-1): 15:32:58 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.63s]
2021-01-19 14:32:58.310600 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:32:58.312189 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:32:58.312430 (MainThread): Using snowflake connection "master".
2021-01-19 14:32:58.312547 (MainThread): On master: BEGIN
2021-01-19 14:32:58.312650 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:33:00.172890 (MainThread): SQL status: SUCCESS 1 in 1.86 seconds
2021-01-19 14:33:00.173158 (MainThread): On master: COMMIT
2021-01-19 14:33:00.173404 (MainThread): Using snowflake connection "master".
2021-01-19 14:33:00.173546 (MainThread): On master: COMMIT
2021-01-19 14:33:00.481551 (MainThread): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 14:33:00.481828 (MainThread): On master: Close
2021-01-19 14:33:01.187555 (MainThread): 15:33:01 | 
2021-01-19 14:33:01.187754 (MainThread): 15:33:01 | Finished running 4 view models in 21.10s.
2021-01-19 14:33:01.187885 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:33:01.188039 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:33:01.203007 (MainThread): 
2021-01-19 14:33:01.203185 (MainThread): Completed successfully
2021-01-19 14:33:01.203314 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:33:01.203500 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f69a760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f69a820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb2ae80>]}
2021-01-19 14:33:01.203709 (MainThread): Flushing usage events
2021-01-19 14:36:30.593708 (MainThread): Running with dbt=0.18.1
2021-01-19 14:36:30.701420 (MainThread): Loading KWallet
2021-01-19 14:36:30.702278 (MainThread): Loading SecretService
2021-01-19 14:36:30.702858 (MainThread): Loading Windows
2021-01-19 14:36:30.703572 (MainThread): Loading chainer
2021-01-19 14:36:30.703933 (MainThread): Loading macOS
2021-01-19 14:36:31.051262 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:36:31.052321 (MainThread): Tracking: tracking
2021-01-19 14:36:31.052640 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10670e970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa97c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068400a0>]}
2021-01-19 14:36:31.101374 (MainThread): Got an acceptable cached parse result
2021-01-19 14:36:31.324138 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:36:31.326116 (MainThread): 
2021-01-19 14:36:31.326967 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:36:31.334083 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:36:31.351847 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:36:31.352010 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:36:31.352124 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:36:34.301478 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.95 seconds
2021-01-19 14:36:34.306594 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:36:34.591077 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:36:34.599423 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:36:34.599600 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:36:34.599716 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:36:36.085113 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.49 seconds
2021-01-19 14:36:36.089483 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:36:36.383465 (MainThread): Using snowflake connection "master".
2021-01-19 14:36:36.383621 (MainThread): On master: BEGIN
2021-01-19 14:36:36.383733 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:36:38.040307 (MainThread): SQL status: SUCCESS 1 in 1.66 seconds
2021-01-19 14:36:38.040530 (MainThread): On master: COMMIT
2021-01-19 14:36:38.040728 (MainThread): Using snowflake connection "master".
2021-01-19 14:36:38.040856 (MainThread): On master: COMMIT
2021-01-19 14:36:38.608605 (MainThread): SQL status: SUCCESS 1 in 0.57 seconds
2021-01-19 14:36:38.608894 (MainThread): On master: Close
2021-01-19 14:36:39.560656 (MainThread): 15:36:39 | Concurrency: 1 threads (target='dev')
2021-01-19 14:36:39.560890 (MainThread): 15:36:39 | 
2021-01-19 14:36:39.562801 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:36:39.564173 (Thread-1): 15:36:39 | 1 of 4 START view model dbt.my_first_dbt_model....................... [RUN]
2021-01-19 14:36:39.564583 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:36:39.564759 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:36:39.596256 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:36:39.596871 (Thread-1): finished collecting timing info
2021-01-19 14:36:39.630682 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:36:39.631752 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:36:39.631866 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:36:39.631970 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:36:40.941586 (Thread-1): SQL status: SUCCESS 1 in 1.31 seconds
2021-01-19 14:36:40.941779 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:36:40.941882 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-01-19 14:36:41.464200 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2021-01-19 14:36:41.465398 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:36:41.465578 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:36:41.465678 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:36:41.617825 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:36:41.629768 (Thread-1): finished collecting timing info
2021-01-19 14:36:41.630094 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:36:42.900157 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e69fc35e-a83b-41e9-9be6-a839f31756ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a72e0>]}
2021-01-19 14:36:42.901470 (Thread-1): 15:36:42 | 1 of 4 OK created view model dbt.my_first_dbt_model.................. [SUCCESS 1 in 3.34s]
2021-01-19 14:36:42.901634 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:36:42.901787 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:36:42.903362 (Thread-1): 15:36:42 | 2 of 4 START view model dbt.cumulative_orders_by_date................ [RUN]
2021-01-19 14:36:42.903802 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:36:42.903935 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:36:42.913181 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:36:42.913727 (Thread-1): finished collecting timing info
2021-01-19 14:36:42.963574 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:36:42.964814 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:36:42.964951 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:36:42.965064 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:36:44.999043 (Thread-1): SQL status: SUCCESS 1 in 2.03 seconds
2021-01-19 14:36:44.999261 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:36:44.999385 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */

  create or replace  view analytics.dbt.cumulative_orders_by_date  as (
    

select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
  );
2021-01-19 14:36:45.657097 (Thread-1): SQL status: SUCCESS 1 in 0.66 seconds
2021-01-19 14:36:45.658345 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:36:45.658505 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:36:45.658590 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:36:45.905367 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 14:36:45.910344 (Thread-1): finished collecting timing info
2021-01-19 14:36:45.910729 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:36:46.222164 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e69fc35e-a83b-41e9-9be6-a839f31756ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077d6c40>]}
2021-01-19 14:36:46.223485 (Thread-1): 15:36:46 | 2 of 4 OK created view model dbt.cumulative_orders_by_date........... [SUCCESS 1 in 3.32s]
2021-01-19 14:36:46.223649 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:36:46.223828 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:36:46.226089 (Thread-1): 15:36:46 | 3 of 4 START view model dbt.snowflake_customer_purchases............. [RUN]
2021-01-19 14:36:46.226572 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:36:46.226717 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:36:46.235345 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:36:46.235847 (Thread-1): finished collecting timing info
2021-01-19 14:36:46.241224 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:36:46.242504 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:36:46.242637 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:36:46.242745 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:36:47.384516 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 14:36:47.384718 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:36:47.384826 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */

  create or replace  view analytics.dbt.snowflake_customer_purchases  as (
    

SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
  );
2021-01-19 14:36:47.811963 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-01-19 14:36:47.813190 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:36:47.813614 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:36:47.813726 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:36:48.802228 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 14:36:48.805990 (Thread-1): finished collecting timing info
2021-01-19 14:36:48.806289 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:36:49.092748 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e69fc35e-a83b-41e9-9be6-a839f31756ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074a61c0>]}
2021-01-19 14:36:49.094642 (Thread-1): 15:36:49 | 3 of 4 OK created view model dbt.snowflake_customer_purchases........ [SUCCESS 1 in 2.87s]
2021-01-19 14:36:49.094855 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:36:49.095091 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:36:49.097411 (Thread-1): 15:36:49 | 4 of 4 START view model dbt.my_second_dbt_model...................... [RUN]
2021-01-19 14:36:49.097878 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:36:49.098030 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:36:49.108658 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:36:49.109254 (Thread-1): finished collecting timing info
2021-01-19 14:36:49.115660 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:36:49.116735 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:36:49.116916 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:36:49.117035 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:36:50.026983 (Thread-1): SQL status: SUCCESS 1 in 0.91 seconds
2021-01-19 14:36:50.027220 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:36:50.027355 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
2021-01-19 14:36:50.471763 (Thread-1): SQL status: SUCCESS 1 in 0.44 seconds
2021-01-19 14:36:50.472944 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:36:50.473128 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:36:50.473239 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:36:50.969099 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-01-19 14:36:50.973542 (Thread-1): finished collecting timing info
2021-01-19 14:36:50.973911 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:36:51.286723 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e69fc35e-a83b-41e9-9be6-a839f31756ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10751a2e0>]}
2021-01-19 14:36:51.288462 (Thread-1): 15:36:51 | 4 of 4 OK created view model dbt.my_second_dbt_model................. [SUCCESS 1 in 2.19s]
2021-01-19 14:36:51.288635 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:36:51.289806 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:36:51.290032 (MainThread): Using snowflake connection "master".
2021-01-19 14:36:51.290135 (MainThread): On master: BEGIN
2021-01-19 14:36:51.290237 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:36:52.693254 (MainThread): SQL status: SUCCESS 1 in 1.40 seconds
2021-01-19 14:36:52.693549 (MainThread): On master: COMMIT
2021-01-19 14:36:52.693804 (MainThread): Using snowflake connection "master".
2021-01-19 14:36:52.693967 (MainThread): On master: COMMIT
2021-01-19 14:36:53.159984 (MainThread): SQL status: SUCCESS 1 in 0.47 seconds
2021-01-19 14:36:53.160270 (MainThread): On master: Close
2021-01-19 14:36:53.458228 (MainThread): 15:36:53 | 
2021-01-19 14:36:53.458456 (MainThread): 15:36:53 | Finished running 4 view models in 22.13s.
2021-01-19 14:36:53.458632 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:36:53.458819 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:36:53.473871 (MainThread): 
2021-01-19 14:36:53.474085 (MainThread): Completed successfully
2021-01-19 14:36:53.474230 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:36:53.474424 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a7130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e93d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e9760>]}
2021-01-19 14:36:53.474647 (MainThread): Flushing usage events
2021-01-19 14:37:42.929395 (MainThread): Running with dbt=0.18.1
2021-01-19 14:37:43.004028 (MainThread): Loading KWallet
2021-01-19 14:37:43.004594 (MainThread): Loading SecretService
2021-01-19 14:37:43.005028 (MainThread): Loading Windows
2021-01-19 14:37:43.005572 (MainThread): Loading chainer
2021-01-19 14:37:43.005856 (MainThread): Loading macOS
2021-01-19 14:37:43.293953 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:37:43.295150 (MainThread): Tracking: tracking
2021-01-19 14:37:43.295431 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4e07f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6efd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6ef310>]}
2021-01-19 14:37:43.335144 (MainThread): Got an acceptable cached parse result
2021-01-19 14:37:43.372567 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:37:43.392370 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:37:43.403659 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:37:43.416602 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:37:43.567500 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:37:43.569079 (MainThread): 
2021-01-19 14:37:43.569641 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:37:43.575525 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:37:43.589076 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:37:43.589194 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:37:43.589274 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:37:44.913678 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.32 seconds
2021-01-19 14:37:44.918032 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:37:45.206125 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:37:45.214722 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:37:45.214886 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:37:45.214995 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:37:46.837815 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.62 seconds
2021-01-19 14:37:46.843592 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:37:47.113236 (MainThread): Using snowflake connection "master".
2021-01-19 14:37:47.113409 (MainThread): On master: BEGIN
2021-01-19 14:37:47.113526 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:37:48.224310 (MainThread): SQL status: SUCCESS 1 in 1.11 seconds
2021-01-19 14:37:48.224596 (MainThread): On master: COMMIT
2021-01-19 14:37:48.224863 (MainThread): Using snowflake connection "master".
2021-01-19 14:37:48.225017 (MainThread): On master: COMMIT
2021-01-19 14:37:48.633709 (MainThread): SQL status: SUCCESS 1 in 0.41 seconds
2021-01-19 14:37:48.633991 (MainThread): On master: Close
2021-01-19 14:37:48.897490 (MainThread): 15:37:48 | Concurrency: 1 threads (target='dev')
2021-01-19 14:37:48.897702 (MainThread): 15:37:48 | 
2021-01-19 14:37:48.899749 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:37:48.901081 (Thread-1): 15:37:48 | 1 of 4 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:37:48.901411 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:37:48.901556 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:37:48.923403 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:37:48.923907 (Thread-1): finished collecting timing info
2021-01-19 14:37:48.951049 (Thread-1): Dropping relation "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" because it is of type view
2021-01-19 14:37:48.999850 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:37:49.000019 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
2021-01-19 14:37:49.000137 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:37:50.108501 (Thread-1): SQL status: SUCCESS 1 in 1.11 seconds
2021-01-19 14:37:50.123342 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:37:50.124530 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:37:50.124667 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:37:50.476355 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2021-01-19 14:37:50.476564 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:37:50.476685 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:37:52.676483 (Thread-1): SQL status: SUCCESS 1 in 2.20 seconds
2021-01-19 14:37:52.677873 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:37:52.678100 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:37:52.678210 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:37:53.045400 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-01-19 14:37:53.060816 (Thread-1): finished collecting timing info
2021-01-19 14:37:53.061274 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:37:53.341890 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1e989a1-3de3-4628-ad26-700a5dac940a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1778b0>]}
2021-01-19 14:37:53.343477 (Thread-1): 15:37:53 | 1 of 4 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 4.44s]
2021-01-19 14:37:53.343698 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:37:53.343900 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:37:53.346190 (Thread-1): 15:37:53 | 2 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:37:53.347307 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:37:53.347537 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:37:53.361264 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:37:53.361746 (Thread-1): finished collecting timing info
2021-01-19 14:37:53.367919 (Thread-1): Dropping relation "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" because it is of type view
2021-01-19 14:37:53.370496 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:37:53.370654 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */
drop view if exists "ANALYTICS"."DBT"."CUMULATIVE_ORDERS_BY_DATE" cascade
2021-01-19 14:37:53.370771 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:37:54.261843 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2021-01-19 14:37:54.263249 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:37:54.264328 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:37:54.264442 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:37:54.435001 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:37:54.435256 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:37:54.435409 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 14:37:56.556946 (Thread-1): SQL status: SUCCESS 1 in 2.12 seconds
2021-01-19 14:37:56.558117 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:37:56.558307 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:37:56.558409 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:37:56.753490 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-01-19 14:37:56.756036 (Thread-1): finished collecting timing info
2021-01-19 14:37:56.756315 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:37:57.088808 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1e989a1-3de3-4628-ad26-700a5dac940a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1158aca00>]}
2021-01-19 14:37:57.090340 (Thread-1): 15:37:57 | 2 of 4 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.74s]
2021-01-19 14:37:57.090514 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:37:57.090814 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:37:57.093022 (Thread-1): 15:37:57 | 3 of 4 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:37:57.093374 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:37:57.093509 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:37:57.101356 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:37:57.101853 (Thread-1): finished collecting timing info
2021-01-19 14:37:57.106481 (Thread-1): Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" because it is of type view
2021-01-19 14:37:57.108992 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:37:57.109163 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */
drop view if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" cascade
2021-01-19 14:37:57.109282 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:37:58.535516 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-01-19 14:37:58.537468 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:37:58.538892 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:37:58.539027 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:37:58.714704 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 14:37:58.714896 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:37:58.715014 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:38:01.331589 (Thread-1): SQL status: SUCCESS 1 in 2.62 seconds
2021-01-19 14:38:01.333122 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:38:01.333384 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:38:01.333555 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:38:01.494197 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:38:01.496954 (Thread-1): finished collecting timing info
2021-01-19 14:38:01.497296 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:38:02.293451 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1e989a1-3de3-4628-ad26-700a5dac940a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f200790>]}
2021-01-19 14:38:02.294992 (Thread-1): 15:38:02 | 3 of 4 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 5.20s]
2021-01-19 14:38:02.295196 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:38:02.295418 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:38:02.296996 (Thread-1): 15:38:02 | 4 of 4 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 14:38:02.297724 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:38:02.297883 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:38:02.308490 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:38:02.309015 (Thread-1): finished collecting timing info
2021-01-19 14:38:02.313845 (Thread-1): Dropping relation "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" because it is of type view
2021-01-19 14:38:02.316216 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:38:02.316344 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" cascade
2021-01-19 14:38:02.316452 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:38:03.752399 (Thread-1): SQL status: SUCCESS 1 in 1.44 seconds
2021-01-19 14:38:03.754336 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:38:03.755417 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:38:03.755553 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:38:03.932658 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 14:38:03.932909 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:38:03.933058 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-01-19 14:38:05.529384 (Thread-1): SQL status: SUCCESS 1 in 1.60 seconds
2021-01-19 14:38:05.530677 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:38:05.530922 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:38:05.531045 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:38:05.704302 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:38:05.707481 (Thread-1): finished collecting timing info
2021-01-19 14:38:05.707852 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:38:05.972791 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1e989a1-3de3-4628-ad26-700a5dac940a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f48ddf0>]}
2021-01-19 14:38:05.974139 (Thread-1): 15:38:05 | 4 of 4 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.68s]
2021-01-19 14:38:05.974318 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:38:05.975634 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:38:05.975893 (MainThread): Using snowflake connection "master".
2021-01-19 14:38:05.976012 (MainThread): On master: BEGIN
2021-01-19 14:38:05.976122 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:38:07.134622 (MainThread): SQL status: SUCCESS 1 in 1.16 seconds
2021-01-19 14:38:07.134903 (MainThread): On master: COMMIT
2021-01-19 14:38:07.135153 (MainThread): Using snowflake connection "master".
2021-01-19 14:38:07.135302 (MainThread): On master: COMMIT
2021-01-19 14:38:07.363443 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 14:38:07.363770 (MainThread): On master: Close
2021-01-19 14:38:07.641630 (MainThread): 15:38:07 | 
2021-01-19 14:38:07.641873 (MainThread): 15:38:07 | Finished running 4 table models in 24.07s.
2021-01-19 14:38:07.642089 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:38:07.642245 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:38:07.657247 (MainThread): 
2021-01-19 14:38:07.657433 (MainThread): Completed successfully
2021-01-19 14:38:07.657568 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:38:07.657761 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f383cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2c8eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2c8160>]}
2021-01-19 14:38:07.657980 (MainThread): Flushing usage events
2021-01-19 14:44:09.301707 (MainThread): Running with dbt=0.18.1
2021-01-19 14:44:09.374912 (MainThread): Loading KWallet
2021-01-19 14:44:09.375566 (MainThread): Loading SecretService
2021-01-19 14:44:09.376043 (MainThread): Loading Windows
2021-01-19 14:44:09.376672 (MainThread): Loading chainer
2021-01-19 14:44:09.376989 (MainThread): Loading macOS
2021-01-19 14:44:09.665345 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:44:09.666598 (MainThread): Tracking: tracking
2021-01-19 14:44:09.666839 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048d99a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1031727f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a0b0d0>]}
2021-01-19 14:44:09.709330 (MainThread): Got an acceptable cached parse result
2021-01-19 14:44:09.746631 (MainThread): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 14:44:09.957462 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 14:44:10.056847 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:44:10.058194 (MainThread): 
2021-01-19 14:44:10.058564 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:44:10.065286 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:44:10.080073 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:44:10.080225 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:44:10.080323 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:44:11.657083 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.58 seconds
2021-01-19 14:44:11.661619 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:44:11.982442 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:44:11.990796 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:44:11.990940 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:44:11.991054 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:44:13.133898 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.14 seconds
2021-01-19 14:44:13.139109 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:44:13.617988 (MainThread): Using snowflake connection "master".
2021-01-19 14:44:13.618166 (MainThread): On master: BEGIN
2021-01-19 14:44:13.618285 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:44:14.764940 (MainThread): SQL status: SUCCESS 1 in 1.15 seconds
2021-01-19 14:44:14.765224 (MainThread): On master: COMMIT
2021-01-19 14:44:14.765433 (MainThread): Using snowflake connection "master".
2021-01-19 14:44:14.765550 (MainThread): On master: COMMIT
2021-01-19 14:44:15.090667 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 14:44:15.090914 (MainThread): On master: Close
2021-01-19 14:44:15.402067 (MainThread): 15:44:15 | Concurrency: 1 threads (target='dev')
2021-01-19 14:44:15.402286 (MainThread): 15:44:15 | 
2021-01-19 14:44:15.404316 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:44:15.405608 (Thread-1): 15:44:15 | 1 of 5 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:44:15.405931 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:44:15.406069 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:44:15.427829 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:44:15.428343 (Thread-1): finished collecting timing info
2021-01-19 14:44:15.464533 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:44:15.465709 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:44:15.465827 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:44:15.465923 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:44:16.286200 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 14:44:16.286401 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:44:16.286509 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:44:18.550887 (Thread-1): SQL status: SUCCESS 1 in 2.26 seconds
2021-01-19 14:44:18.552340 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:44:18.552554 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:44:18.552677 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:44:18.741720 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-01-19 14:44:18.757582 (Thread-1): finished collecting timing info
2021-01-19 14:44:18.757905 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:44:19.022512 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ebaca14-48a0-4869-b82f-6a73862d8e35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ac66a0>]}
2021-01-19 14:44:19.023841 (Thread-1): 15:44:19 | 1 of 5 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 3.62s]
2021-01-19 14:44:19.024031 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:44:19.024188 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:44:19.026040 (Thread-1): 15:44:19 | 2 of 5 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:44:19.026476 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:44:19.026607 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:44:19.034744 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:44:19.035252 (Thread-1): finished collecting timing info
2021-01-19 14:44:19.040167 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:44:19.041145 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:44:19.041258 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:44:19.041368 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:44:20.179720 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 14:44:20.179888 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:44:20.179973 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 14:44:21.849083 (Thread-1): SQL status: SUCCESS 1 in 1.67 seconds
2021-01-19 14:44:21.850206 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:44:21.850389 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:44:21.850495 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:44:21.996140 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:44:21.998962 (Thread-1): finished collecting timing info
2021-01-19 14:44:21.999311 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:44:22.266467 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ebaca14-48a0-4869-b82f-6a73862d8e35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ac6a00>]}
2021-01-19 14:44:22.268029 (Thread-1): 15:44:22 | 2 of 5 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.24s]
2021-01-19 14:44:22.268223 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:44:22.268406 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 14:44:22.270224 (Thread-1): 15:44:22 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-01-19 14:44:22.270576 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 14:44:22.270700 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 14:44:22.279338 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 14:44:22.279792 (Thread-1): finished collecting timing info
2021-01-19 14:44:22.314305 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 14:44:22.315270 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:44:22.315404 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 14:44:22.315510 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:44:23.592256 (Thread-1): SQL status: SUCCESS 1 in 1.28 seconds
2021-01-19 14:44:23.592505 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:44:23.592729 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


      );
2021-01-19 14:44:26.553291 (Thread-1): SQL status: SUCCESS 1 in 2.96 seconds
2021-01-19 14:44:26.554436 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:44:26.554618 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:44:26.554718 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:44:26.733275 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 14:44:26.737149 (Thread-1): finished collecting timing info
2021-01-19 14:44:26.737447 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 14:44:26.998584 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ebaca14-48a0-4869-b82f-6a73862d8e35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057416a0>]}
2021-01-19 14:44:27.000003 (Thread-1): 15:44:26 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 1 in 4.73s]
2021-01-19 14:44:27.000218 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 14:44:27.000383 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:44:27.001975 (Thread-1): 15:44:27 | 4 of 5 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:44:27.002322 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:44:27.002450 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:44:27.010081 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:44:27.010571 (Thread-1): finished collecting timing info
2021-01-19 14:44:27.015564 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:44:27.016745 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:44:27.016858 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:44:27.016961 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:44:28.097237 (Thread-1): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 14:44:28.097452 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:44:28.097559 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:44:31.150664 (Thread-1): SQL status: SUCCESS 1 in 3.05 seconds
2021-01-19 14:44:31.151777 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:44:31.151954 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:44:31.152054 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:44:31.301032 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:44:31.303367 (Thread-1): finished collecting timing info
2021-01-19 14:44:31.303649 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:44:31.572947 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ebaca14-48a0-4869-b82f-6a73862d8e35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105685a90>]}
2021-01-19 14:44:31.574359 (Thread-1): 15:44:31 | 4 of 5 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 4.57s]
2021-01-19 14:44:31.574515 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:44:31.574664 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:44:31.576240 (Thread-1): 15:44:31 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 14:44:31.576657 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:44:31.576788 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:44:31.586623 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:44:31.587113 (Thread-1): finished collecting timing info
2021-01-19 14:44:31.591932 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:44:31.592844 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:44:31.592963 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:44:31.593070 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:44:32.578873 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 14:44:32.579058 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:44:32.579158 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-01-19 14:44:34.035099 (Thread-1): SQL status: SUCCESS 1 in 1.46 seconds
2021-01-19 14:44:34.036351 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:44:34.036558 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:44:34.036673 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:44:34.208461 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:44:34.211518 (Thread-1): finished collecting timing info
2021-01-19 14:44:34.211842 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:44:34.469033 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ebaca14-48a0-4869-b82f-6a73862d8e35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10572e970>]}
2021-01-19 14:44:34.470549 (Thread-1): 15:44:34 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.89s]
2021-01-19 14:44:34.470734 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:44:34.472190 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:44:34.472570 (MainThread): Using snowflake connection "master".
2021-01-19 14:44:34.472681 (MainThread): On master: BEGIN
2021-01-19 14:44:34.472785 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:44:35.552979 (MainThread): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 14:44:35.561436 (MainThread): On master: COMMIT
2021-01-19 14:44:35.561981 (MainThread): Using snowflake connection "master".
2021-01-19 14:44:35.562138 (MainThread): On master: COMMIT
2021-01-19 14:44:35.794803 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 14:44:35.795096 (MainThread): On master: Close
2021-01-19 14:44:36.060597 (MainThread): 15:44:36 | 
2021-01-19 14:44:36.060833 (MainThread): 15:44:36 | Finished running 4 table models, 1 incremental model in 26.00s.
2021-01-19 14:44:36.060987 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:44:36.061147 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:44:36.079587 (MainThread): 
2021-01-19 14:44:36.079779 (MainThread): Completed successfully
2021-01-19 14:44:36.079924 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-01-19 14:44:36.080120 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105af76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105af7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105af7580>]}
2021-01-19 14:44:36.080342 (MainThread): Flushing usage events
2021-01-19 14:48:38.212785 (MainThread): Running with dbt=0.18.1
2021-01-19 14:48:38.287405 (MainThread): Loading KWallet
2021-01-19 14:48:38.288049 (MainThread): Loading SecretService
2021-01-19 14:48:38.288498 (MainThread): Loading Windows
2021-01-19 14:48:38.289095 (MainThread): Loading chainer
2021-01-19 14:48:38.289389 (MainThread): Loading macOS
2021-01-19 14:48:38.574959 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:48:38.576580 (MainThread): Tracking: tracking
2021-01-19 14:48:38.576881 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fa29a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10483b7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060d30d0>]}
2021-01-19 14:48:38.615228 (MainThread): Got an acceptable cached parse result
2021-01-19 14:48:38.702121 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 14:48:38.798674 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:48:38.801119 (MainThread): 
2021-01-19 14:48:38.801745 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:48:38.811805 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:48:38.827973 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:48:38.828141 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:48:38.828252 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:48:40.418632 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.59 seconds
2021-01-19 14:48:40.422492 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:48:40.766874 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:48:40.775016 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:48:40.775163 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:48:40.775275 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:48:42.827404 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 2.05 seconds
2021-01-19 14:48:42.832786 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:48:43.098421 (MainThread): Using snowflake connection "master".
2021-01-19 14:48:43.098589 (MainThread): On master: BEGIN
2021-01-19 14:48:43.098707 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:48:44.550156 (MainThread): SQL status: SUCCESS 1 in 1.45 seconds
2021-01-19 14:48:44.550433 (MainThread): On master: COMMIT
2021-01-19 14:48:44.550684 (MainThread): Using snowflake connection "master".
2021-01-19 14:48:44.550831 (MainThread): On master: COMMIT
2021-01-19 14:48:44.786818 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 14:48:44.787123 (MainThread): On master: Close
2021-01-19 14:48:45.093279 (MainThread): 15:48:45 | Concurrency: 1 threads (target='dev')
2021-01-19 14:48:45.093509 (MainThread): 15:48:45 | 
2021-01-19 14:48:45.095539 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:48:45.096907 (Thread-1): 15:48:45 | 1 of 5 START table model dbt.my_first_dbt_model...................... [RUN]
2021-01-19 14:48:45.097254 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:48:45.097407 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:48:45.127102 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:48:45.127655 (Thread-1): finished collecting timing info
2021-01-19 14:48:45.165377 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:48:45.166612 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:48:45.166738 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 14:48:45.166850 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:48:46.365502 (Thread-1): SQL status: SUCCESS 1 in 1.20 seconds
2021-01-19 14:48:46.365746 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:48:46.365859 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 14:48:47.696727 (Thread-1): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-19 14:48:47.697970 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:48:47.698159 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:48:47.698264 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 14:48:47.858757 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:48:47.874084 (Thread-1): finished collecting timing info
2021-01-19 14:48:47.874411 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 14:48:48.131067 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fe04a2-9245-48fb-943b-715b46cd09f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060d38e0>]}
2021-01-19 14:48:48.132540 (Thread-1): 15:48:48 | 1 of 5 OK created table model dbt.my_first_dbt_model................. [SUCCESS 1 in 3.03s]
2021-01-19 14:48:48.132707 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:48:48.132867 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:48:48.134574 (Thread-1): 15:48:48 | 2 of 5 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:48:48.135028 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:48:48.135164 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:48:48.142556 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:48:48.143069 (Thread-1): finished collecting timing info
2021-01-19 14:48:48.147884 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:48:48.148867 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:48:48.148977 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:48:48.149084 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:48:49.036348 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2021-01-19 14:48:49.036614 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:48:49.036770 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 14:48:51.110228 (Thread-1): SQL status: SUCCESS 1 in 2.07 seconds
2021-01-19 14:48:51.111502 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:48:51.111702 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:48:51.111809 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:48:51.362473 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 14:48:51.364620 (Thread-1): finished collecting timing info
2021-01-19 14:48:51.364867 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:48:51.690171 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fe04a2-9245-48fb-943b-715b46cd09f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1eb940>]}
2021-01-19 14:48:51.691550 (Thread-1): 15:48:51 | 2 of 5 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.55s]
2021-01-19 14:48:51.691737 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:48:51.691995 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 14:48:51.693905 (Thread-1): 15:48:51 | 3 of 5 START incremental model dbt.dates............................. [RUN]
2021-01-19 14:48:51.694279 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:51.694415 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 14:48:51.710991 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 14:48:51.711586 (Thread-1): finished collecting timing info
2021-01-19 14:48:51.742901 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:51.743074 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 14:48:51.743187 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:48:53.458050 (Thread-1): SQL status: SUCCESS 1 in 1.71 seconds
2021-01-19 14:48:53.468778 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:53.468944 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 14:48:53.681964 (Thread-1): SQL status: SUCCESS 28 in 0.21 seconds
2021-01-19 14:48:53.687136 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:53.687261 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 14:48:53.870580 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 14:48:53.875869 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:53.876101 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 14:48:54.046592 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 14:48:54.079160 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 14:48:54.083308 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:54.083488 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 14:48:54.309565 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 14:48:54.309747 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:54.309850 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 14:48:55.171986 (Thread-1): SQL status: SUCCESS 0 in 0.86 seconds
2021-01-19 14:48:55.173065 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:48:55.173254 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:48:55.173356 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:48:55.390483 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 14:48:55.395544 (Thread-1): finished collecting timing info
2021-01-19 14:48:55.395838 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 14:48:55.689672 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fe04a2-9245-48fb-943b-715b46cd09f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0ffca0>]}
2021-01-19 14:48:55.691132 (Thread-1): 15:48:55 | 3 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.00s]
2021-01-19 14:48:55.691320 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 14:48:55.691550 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:48:55.693842 (Thread-1): 15:48:55 | 4 of 5 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:48:55.694251 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:48:55.694389 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:48:55.701896 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:48:55.702389 (Thread-1): finished collecting timing info
2021-01-19 14:48:55.707635 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:48:55.709108 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:48:55.709333 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:48:55.709515 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:48:56.904605 (Thread-1): SQL status: SUCCESS 1 in 1.20 seconds
2021-01-19 14:48:56.904880 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:48:56.905046 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:48:58.763047 (Thread-1): SQL status: SUCCESS 1 in 1.86 seconds
2021-01-19 14:48:58.764385 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:48:58.764611 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:48:58.764735 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:48:59.063278 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 14:48:59.066049 (Thread-1): finished collecting timing info
2021-01-19 14:48:59.066386 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:48:59.578077 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fe04a2-9245-48fb-943b-715b46cd09f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf5370>]}
2021-01-19 14:48:59.579426 (Thread-1): 15:48:59 | 4 of 5 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.88s]
2021-01-19 14:48:59.579596 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:48:59.579824 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:48:59.581289 (Thread-1): 15:48:59 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 14:48:59.581630 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:48:59.581771 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:48:59.592236 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:48:59.592732 (Thread-1): finished collecting timing info
2021-01-19 14:48:59.597800 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:48:59.598708 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:48:59.598822 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:48:59.598932 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:49:00.788213 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-01-19 14:49:00.788482 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:49:00.788638 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
2021-01-19 14:49:01.828054 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 14:49:01.829343 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:49:01.829576 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:49:01.829702 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:49:01.991544 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:49:01.994509 (Thread-1): finished collecting timing info
2021-01-19 14:49:01.994843 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:49:02.263661 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fe04a2-9245-48fb-943b-715b46cd09f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d408b0>]}
2021-01-19 14:49:02.264874 (Thread-1): 15:49:02 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.68s]
2021-01-19 14:49:02.265030 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:49:02.266493 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:49:02.266722 (MainThread): Using snowflake connection "master".
2021-01-19 14:49:02.266827 (MainThread): On master: BEGIN
2021-01-19 14:49:02.266930 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:49:03.328549 (MainThread): SQL status: SUCCESS 1 in 1.06 seconds
2021-01-19 14:49:03.328782 (MainThread): On master: COMMIT
2021-01-19 14:49:03.328985 (MainThread): Using snowflake connection "master".
2021-01-19 14:49:03.329102 (MainThread): On master: COMMIT
2021-01-19 14:49:03.549545 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 14:49:03.549749 (MainThread): On master: Close
2021-01-19 14:49:03.874507 (MainThread): 15:49:03 | 
2021-01-19 14:49:03.874748 (MainThread): 15:49:03 | Finished running 4 table models, 1 incremental model in 25.07s.
2021-01-19 14:49:03.874913 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:49:03.875118 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:49:03.894005 (MainThread): 
2021-01-19 14:49:03.894191 (MainThread): Completed successfully
2021-01-19 14:49:03.894325 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-01-19 14:49:03.894516 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b7d790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0fa7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dbb7c0>]}
2021-01-19 14:49:03.894740 (MainThread): Flushing usage events
2021-01-19 14:50:03.909420 (MainThread): Running with dbt=0.18.1
2021-01-19 14:50:03.986355 (MainThread): Loading KWallet
2021-01-19 14:50:03.986979 (MainThread): Loading SecretService
2021-01-19 14:50:03.987447 (MainThread): Loading Windows
2021-01-19 14:50:03.988079 (MainThread): Loading chainer
2021-01-19 14:50:03.988391 (MainThread): Loading macOS
2021-01-19 14:50:04.280541 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:50:04.281614 (MainThread): Tracking: tracking
2021-01-19 14:50:04.281915 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10825f4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10846dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10846d2e0>]}
2021-01-19 14:50:04.319262 (MainThread): Got an acceptable cached parse result
2021-01-19 14:50:04.358025 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:50:04.433929 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 14:50:04.533575 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:50:04.535785 (MainThread): 
2021-01-19 14:50:04.536739 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:50:04.543153 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:50:04.555934 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:50:04.556240 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:50:04.556375 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:50:06.006936 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.45 seconds
2021-01-19 14:50:06.011403 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:50:06.294622 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:50:06.302772 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:50:06.302919 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:50:06.303030 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:50:07.346629 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 1.04 seconds
2021-01-19 14:50:07.351698 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:50:07.731349 (MainThread): Using snowflake connection "master".
2021-01-19 14:50:07.731540 (MainThread): On master: BEGIN
2021-01-19 14:50:07.731673 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:50:08.569318 (MainThread): SQL status: SUCCESS 1 in 0.84 seconds
2021-01-19 14:50:08.569573 (MainThread): On master: COMMIT
2021-01-19 14:50:08.569837 (MainThread): Using snowflake connection "master".
2021-01-19 14:50:08.569989 (MainThread): On master: COMMIT
2021-01-19 14:50:09.302334 (MainThread): SQL status: SUCCESS 1 in 0.73 seconds
2021-01-19 14:50:09.302617 (MainThread): On master: Close
2021-01-19 14:50:09.562979 (MainThread): 15:50:09 | Concurrency: 1 threads (target='dev')
2021-01-19 14:50:09.563190 (MainThread): 15:50:09 | 
2021-01-19 14:50:09.565333 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:50:09.565710 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:50:09.565864 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:50:09.588957 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:50:09.589565 (Thread-1): finished collecting timing info
2021-01-19 14:50:09.590224 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:50:09.590393 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:50:09.591713 (Thread-1): 15:50:09 | 1 of 4 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:50:09.592042 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:50:09.592170 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:50:09.599666 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:50:09.600101 (Thread-1): finished collecting timing info
2021-01-19 14:50:09.681042 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:50:09.682191 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:50:09.682313 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:50:09.682428 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:50:11.303085 (Thread-1): SQL status: SUCCESS 1 in 1.62 seconds
2021-01-19 14:50:11.303309 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:50:11.303443 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 14:50:15.823298 (Thread-1): SQL status: SUCCESS 1 in 4.52 seconds
2021-01-19 14:50:15.824721 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:50:15.824924 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:50:15.825031 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:50:16.003978 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 14:50:16.019570 (Thread-1): finished collecting timing info
2021-01-19 14:50:16.019898 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:50:16.377592 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b2c8c02-9df9-468c-85cb-8494288c0bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109282490>]}
2021-01-19 14:50:16.378958 (Thread-1): 15:50:16 | 1 of 4 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 6.79s]
2021-01-19 14:50:16.379131 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:50:16.379294 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 14:50:16.380845 (Thread-1): 15:50:16 | 2 of 4 START incremental model dbt.dates............................. [RUN]
2021-01-19 14:50:16.381181 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:16.381309 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 14:50:16.397725 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 14:50:16.398231 (Thread-1): finished collecting timing info
2021-01-19 14:50:16.429885 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:16.430047 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 14:50:16.430154 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:50:18.423173 (Thread-1): SQL status: SUCCESS 1 in 1.99 seconds
2021-01-19 14:50:18.434015 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:18.434158 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 14:50:18.609956 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 14:50:18.615674 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:18.615793 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 14:50:18.780929 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 14:50:18.787304 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:18.787454 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 14:50:18.965324 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 14:50:18.994702 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 14:50:18.997963 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:18.998098 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 14:50:19.344736 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2021-01-19 14:50:19.355869 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:19.356804 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 14:50:19.810780 (Thread-1): SQL status: SUCCESS 0 in 0.45 seconds
2021-01-19 14:50:19.811925 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:50:19.812141 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:50:19.812264 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:50:20.103908 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2021-01-19 14:50:20.108798 (Thread-1): finished collecting timing info
2021-01-19 14:50:20.109199 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 14:50:20.516823 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b2c8c02-9df9-468c-85cb-8494288c0bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10952e250>]}
2021-01-19 14:50:20.518159 (Thread-1): 15:50:20 | 2 of 4 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.14s]
2021-01-19 14:50:20.518321 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 14:50:20.518478 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:50:20.519971 (Thread-1): 15:50:20 | 3 of 4 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:50:20.520306 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:50:20.520436 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:50:20.528474 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:50:20.528998 (Thread-1): finished collecting timing info
2021-01-19 14:50:20.533835 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:50:20.535017 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:50:20.535128 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:50:20.535233 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:50:22.109548 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2021-01-19 14:50:22.109763 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:50:22.109912 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:50:24.474952 (Thread-1): SQL status: SUCCESS 1 in 2.36 seconds
2021-01-19 14:50:24.476020 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:50:24.476202 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:50:24.476297 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:50:24.628458 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:50:24.630655 (Thread-1): finished collecting timing info
2021-01-19 14:50:24.630918 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:50:24.920818 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b2c8c02-9df9-468c-85cb-8494288c0bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109235850>]}
2021-01-19 14:50:24.922107 (Thread-1): 15:50:24 | 3 of 4 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 4.40s]
2021-01-19 14:50:24.922274 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:50:24.922429 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:50:24.924386 (Thread-1): 15:50:24 | 4 of 4 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 14:50:24.924974 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:50:24.925121 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:50:24.936869 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:50:24.937368 (Thread-1): finished collecting timing info
2021-01-19 14:50:24.943204 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:50:24.944509 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:50:24.944624 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:50:24.944728 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:50:26.512723 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2021-01-19 14:50:26.512907 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:50:26.513014 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__CTE__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models



select *
from __dbt__CTE__my_first_dbt_model
where id = 1
      );
2021-01-19 14:50:28.043703 (Thread-1): SQL status: SUCCESS 1 in 1.53 seconds
2021-01-19 14:50:28.044792 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:50:28.044982 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:50:28.045085 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:50:28.297174 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 14:50:28.300045 (Thread-1): finished collecting timing info
2021-01-19 14:50:28.300280 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:50:28.566998 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b2c8c02-9df9-468c-85cb-8494288c0bab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091457c0>]}
2021-01-19 14:50:28.568265 (Thread-1): 15:50:28 | 4 of 4 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.64s]
2021-01-19 14:50:28.568424 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:50:28.569865 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:50:28.570137 (MainThread): Using snowflake connection "master".
2021-01-19 14:50:28.570246 (MainThread): On master: BEGIN
2021-01-19 14:50:28.570353 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:50:30.379918 (MainThread): SQL status: SUCCESS 1 in 1.81 seconds
2021-01-19 14:50:30.380153 (MainThread): On master: COMMIT
2021-01-19 14:50:30.380355 (MainThread): Using snowflake connection "master".
2021-01-19 14:50:30.380474 (MainThread): On master: COMMIT
2021-01-19 14:50:30.877498 (MainThread): SQL status: SUCCESS 1 in 0.50 seconds
2021-01-19 14:50:30.877777 (MainThread): On master: Close
2021-01-19 14:50:31.145882 (MainThread): 15:50:31 | 
2021-01-19 14:50:31.146078 (MainThread): 15:50:31 | Finished running 3 table models, 1 incremental model in 26.61s.
2021-01-19 14:50:31.146216 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:50:31.146391 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:50:31.160914 (MainThread): 
2021-01-19 14:50:31.161094 (MainThread): Completed successfully
2021-01-19 14:50:31.161224 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-01-19 14:50:31.161410 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f0b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109001e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090017c0>]}
2021-01-19 14:50:31.161612 (MainThread): Flushing usage events
2021-01-19 14:56:59.526940 (MainThread): Running with dbt=0.18.1
2021-01-19 14:56:59.603476 (MainThread): Loading KWallet
2021-01-19 14:56:59.604163 (MainThread): Loading SecretService
2021-01-19 14:56:59.604639 (MainThread): Loading Windows
2021-01-19 14:56:59.605265 (MainThread): Loading chainer
2021-01-19 14:56:59.605583 (MainThread): Loading macOS
2021-01-19 14:56:59.922722 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 14:56:59.923715 (MainThread): Tracking: tracking
2021-01-19 14:56:59.923986 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b49550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d58040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d58d90>]}
2021-01-19 14:56:59.962417 (MainThread): Got an acceptable cached parse result
2021-01-19 14:57:00.007063 (MainThread): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 14:57:00.232346 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 14:57:00.350066 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 14:57:00.352311 (MainThread): 
2021-01-19 14:57:00.352970 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:57:00.359753 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 14:57:00.374892 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 14:57:00.375035 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 14:57:00.375125 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 14:57:02.031626 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.66 seconds
2021-01-19 14:57:02.035819 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 14:57:02.448426 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 14:57:02.456513 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 14:57:02.456652 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 14:57:02.456763 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 14:57:03.649574 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 3 in 1.19 seconds
2021-01-19 14:57:03.653590 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 14:57:04.301366 (MainThread): Using snowflake connection "master".
2021-01-19 14:57:04.301535 (MainThread): On master: BEGIN
2021-01-19 14:57:04.301647 (MainThread): Opening a new connection, currently in state init
2021-01-19 14:57:05.382807 (MainThread): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 14:57:05.383020 (MainThread): On master: COMMIT
2021-01-19 14:57:05.383213 (MainThread): Using snowflake connection "master".
2021-01-19 14:57:05.383317 (MainThread): On master: COMMIT
2021-01-19 14:57:05.622575 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 14:57:05.622788 (MainThread): On master: Close
2021-01-19 14:57:05.896260 (MainThread): 15:57:05 | Concurrency: 1 threads (target='dev')
2021-01-19 14:57:05.896474 (MainThread): 15:57:05 | 
2021-01-19 14:57:05.898701 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:57:05.899095 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 14:57:05.899242 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 14:57:05.923043 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 14:57:05.923562 (Thread-1): finished collecting timing info
2021-01-19 14:57:05.924070 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 14:57:05.924230 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:57:05.925355 (Thread-1): 15:57:05 | 1 of 5 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 14:57:05.925828 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:57:05.925962 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:57:05.933852 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:57:05.934315 (Thread-1): finished collecting timing info
2021-01-19 14:57:05.970170 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 14:57:05.971165 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:57:05.971267 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 14:57:05.971361 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:57:07.041663 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2021-01-19 14:57:07.041929 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:57:07.042091 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 14:57:09.025371 (Thread-1): SQL status: SUCCESS 1 in 1.98 seconds
2021-01-19 14:57:09.027067 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:57:09.027276 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 14:57:09.027396 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 14:57:09.176136 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:57:09.191408 (Thread-1): finished collecting timing info
2021-01-19 14:57:09.191810 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 14:57:09.452851 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9642504d-cf0a-4601-babe-3670962f3492', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b979d0>]}
2021-01-19 14:57:09.454326 (Thread-1): 15:57:09 | 1 of 5 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.53s]
2021-01-19 14:57:09.454542 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 14:57:09.454884 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 14:57:09.456918 (Thread-1): 15:57:09 | 2 of 5 START incremental model dbt.dates............................. [RUN]
2021-01-19 14:57:09.457279 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:09.457411 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 14:57:09.471614 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 14:57:09.472189 (Thread-1): finished collecting timing info
2021-01-19 14:57:09.507658 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:09.507828 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 14:57:09.507965 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:57:11.522804 (Thread-1): SQL status: SUCCESS 1 in 2.01 seconds
2021-01-19 14:57:11.535005 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:11.535164 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 14:57:11.940017 (Thread-1): SQL status: SUCCESS 28 in 0.40 seconds
2021-01-19 14:57:11.946077 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:11.946200 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 14:57:12.132653 (Thread-1): SQL status: SUCCESS 28 in 0.19 seconds
2021-01-19 14:57:12.137940 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:12.138071 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 14:57:12.353430 (Thread-1): SQL status: SUCCESS 28 in 0.22 seconds
2021-01-19 14:57:12.382202 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 14:57:12.385471 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:12.385598 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 14:57:12.560654 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 14:57:12.560897 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:12.561063 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 14:57:13.398230 (Thread-1): SQL status: SUCCESS 0 in 0.84 seconds
2021-01-19 14:57:13.399706 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:57:13.399921 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 14:57:13.400038 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 14:57:13.643167 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 14:57:13.647864 (Thread-1): finished collecting timing info
2021-01-19 14:57:13.648151 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 14:57:13.962114 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9642504d-cf0a-4601-babe-3670962f3492', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bc730>]}
2021-01-19 14:57:13.963848 (Thread-1): 15:57:13 | 2 of 5 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.50s]
2021-01-19 14:57:13.964040 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 14:57:13.964221 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 14:57:13.965552 (Thread-1): 15:57:13 | 3 of 5 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 14:57:13.966055 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 14:57:13.966196 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 14:57:13.974762 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 14:57:13.975204 (Thread-1): finished collecting timing info
2021-01-19 14:57:13.981219 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 14:57:13.982186 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 14:57:13.982302 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 14:57:13.982404 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:57:15.207743 (Thread-1): SQL status: SUCCESS 1 in 1.23 seconds
2021-01-19 14:57:15.207996 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 14:57:15.208140 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


      );
2021-01-19 14:57:16.776533 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2021-01-19 14:57:16.777632 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 14:57:16.777809 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 14:57:16.777907 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 14:57:16.938796 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 14:57:16.943673 (Thread-1): finished collecting timing info
2021-01-19 14:57:16.944050 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 14:57:17.394086 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9642504d-cf0a-4601-babe-3670962f3492', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a857c0>]}
2021-01-19 14:57:17.395403 (Thread-1): 15:57:17 | 3 of 5 OK created incremental model dbt.incremental_time............. [SUCCESS 1 in 3.43s]
2021-01-19 14:57:17.395562 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 14:57:17.395721 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:57:17.397526 (Thread-1): 15:57:17 | 4 of 5 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 14:57:17.397944 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:57:17.398090 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:57:17.405471 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:57:17.405936 (Thread-1): finished collecting timing info
2021-01-19 14:57:17.410858 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 14:57:17.412015 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:57:17.412127 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 14:57:17.412231 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:57:18.445367 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-01-19 14:57:18.445625 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:57:18.445802 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 14:57:20.901232 (Thread-1): SQL status: SUCCESS 1 in 2.46 seconds
2021-01-19 14:57:20.902554 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:57:20.902760 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 14:57:20.902879 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 14:57:21.057830 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:57:21.060951 (Thread-1): finished collecting timing info
2021-01-19 14:57:21.061298 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 14:57:21.314672 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9642504d-cf0a-4601-babe-3670962f3492', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107916c70>]}
2021-01-19 14:57:21.316190 (Thread-1): 15:57:21 | 4 of 5 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.92s]
2021-01-19 14:57:21.316372 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 14:57:21.316547 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:57:21.318220 (Thread-1): 15:57:21 | 5 of 5 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 14:57:21.318582 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:57:21.318721 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 14:57:21.329501 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:57:21.329981 (Thread-1): finished collecting timing info
2021-01-19 14:57:21.335172 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 14:57:21.336472 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:57:21.336586 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 14:57:21.336689 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 14:57:22.511797 (Thread-1): SQL status: SUCCESS 1 in 1.18 seconds
2021-01-19 14:57:22.512026 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:57:22.512125 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__CTE__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models



select *
from __dbt__CTE__my_first_dbt_model
where id = 1
      );
2021-01-19 14:57:23.330762 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 14:57:23.332314 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:57:23.332577 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 14:57:23.332723 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 14:57:23.480342 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 14:57:23.482876 (Thread-1): finished collecting timing info
2021-01-19 14:57:23.483162 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 14:57:23.744748 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9642504d-cf0a-4601-babe-3670962f3492', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107dfefa0>]}
2021-01-19 14:57:23.746300 (Thread-1): 15:57:23 | 5 of 5 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.43s]
2021-01-19 14:57:23.746644 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 14:57:23.748152 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 14:57:23.748382 (MainThread): Using snowflake connection "master".
2021-01-19 14:57:23.748487 (MainThread): On master: BEGIN
2021-01-19 14:57:23.748590 (MainThread): Opening a new connection, currently in state closed
2021-01-19 14:57:24.850478 (MainThread): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 14:57:24.850768 (MainThread): On master: COMMIT
2021-01-19 14:57:24.850965 (MainThread): Using snowflake connection "master".
2021-01-19 14:57:24.851077 (MainThread): On master: COMMIT
2021-01-19 14:57:25.075032 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 14:57:25.075240 (MainThread): On master: Close
2021-01-19 14:57:25.344303 (MainThread): 15:57:25 | 
2021-01-19 14:57:25.344529 (MainThread): 15:57:25 | Finished running 3 table models, 2 incremental models in 24.99s.
2021-01-19 14:57:25.344676 (MainThread): Connection 'master' was properly closed.
2021-01-19 14:57:25.344786 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 14:57:25.363567 (MainThread): 
2021-01-19 14:57:25.363748 (MainThread): Completed successfully
2021-01-19 14:57:25.363878 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-01-19 14:57:25.364064 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b82910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b82d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b82b80>]}
2021-01-19 14:57:25.364269 (MainThread): Flushing usage events
2021-01-19 15:20:53.549603 (MainThread): Running with dbt=0.18.1
2021-01-19 15:20:53.634295 (MainThread): Loading KWallet
2021-01-19 15:20:53.634979 (MainThread): Loading SecretService
2021-01-19 15:20:53.635497 (MainThread): Loading Windows
2021-01-19 15:20:53.636171 (MainThread): Loading chainer
2021-01-19 15:20:53.636511 (MainThread): Loading macOS
2021-01-19 15:20:53.963435 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:20:53.964365 (MainThread): Tracking: tracking
2021-01-19 15:20:53.964621 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe52850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110061040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110061d90>]}
2021-01-19 15:20:54.008517 (MainThread): Got an acceptable cached parse result
2021-01-19 15:20:54.050973 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:20:54.133369 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:20:54.243294 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:20:54.245456 (MainThread): 
2021-01-19 15:20:54.245953 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:20:54.254895 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:20:54.270943 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:20:54.271096 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:20:54.271249 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:20:55.586878 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.32 seconds
2021-01-19 15:20:55.591688 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:20:55.872330 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:20:55.881211 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:20:55.881384 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:20:55.881499 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:20:56.709439 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 5 in 0.83 seconds
2021-01-19 15:20:56.715905 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:20:56.981082 (MainThread): Using snowflake connection "master".
2021-01-19 15:20:56.981270 (MainThread): On master: BEGIN
2021-01-19 15:20:56.981386 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:20:58.788192 (MainThread): SQL status: SUCCESS 1 in 1.81 seconds
2021-01-19 15:20:58.788476 (MainThread): On master: COMMIT
2021-01-19 15:20:58.788735 (MainThread): Using snowflake connection "master".
2021-01-19 15:20:58.788856 (MainThread): On master: COMMIT
2021-01-19 15:20:59.112435 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:20:59.112996 (MainThread): On master: Close
2021-01-19 15:20:59.397913 (MainThread): 16:20:59 | Concurrency: 1 threads (target='dev')
2021-01-19 15:20:59.398142 (MainThread): 16:20:59 | 
2021-01-19 15:20:59.400337 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:20:59.401746 (Thread-1): 16:20:59 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:20:59.402155 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:20:59.402316 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:20:59.426153 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:20:59.426636 (Thread-1): finished collecting timing info
2021-01-19 15:20:59.509882 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:20:59.531176 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:20:59.531332 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:20:59.531447 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:21:01.333687 (Thread-1): SQL status: SUCCESS 1 in 1.80 seconds
2021-01-19 15:21:01.333904 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:21:01.334018 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:21:11.726812 (Thread-1): SQL status: SUCCESS 1 in 10.39 seconds
2021-01-19 15:21:11.728255 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:21:11.728633 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:21:11.728839 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:21:11.937311 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 15:21:11.953420 (Thread-1): finished collecting timing info
2021-01-19 15:21:11.953761 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:21:12.254556 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '686e1f69-b49f-41fc-9db1-0a60b2b10308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bc7d90>]}
2021-01-19 15:21:12.255860 (Thread-1): 16:21:12 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 12.85s]
2021-01-19 15:21:12.256025 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:21:12.256184 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:21:12.257936 (Thread-1): 16:21:12 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:21:12.258387 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:21:12.258529 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:21:12.267244 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:21:12.267773 (Thread-1): finished collecting timing info
2021-01-19 15:21:12.272882 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:21:12.273961 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:21:12.274086 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:21:12.274197 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:21:13.461823 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2021-01-19 15:21:13.462027 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:21:13.462143 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:21:15.864007 (Thread-1): SQL status: SUCCESS 1 in 2.40 seconds
2021-01-19 15:21:15.865572 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:21:15.865850 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:21:15.865962 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:21:16.020012 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 15:21:16.022594 (Thread-1): finished collecting timing info
2021-01-19 15:21:16.022883 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:21:16.346110 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '686e1f69-b49f-41fc-9db1-0a60b2b10308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b0a6d0>]}
2021-01-19 15:21:16.348049 (Thread-1): 16:21:16 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 4.09s]
2021-01-19 15:21:16.348259 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:21:16.348422 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 15:21:16.349775 (Thread-1): 16:21:16 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 15:21:16.350217 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:16.350367 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 15:21:16.367527 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 15:21:16.368018 (Thread-1): finished collecting timing info
2021-01-19 15:21:16.402668 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:16.402849 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 15:21:16.402967 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:21:20.940219 (Thread-1): SQL status: SUCCESS 1 in 4.54 seconds
2021-01-19 15:21:20.952100 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:20.952270 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 15:21:21.132161 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 15:21:21.138644 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:21.138810 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:21:21.306966 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 15:21:21.313035 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:21.313211 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:21:21.475047 (Thread-1): SQL status: SUCCESS 28 in 0.16 seconds
2021-01-19 15:21:21.503576 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 15:21:21.506669 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:21.506788 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 15:21:21.672736 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:21:21.672922 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:21.673028 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 15:21:22.363643 (Thread-1): SQL status: SUCCESS 0 in 0.69 seconds
2021-01-19 15:21:22.365126 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:21:22.365339 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:21:22.365461 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:21:22.663565 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 15:21:22.667745 (Thread-1): finished collecting timing info
2021-01-19 15:21:22.668044 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 15:21:22.937465 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '686e1f69-b49f-41fc-9db1-0a60b2b10308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e1ff70>]}
2021-01-19 15:21:22.938832 (Thread-1): 16:21:22 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 6.59s]
2021-01-19 15:21:22.939014 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 15:21:22.939197 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 15:21:22.941028 (Thread-1): 16:21:22 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 15:21:22.941380 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:22.941509 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 15:21:22.950814 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:21:22.951313 (Thread-1): finished collecting timing info
2021-01-19 15:21:22.957966 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:22.958117 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 15:21:22.958233 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:21:25.326795 (Thread-1): SQL status: SUCCESS 1 in 2.37 seconds
2021-01-19 15:21:25.330436 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:25.330599 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 15:21:25.507396 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-19 15:21:25.511437 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:25.511583 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:21:25.690166 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-19 15:21:25.694990 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:25.695132 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:21:26.145541 (Thread-1): SQL status: SUCCESS 10 in 0.45 seconds
2021-01-19 15:21:26.148791 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:21:26.150552 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:26.150669 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 15:21:26.341153 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-01-19 15:21:26.341334 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:26.341439 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 15:21:27.271949 (Thread-1): SQL status: SUCCESS 1448 in 0.93 seconds
2021-01-19 15:21:27.273214 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:21:27.273448 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:21:27.273573 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:21:27.700467 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-01-19 15:21:27.705056 (Thread-1): finished collecting timing info
2021-01-19 15:21:27.705348 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 15:21:27.972794 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '686e1f69-b49f-41fc-9db1-0a60b2b10308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110da73d0>]}
2021-01-19 15:21:27.974056 (Thread-1): 16:21:27 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 1448 in 5.03s]
2021-01-19 15:21:27.974319 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 15:21:27.974542 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:21:27.976461 (Thread-1): 16:21:27 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 15:21:27.976838 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:21:27.976986 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:21:27.984988 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:21:27.985494 (Thread-1): finished collecting timing info
2021-01-19 15:21:27.990430 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:21:27.991579 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:21:27.991690 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 15:21:27.991794 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:21:29.250282 (Thread-1): SQL status: SUCCESS 1 in 1.26 seconds
2021-01-19 15:21:29.250485 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:21:29.250593 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 15:21:31.123820 (Thread-1): SQL status: SUCCESS 1 in 1.87 seconds
2021-01-19 15:21:31.124925 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:21:31.125102 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:21:31.125207 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:21:31.365055 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 15:21:31.367824 (Thread-1): finished collecting timing info
2021-01-19 15:21:31.368178 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 15:21:31.728177 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '686e1f69-b49f-41fc-9db1-0a60b2b10308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110df72e0>]}
2021-01-19 15:21:31.729598 (Thread-1): 16:21:31 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.75s]
2021-01-19 15:21:31.729769 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:21:31.729930 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:21:31.731234 (Thread-1): 16:21:31 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 15:21:31.731564 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:21:31.731693 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 15:21:31.741102 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:21:31.741579 (Thread-1): finished collecting timing info
2021-01-19 15:21:31.746881 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:21:31.747845 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:21:31.747965 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 15:21:31.748076 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:21:33.037930 (Thread-1): SQL status: SUCCESS 1 in 1.29 seconds
2021-01-19 15:21:33.038197 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:21:33.038349 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 15:21:34.141041 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 15:21:34.142260 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:21:34.142455 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:21:34.142567 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:21:34.312233 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:21:34.315376 (Thread-1): finished collecting timing info
2021-01-19 15:21:34.315731 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 15:21:34.575690 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '686e1f69-b49f-41fc-9db1-0a60b2b10308', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111245640>]}
2021-01-19 15:21:34.577061 (Thread-1): 16:21:34 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.84s]
2021-01-19 15:21:34.577236 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:21:34.578917 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:21:34.579226 (MainThread): Using snowflake connection "master".
2021-01-19 15:21:34.579345 (MainThread): On master: BEGIN
2021-01-19 15:21:34.579459 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:21:35.950561 (MainThread): SQL status: SUCCESS 1 in 1.37 seconds
2021-01-19 15:21:35.950959 (MainThread): On master: COMMIT
2021-01-19 15:21:35.951336 (MainThread): Using snowflake connection "master".
2021-01-19 15:21:35.951551 (MainThread): On master: COMMIT
2021-01-19 15:21:36.225197 (MainThread): SQL status: SUCCESS 1 in 0.27 seconds
2021-01-19 15:21:36.225437 (MainThread): On master: Close
2021-01-19 15:21:36.492159 (MainThread): 16:21:36 | 
2021-01-19 15:21:36.492405 (MainThread): 16:21:36 | Finished running 4 table models, 2 incremental models in 42.25s.
2021-01-19 15:21:36.492597 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:21:36.492793 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 15:21:36.515153 (MainThread): 
2021-01-19 15:21:36.515329 (MainThread): Completed successfully
2021-01-19 15:21:36.515494 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 15:21:36.515679 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110eb6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110eb760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e28ac0>]}
2021-01-19 15:21:36.515953 (MainThread): Flushing usage events
2021-01-19 15:32:44.035540 (MainThread): Running with dbt=0.18.1
2021-01-19 15:32:44.112217 (MainThread): Loading KWallet
2021-01-19 15:32:44.112814 (MainThread): Loading SecretService
2021-01-19 15:32:44.113254 (MainThread): Loading Windows
2021-01-19 15:32:44.113854 (MainThread): Loading chainer
2021-01-19 15:32:44.114428 (MainThread): Loading macOS
2021-01-19 15:32:44.406064 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:32:44.407086 (MainThread): Tracking: tracking
2021-01-19 15:32:44.407606 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106613ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106822040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106822d90>]}
2021-01-19 15:32:44.434461 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='b17bc49c0e5698b8b3aa3772dc09e1ed6154bdd3305856dfaf0d6d59c0a13448') -> FileHash(name='sha256', checksum='fd440892294acab26b9164df856cb4c120f695ff7849c92db9a8b71e7ff11b85')), cache invalidated
2021-01-19 15:32:44.435500 (MainThread): Parsing macros/catalog.sql
2021-01-19 15:32:44.437691 (MainThread): Parsing macros/adapters.sql
2021-01-19 15:32:44.466221 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 15:32:44.468084 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 15:32:44.469515 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 15:32:44.476020 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 15:32:44.487662 (MainThread): Parsing macros/core.sql
2021-01-19 15:32:44.490987 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 15:32:44.499541 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 15:32:44.501142 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 15:32:44.517719 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 15:32:44.547450 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 15:32:44.567943 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 15:32:44.569701 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 15:32:44.575519 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 15:32:44.589234 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 15:32:44.595561 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 15:32:44.602667 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 15:32:44.607880 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 15:32:44.608751 (MainThread): Parsing macros/etc/query.sql
2021-01-19 15:32:44.609709 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 15:32:44.611200 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 15:32:44.620061 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 15:32:44.621890 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 15:32:44.623649 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 15:32:44.665970 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 15:32:44.667843 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 15:32:44.669571 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 15:32:44.671423 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 15:32:44.681962 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='b17bc49c0e5698b8b3aa3772dc09e1ed6154bdd3305856dfaf0d6d59c0a13448') -> FileHash(name='sha256', checksum='fd440892294acab26b9164df856cb4c120f695ff7849c92db9a8b71e7ff11b85')), cache invalidated
2021-01-19 15:32:44.720185 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:32:44.742085 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:32:44.752252 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:32:44.763953 (MainThread): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:44.778264 (MainThread): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:32:44.789975 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:32:44.985254 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:32:45.025448 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_learn.example.vars

2021-01-19 15:32:45.093613 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:32:45.094464 (MainThread): 
2021-01-19 15:32:45.094732 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:32:45.102074 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:32:45.117193 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:32:45.117324 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:32:45.117408 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:32:46.613997 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.50 seconds
2021-01-19 15:32:46.618758 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:32:46.950247 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:32:46.958294 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:32:46.958431 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:32:46.958543 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:32:48.117728 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.16 seconds
2021-01-19 15:32:48.124708 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:32:48.410412 (MainThread): Using snowflake connection "master".
2021-01-19 15:32:48.410576 (MainThread): On master: BEGIN
2021-01-19 15:32:48.410691 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:32:49.521403 (MainThread): SQL status: SUCCESS 1 in 1.11 seconds
2021-01-19 15:32:49.521638 (MainThread): On master: COMMIT
2021-01-19 15:32:49.521837 (MainThread): Using snowflake connection "master".
2021-01-19 15:32:49.521952 (MainThread): On master: COMMIT
2021-01-19 15:32:49.770256 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 15:32:49.770498 (MainThread): On master: Close
2021-01-19 15:32:50.215909 (MainThread): 16:32:50 | Concurrency: 1 threads (target='dev')
2021-01-19 15:32:50.216128 (MainThread): 16:32:50 | 
2021-01-19 15:32:50.218042 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:32:50.219349 (Thread-1): 16:32:50 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:32:50.219673 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:32:50.219807 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:32:50.243578 (Thread-1): finished collecting timing info
2021-01-19 15:32:50.244177 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/compilation.py", line 385, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 19, in top-level template code
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/context/base.py", line 148, in __call__
    return self.get_missing_var(var_name)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/context/base.py", line 129, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 15:32:50.250785 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaff2c66-50da-46d2-a969-22c347986fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107630430>]}
2021-01-19 15:32:50.252101 (Thread-1): 16:32:50 | 1 of 6 ERROR creating table model dbt.first_model.................... [ERROR in 0.03s]
2021-01-19 15:32:50.252263 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:32:50.252417 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:32:50.253470 (Thread-1): 16:32:50 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:32:50.254024 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:32:50.254157 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:32:50.261371 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:32:50.261791 (Thread-1): finished collecting timing info
2021-01-19 15:32:50.297844 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:32:50.299148 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:32:50.299285 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:32:50.299388 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:32:51.148199 (Thread-1): SQL status: SUCCESS 1 in 0.85 seconds
2021-01-19 15:32:51.148462 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:32:51.148730 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:32:54.937302 (Thread-1): SQL status: SUCCESS 1 in 3.79 seconds
2021-01-19 15:32:54.938704 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:32:54.938913 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:32:54.939032 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:32:55.197157 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-19 15:32:55.212610 (Thread-1): finished collecting timing info
2021-01-19 15:32:55.212928 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:32:55.488997 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaff2c66-50da-46d2-a969-22c347986fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074b2070>]}
2021-01-19 15:32:55.490543 (Thread-1): 16:32:55 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 5.23s]
2021-01-19 15:32:55.490733 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:32:55.490930 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 15:32:55.493123 (Thread-1): 16:32:55 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 15:32:55.493605 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:55.493749 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 15:32:55.505497 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 15:32:55.506016 (Thread-1): finished collecting timing info
2021-01-19 15:32:55.538078 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:55.538282 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 15:32:55.538401 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:32:57.962715 (Thread-1): SQL status: SUCCESS 1 in 2.42 seconds
2021-01-19 15:32:57.973429 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:57.973559 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 15:32:58.149255 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 15:32:58.155246 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:58.155368 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:32:58.314280 (Thread-1): SQL status: SUCCESS 28 in 0.16 seconds
2021-01-19 15:32:58.320565 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:58.320684 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:32:58.499485 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 15:32:58.528067 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 15:32:58.531203 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:58.531321 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 15:32:58.704318 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:32:58.704506 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:58.704610 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 15:32:59.190964 (Thread-1): SQL status: SUCCESS 0 in 0.49 seconds
2021-01-19 15:32:59.192522 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:32:59.192782 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:32:59.192900 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:32:59.497209 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 15:32:59.501083 (Thread-1): finished collecting timing info
2021-01-19 15:32:59.501359 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 15:32:59.766456 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaff2c66-50da-46d2-a969-22c347986fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075fb610>]}
2021-01-19 15:32:59.767955 (Thread-1): 16:32:59 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.27s]
2021-01-19 15:32:59.768139 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 15:32:59.768322 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 15:32:59.769644 (Thread-1): 16:32:59 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 15:32:59.770013 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:32:59.770138 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 15:32:59.778665 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:32:59.779089 (Thread-1): finished collecting timing info
2021-01-19 15:32:59.785581 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:32:59.785717 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 15:32:59.785827 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:33:01.750674 (Thread-1): SQL status: SUCCESS 1 in 1.96 seconds
2021-01-19 15:33:01.753538 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:33:01.753654 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 15:33:02.980202 (Thread-1): SQL status: SUCCESS 10 in 1.23 seconds
2021-01-19 15:33:02.984701 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:33:02.984851 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:33:03.158214 (Thread-1): SQL status: SUCCESS 10 in 0.17 seconds
2021-01-19 15:33:03.162800 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:33:03.162901 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:33:03.320484 (Thread-1): SQL status: SUCCESS 10 in 0.16 seconds
2021-01-19 15:33:03.323764 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:33:03.325960 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:33:03.326092 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 15:33:03.530245 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 15:33:03.530426 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:33:03.530523 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 15:33:04.515469 (Thread-1): SQL status: SUCCESS 697 in 0.98 seconds
2021-01-19 15:33:04.516959 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:33:04.517223 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:33:04.517337 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:33:04.851756 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 15:33:04.856482 (Thread-1): finished collecting timing info
2021-01-19 15:33:04.856805 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 15:33:05.148701 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaff2c66-50da-46d2-a969-22c347986fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d958190>]}
2021-01-19 15:33:05.150176 (Thread-1): 16:33:05 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 697 in 5.38s]
2021-01-19 15:33:05.150354 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 15:33:05.150532 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:33:05.151973 (Thread-1): 16:33:05 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 15:33:05.152328 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:33:05.152498 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:33:05.160378 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:33:05.160829 (Thread-1): finished collecting timing info
2021-01-19 15:33:05.165754 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:33:05.167026 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:33:05.167141 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 15:33:05.167244 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:33:06.467901 (Thread-1): SQL status: SUCCESS 1 in 1.30 seconds
2021-01-19 15:33:06.468168 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:33:06.468330 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 15:33:08.509061 (Thread-1): SQL status: SUCCESS 1 in 2.04 seconds
2021-01-19 15:33:08.510668 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:33:08.510965 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:33:08.511090 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:33:08.654801 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-01-19 15:33:08.657469 (Thread-1): finished collecting timing info
2021-01-19 15:33:08.657744 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 15:33:08.925719 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaff2c66-50da-46d2-a969-22c347986fa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10745cdc0>]}
2021-01-19 15:33:08.926940 (Thread-1): 16:33:08 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.77s]
2021-01-19 15:33:08.927089 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:33:08.927256 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:33:08.927465 (Thread-1): 16:33:08 | 6 of 6 SKIP relation dbt.my_second_dbt_model......................... [SKIP]
2021-01-19 15:33:08.927789 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:33:08.929013 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:33:08.929231 (MainThread): Using snowflake connection "master".
2021-01-19 15:33:08.929335 (MainThread): On master: BEGIN
2021-01-19 15:33:08.929436 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:33:10.015727 (MainThread): SQL status: SUCCESS 1 in 1.09 seconds
2021-01-19 15:33:10.015928 (MainThread): On master: COMMIT
2021-01-19 15:33:10.016100 (MainThread): Using snowflake connection "master".
2021-01-19 15:33:10.016200 (MainThread): On master: COMMIT
2021-01-19 15:33:10.236167 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 15:33:10.236404 (MainThread): On master: Close
2021-01-19 15:33:10.517155 (MainThread): 16:33:10 | 
2021-01-19 15:33:10.517359 (MainThread): 16:33:10 | Finished running 4 table models, 2 incremental models in 25.42s.
2021-01-19 15:33:10.517512 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:33:10.517651 (MainThread): Connection 'model.dbt_learn.snowflake_customer_purchases' was properly closed.
2021-01-19 15:33:10.537702 (MainThread): 
2021-01-19 15:33:10.537882 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 15:33:10.538011 (MainThread): 
2021-01-19 15:33:10.538132 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 15:33:10.538243 (MainThread):   Required var 'my_first_variable' not found in config:
2021-01-19 15:33:10.538342 (MainThread):   Vars supplied to my_first_dbt_model = {}
2021-01-19 15:33:10.538437 (MainThread):   
2021-01-19 15:33:10.538530 (MainThread):   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 15:33:10.538622 (MainThread):   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 15:33:10.538728 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
2021-01-19 15:33:10.538910 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10743b070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10744c790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d905280>]}
2021-01-19 15:33:10.539121 (MainThread): Flushing usage events
2021-01-19 15:35:17.361270 (MainThread): Running with dbt=0.18.1
2021-01-19 15:35:17.429625 (MainThread): Loading KWallet
2021-01-19 15:35:17.430086 (MainThread): Loading SecretService
2021-01-19 15:35:17.430447 (MainThread): Loading Windows
2021-01-19 15:35:17.430920 (MainThread): Loading chainer
2021-01-19 15:35:17.431160 (MainThread): Loading macOS
2021-01-19 15:35:17.688569 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:35:17.689775 (MainThread): Tracking: tracking
2021-01-19 15:35:17.690048 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b94e8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1e9790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba81d30>]}
2021-01-19 15:35:17.724210 (MainThread): Got an acceptable cached parse result
2021-01-19 15:35:17.801991 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:35:17.839399 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_learn.example.vars

2021-01-19 15:35:17.896445 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:35:17.897443 (MainThread): 
2021-01-19 15:35:17.897802 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:35:17.903934 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:35:17.916923 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:35:17.917183 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:35:17.917265 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:35:19.159829 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.24 seconds
2021-01-19 15:35:19.164834 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:35:19.550792 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:35:19.558965 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:35:19.559103 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:35:19.559213 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:35:20.364739 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 0.81 seconds
2021-01-19 15:35:20.372012 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:35:20.810618 (MainThread): Using snowflake connection "master".
2021-01-19 15:35:20.810811 (MainThread): On master: BEGIN
2021-01-19 15:35:20.810940 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:35:21.806516 (MainThread): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 15:35:21.806799 (MainThread): On master: COMMIT
2021-01-19 15:35:21.807048 (MainThread): Using snowflake connection "master".
2021-01-19 15:35:21.807196 (MainThread): On master: COMMIT
2021-01-19 15:35:22.126091 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:35:22.126375 (MainThread): On master: Close
2021-01-19 15:35:22.454741 (MainThread): 16:35:22 | Concurrency: 1 threads (target='dev')
2021-01-19 15:35:22.454982 (MainThread): 16:35:22 | 
2021-01-19 15:35:22.456995 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:35:22.458483 (Thread-1): 16:35:22 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:35:22.458817 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:35:22.458969 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:35:22.489577 (Thread-1): finished collecting timing info
2021-01-19 15:35:22.490091 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/compilation.py", line 385, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 19, in top-level template code
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/context/base.py", line 148, in __call__
    return self.get_missing_var(var_name)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/context/base.py", line 129, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 15:35:22.492281 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '639eca71-d0a9-451e-b1d4-475a50f6a114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb6f310>]}
2021-01-19 15:35:22.493463 (Thread-1): 16:35:22 | 1 of 6 ERROR creating table model dbt.first_model.................... [ERROR in 0.03s]
2021-01-19 15:35:22.493621 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:35:22.493773 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:35:22.494842 (Thread-1): 16:35:22 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:35:22.495372 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:35:22.495508 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:35:22.502933 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:35:22.503364 (Thread-1): finished collecting timing info
2021-01-19 15:35:22.580177 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:35:22.581314 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:35:22.581439 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:35:22.581551 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:35:23.592237 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:35:23.592464 (MainThread): Cancelling query 'model.dbt_learn.cumulative_orders_by_date' (247111831713)
2021-01-19 15:35:23.592794 (MainThread): Using snowflake connection "master".
2021-01-19 15:35:23.592913 (MainThread): On master: BEGIN
2021-01-19 15:35:23.593034 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:35:23.660805 (Thread-1): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 15:35:23.661066 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:35:23.661214 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:35:24.310645 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:35:24.310895 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:35:24.311024 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:35:24.825877 (MainThread): Flushing usage events
2021-01-19 15:35:25.052288 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:35:25.052483 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:35:25.052606 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:37:35.292827 (MainThread): Running with dbt=0.18.1
2021-01-19 15:37:35.364851 (MainThread): Loading KWallet
2021-01-19 15:37:35.365306 (MainThread): Loading SecretService
2021-01-19 15:37:35.365672 (MainThread): Loading Windows
2021-01-19 15:37:35.366157 (MainThread): Loading chainer
2021-01-19 15:37:35.366401 (MainThread): Loading macOS
2021-01-19 15:37:35.627553 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:37:35.628786 (MainThread): Tracking: tracking
2021-01-19 15:37:35.629083 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cb8370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec7d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec7310>]}
2021-01-19 15:37:35.657616 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='fd440892294acab26b9164df856cb4c120f695ff7849c92db9a8b71e7ff11b85') -> FileHash(name='sha256', checksum='9219aeebb1b4a9225aca7f491059e9bfa4449b0d76c2254da83ec4bd1afcfa1c')), cache invalidated
2021-01-19 15:37:35.659065 (MainThread): Parsing macros/catalog.sql
2021-01-19 15:37:35.662068 (MainThread): Parsing macros/adapters.sql
2021-01-19 15:37:35.701688 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 15:37:35.706380 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 15:37:35.708397 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 15:37:35.713641 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 15:37:35.726263 (MainThread): Parsing macros/core.sql
2021-01-19 15:37:35.730416 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 15:37:35.740861 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 15:37:35.742871 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 15:37:35.759590 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 15:37:35.790515 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 15:37:35.815412 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 15:37:35.817188 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 15:37:35.824196 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 15:37:35.839055 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 15:37:35.846518 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 15:37:35.852396 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 15:37:35.858172 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 15:37:35.859057 (MainThread): Parsing macros/etc/query.sql
2021-01-19 15:37:35.860021 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 15:37:35.861570 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 15:37:35.870544 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 15:37:35.872388 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 15:37:35.873937 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 15:37:35.913986 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 15:37:35.915787 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 15:37:35.917231 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 15:37:35.918832 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 15:37:35.927471 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='fd440892294acab26b9164df856cb4c120f695ff7849c92db9a8b71e7ff11b85') -> FileHash(name='sha256', checksum='9219aeebb1b4a9225aca7f491059e9bfa4449b0d76c2254da83ec4bd1afcfa1c')), cache invalidated
2021-01-19 15:37:35.963198 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:37:35.984273 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:37:35.993822 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:37:36.004958 (MainThread): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:37:36.018740 (MainThread): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:37:36.029009 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:37:36.207660 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:37:36.248722 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_learn.example.config

2021-01-19 15:37:36.315153 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:37:36.316127 (MainThread): 
2021-01-19 15:37:36.316395 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:37:36.323291 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:37:36.335216 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:37:36.335339 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:37:36.335422 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:37:38.437000 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.10 seconds
2021-01-19 15:37:38.441620 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:37:38.764251 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:37:38.772272 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:37:38.772403 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:37:38.772513 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:37:39.949776 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.18 seconds
2021-01-19 15:37:39.957156 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:37:40.241274 (MainThread): Using snowflake connection "master".
2021-01-19 15:37:40.241465 (MainThread): On master: BEGIN
2021-01-19 15:37:40.241594 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:37:41.379289 (MainThread): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 15:37:41.379571 (MainThread): On master: COMMIT
2021-01-19 15:37:41.379832 (MainThread): Using snowflake connection "master".
2021-01-19 15:37:41.379984 (MainThread): On master: COMMIT
2021-01-19 15:37:41.637810 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-19 15:37:41.638094 (MainThread): On master: Close
2021-01-19 15:37:42.133023 (MainThread): 16:37:42 | Concurrency: 1 threads (target='dev')
2021-01-19 15:37:42.133265 (MainThread): 16:37:42 | 
2021-01-19 15:37:42.135630 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:37:42.137117 (Thread-1): 16:37:42 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:37:42.137457 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:37:42.137598 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:37:42.161828 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:37:42.162318 (Thread-1): finished collecting timing info
2021-01-19 15:37:42.198151 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:37:42.199251 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:37:42.199364 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:37:42.199461 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:37:43.439354 (Thread-1): SQL status: SUCCESS 1 in 1.24 seconds
2021-01-19 15:37:43.439628 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:37:43.439780 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, None as first_variable
from source_data
where id >= None

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:37:43.964943 (Thread-1): Snowflake query id: 0199b769-0643-bd69-0000-003989032791
2021-01-19 15:37:43.965178 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 20 at position 10
invalid identifier 'NONE'
2021-01-19 15:37:43.965411 (Thread-1): finished collecting timing info
2021-01-19 15:37:43.965851 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 15:37:44.175018 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:37:44.550982 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000904 (42000): SQL compilation error: error line 20 at position 10
  invalid identifier 'NONE'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 20 at position 10
invalid identifier 'NONE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000904 (42000): SQL compilation error: error line 20 at position 10
  invalid identifier 'NONE'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 15:37:44.554153 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '035681c0-234d-4c6d-903f-4f19a889cf63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ad69a0>]}
2021-01-19 15:37:44.555494 (Thread-1): 16:37:44 | 1 of 6 ERROR creating table model dbt.first_model.................... [ERROR in 2.42s]
2021-01-19 15:37:44.555657 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:37:44.555852 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:37:44.557511 (Thread-1): 16:37:44 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:37:44.558116 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:37:44.558259 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:37:44.566228 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:37:44.566736 (Thread-1): finished collecting timing info
2021-01-19 15:37:44.571847 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:37:44.572819 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:37:44.572932 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:37:44.573038 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:37:45.933236 (Thread-1): SQL status: SUCCESS 1 in 1.36 seconds
2021-01-19 15:37:45.933502 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:37:45.933655 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:37:46.355086 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:37:46.355290 (MainThread): Cancelling query 'model.dbt_learn.cumulative_orders_by_date' (247111823521)
2021-01-19 15:37:46.355591 (MainThread): Using snowflake connection "master".
2021-01-19 15:37:46.355697 (MainThread): On master: BEGIN
2021-01-19 15:37:46.355805 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:37:46.578138 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:37:46.578331 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:37:46.578446 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:37:47.365042 (MainThread): Flushing usage events
2021-01-19 15:37:47.996164 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:37:47.996365 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:37:47.996484 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:37:48.146690 (MainThread): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:37:48.939757 (MainThread): ctrl-c
2021-01-19 15:37:48.940163 (MainThread): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.10', 64807), raddr=('3.232.20.32', 443)>
2021-01-19 15:37:48.942136 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.10', 64808), raddr=('3.232.20.32', 443)>
2021-01-19 15:40:37.974780 (MainThread): Running with dbt=0.18.1
2021-01-19 15:40:38.052541 (MainThread): Loading KWallet
2021-01-19 15:40:38.053171 (MainThread): Loading SecretService
2021-01-19 15:40:38.053855 (MainThread): Loading Windows
2021-01-19 15:40:38.054697 (MainThread): Loading chainer
2021-01-19 15:40:38.055052 (MainThread): Loading macOS
2021-01-19 15:40:38.343297 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:40:38.344234 (MainThread): Tracking: tracking
2021-01-19 15:40:38.344455 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0b02b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2bfd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2bf310>]}
2021-01-19 15:40:38.382294 (MainThread): Got an acceptable cached parse result
2021-01-19 15:40:38.466441 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:40:38.509658 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_learn.example.config

2021-01-19 15:40:38.568944 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:40:38.569806 (MainThread): 
2021-01-19 15:40:38.570179 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:40:38.577621 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:40:38.592089 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:40:38.592221 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:40:38.592300 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:40:39.860268 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.27 seconds
2021-01-19 15:40:39.864761 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:40:40.181447 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:40:40.189256 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:40:40.189414 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:40:40.189514 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:40:41.425120 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.24 seconds
2021-01-19 15:40:41.432062 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:40:41.751148 (MainThread): Using snowflake connection "master".
2021-01-19 15:40:41.751340 (MainThread): On master: BEGIN
2021-01-19 15:40:41.751469 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:40:42.573707 (MainThread): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 15:40:42.573933 (MainThread): On master: COMMIT
2021-01-19 15:40:42.574141 (MainThread): Using snowflake connection "master".
2021-01-19 15:40:42.574257 (MainThread): On master: COMMIT
2021-01-19 15:40:42.815362 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 15:40:42.815649 (MainThread): On master: Close
2021-01-19 15:40:43.118601 (MainThread): 16:40:43 | Concurrency: 1 threads (target='dev')
2021-01-19 15:40:43.118853 (MainThread): 16:40:43 | 
2021-01-19 15:40:43.122327 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:40:43.123734 (Thread-1): 16:40:43 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:40:43.124085 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:40:43.124229 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:40:43.157226 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:40:43.157721 (Thread-1): finished collecting timing info
2021-01-19 15:40:43.194239 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:40:43.195342 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:40:43.195447 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:40:43.195542 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:40:44.051291 (Thread-1): SQL status: SUCCESS 1 in 0.86 seconds
2021-01-19 15:40:44.051574 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:40:44.051729 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, None as first_variable
from source_data
where id >= None

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:40:44.287997 (Thread-1): Snowflake query id: 0199b76c-061c-96f9-0000-0039890377c9
2021-01-19 15:40:44.288239 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 20 at position 10
invalid identifier 'NONE'
2021-01-19 15:40:44.288476 (Thread-1): finished collecting timing info
2021-01-19 15:40:44.289143 (Thread-1): On model.dbt_learn.my_first_dbt_model: ROLLBACK
2021-01-19 15:40:44.599748 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:40:44.861492 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000904 (42000): SQL compilation error: error line 20 at position 10
  invalid identifier 'NONE'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 20 at position 10
invalid identifier 'NONE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 67, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000904 (42000): SQL compilation error: error line 20 at position 10
  invalid identifier 'NONE'
  compiled SQL at target/run/dbt_learn/models/example/my_first_dbt_model.sql
2021-01-19 15:40:44.864465 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9bbc78f-f8a3-4c7b-be39-f50f6d76cdbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad71ac0>]}
2021-01-19 15:40:44.865791 (Thread-1): 16:40:44 | 1 of 6 ERROR creating table model dbt.first_model.................... [ERROR in 1.74s]
2021-01-19 15:40:44.865953 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:40:44.866151 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:40:44.867832 (Thread-1): 16:40:44 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:40:44.868312 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:40:44.868457 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:40:44.876921 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:40:44.877427 (Thread-1): finished collecting timing info
2021-01-19 15:40:44.882409 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:40:44.883434 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:40:44.883549 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:40:44.883656 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:40:46.254708 (Thread-1): SQL status: SUCCESS 1 in 1.37 seconds
2021-01-19 15:40:46.254977 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:40:46.255135 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:40:47.929964 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:40:47.930204 (MainThread): Cancelling query 'model.dbt_learn.cumulative_orders_by_date' (247111831721)
2021-01-19 15:40:47.930495 (MainThread): Using snowflake connection "master".
2021-01-19 15:40:47.930599 (MainThread): On master: BEGIN
2021-01-19 15:40:47.930704 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:40:48.179921 (Thread-1): SQL status: SUCCESS 1 in 1.92 seconds
2021-01-19 15:40:48.558948 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:40:48.559115 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:40:48.559470 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:40:48.559579 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:40:48.714994 (MainThread): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:40:48.941538 (MainThread): Flushing usage events
2021-01-19 15:40:48.941743 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:40:48.942410 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:40:49.580139 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:40:49.580343 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:40:49.580464 (MainThread): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:40:49.629459 (Thread-1): Snowflake query id: None
2021-01-19 15:40:49.629716 (Thread-1): Snowflake error: 390111: Session no longer exists.  New login required to access the service.
2021-01-19 15:40:49.629930 (Thread-1): finished collecting timing info
2021-01-19 15:40:49.952128 (MainThread): ctrl-c
2021-01-19 15:40:49.952307 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:40:49.953036 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.10', 64846), raddr=('3.82.80.214', 443)>
2021-01-19 15:43:01.967347 (MainThread): Running with dbt=0.18.1
2021-01-19 15:43:02.043841 (MainThread): Loading KWallet
2021-01-19 15:43:02.044384 (MainThread): Loading SecretService
2021-01-19 15:43:02.044773 (MainThread): Loading Windows
2021-01-19 15:43:02.045279 (MainThread): Loading chainer
2021-01-19 15:43:02.045535 (MainThread): Loading macOS
2021-01-19 15:43:02.340023 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:43:02.340970 (MainThread): Tracking: tracking
2021-01-19 15:43:02.341241 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10848d880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10869dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10869ddf0>]}
2021-01-19 15:43:02.384814 (MainThread): Got an acceptable cached parse result
2021-01-19 15:43:02.423270 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:02.501961 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:43:02.539562 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_learn.example.config

2021-01-19 15:43:02.608954 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:43:02.609819 (MainThread): 
2021-01-19 15:43:02.610084 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:43:02.616557 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:43:02.628704 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:43:02.628817 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:43:02.628896 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:43:04.104508 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.48 seconds
2021-01-19 15:43:04.109025 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:43:05.618104 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:43:05.626151 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:43:05.626284 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:43:05.626389 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:43:06.685402 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.06 seconds
2021-01-19 15:43:06.691607 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:43:07.004632 (MainThread): Using snowflake connection "master".
2021-01-19 15:43:07.004824 (MainThread): On master: BEGIN
2021-01-19 15:43:07.004958 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:43:08.079575 (MainThread): SQL status: SUCCESS 1 in 1.07 seconds
2021-01-19 15:43:08.079855 (MainThread): On master: COMMIT
2021-01-19 15:43:08.080112 (MainThread): Using snowflake connection "master".
2021-01-19 15:43:08.080261 (MainThread): On master: COMMIT
2021-01-19 15:43:08.967731 (MainThread): SQL status: SUCCESS 1 in 0.89 seconds
2021-01-19 15:43:08.968109 (MainThread): On master: Close
2021-01-19 15:43:09.269989 (MainThread): 16:43:09 | Concurrency: 1 threads (target='dev')
2021-01-19 15:43:09.270234 (MainThread): 16:43:09 | 
2021-01-19 15:43:09.272277 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:43:09.273627 (Thread-1): 16:43:09 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:43:09.273960 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:09.274100 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:43:09.297090 (Thread-1): finished collecting timing info
2021-01-19 15:43:09.297601 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/compilation.py", line 385, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 19, in top-level template code
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/context/base.py", line 148, in __call__
    return self.get_missing_var(var_name)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/context/base.py", line 129, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-01-19 15:43:09.299859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c56e274-ea65-44a2-aeee-a580e97e88ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10978d880>]}
2021-01-19 15:43:09.301160 (Thread-1): 16:43:09 | 1 of 6 ERROR creating table model dbt.first_model.................... [ERROR in 0.03s]
2021-01-19 15:43:09.301341 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:43:09.301501 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:43:09.302593 (Thread-1): 16:43:09 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:43:09.303150 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:09.303281 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:43:09.311358 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:43:09.311901 (Thread-1): finished collecting timing info
2021-01-19 15:43:09.394299 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:43:09.395427 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:09.395543 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:43:09.395647 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:43:10.719155 (Thread-1): SQL status: SUCCESS 1 in 1.32 seconds
2021-01-19 15:43:10.719359 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:10.719478 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:43:11.040163 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:43:11.040344 (MainThread): Cancelling query 'model.dbt_learn.cumulative_orders_by_date' (247111827641)
2021-01-19 15:43:11.040608 (MainThread): Using snowflake connection "master".
2021-01-19 15:43:11.040701 (MainThread): On master: BEGIN
2021-01-19 15:43:11.040796 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:43:11.354770 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:43:11.354928 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:43:11.355022 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:43:12.052335 (MainThread): Flushing usage events
2021-01-19 15:43:12.434853 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:43:12.435042 (MainThread): Connection 'model.dbt_learn.cumulative_orders_by_date' was left open.
2021-01-19 15:43:12.435155 (MainThread): On model.dbt_learn.cumulative_orders_by_date: ROLLBACK
2021-01-19 15:43:13.381236 (Thread-1): SQL status: SUCCESS 1 in 2.66 seconds
2021-01-19 15:43:36.371789 (MainThread): Running with dbt=0.18.1
2021-01-19 15:43:36.451306 (MainThread): Loading KWallet
2021-01-19 15:43:36.452324 (MainThread): Loading SecretService
2021-01-19 15:43:36.452735 (MainThread): Loading Windows
2021-01-19 15:43:36.453259 (MainThread): Loading chainer
2021-01-19 15:43:36.453523 (MainThread): Loading macOS
2021-01-19 15:43:36.748637 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:43:36.749607 (MainThread): Tracking: tracking
2021-01-19 15:43:36.750208 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a68c100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a89c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a89c040>]}
2021-01-19 15:43:36.777316 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='9219aeebb1b4a9225aca7f491059e9bfa4449b0d76c2254da83ec4bd1afcfa1c') -> FileHash(name='sha256', checksum='2a5a92f2dd500819576a0977b01a06b9a96d1a903f9690ea6fe9b1610dfff2f3')), cache invalidated
2021-01-19 15:43:36.778432 (MainThread): Parsing macros/catalog.sql
2021-01-19 15:43:36.780581 (MainThread): Parsing macros/adapters.sql
2021-01-19 15:43:36.810841 (MainThread): Parsing macros/materializations/merge.sql
2021-01-19 15:43:36.812743 (MainThread): Parsing macros/materializations/view.sql
2021-01-19 15:43:36.814113 (MainThread): Parsing macros/materializations/table.sql
2021-01-19 15:43:36.818647 (MainThread): Parsing macros/materializations/incremental.sql
2021-01-19 15:43:36.828270 (MainThread): Parsing macros/core.sql
2021-01-19 15:43:36.831700 (MainThread): Parsing macros/materializations/helpers.sql
2021-01-19 15:43:36.841058 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-01-19 15:43:36.842698 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-01-19 15:43:36.859567 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-01-19 15:43:36.889492 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-01-19 15:43:36.910752 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-01-19 15:43:36.912495 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-01-19 15:43:36.918888 (MainThread): Parsing macros/materializations/common/merge.sql
2021-01-19 15:43:36.932024 (MainThread): Parsing macros/materializations/table/table.sql
2021-01-19 15:43:36.939534 (MainThread): Parsing macros/materializations/view/view.sql
2021-01-19 15:43:36.945589 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-01-19 15:43:36.951992 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-01-19 15:43:36.952998 (MainThread): Parsing macros/etc/query.sql
2021-01-19 15:43:36.953964 (MainThread): Parsing macros/etc/is_incremental.sql
2021-01-19 15:43:36.955454 (MainThread): Parsing macros/etc/datetime.sql
2021-01-19 15:43:36.963905 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-01-19 15:43:36.965846 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-01-19 15:43:36.968840 (MainThread): Parsing macros/adapters/common.sql
2021-01-19 15:43:37.011258 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-01-19 15:43:37.013018 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-01-19 15:43:37.014402 (MainThread): Parsing macros/schema_tests/unique.sql
2021-01-19 15:43:37.016057 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-01-19 15:43:37.024827 (MainThread): For key dbt_learn, hash mismatch (FileHash(name='sha256', checksum='9219aeebb1b4a9225aca7f491059e9bfa4449b0d76c2254da83ec4bd1afcfa1c') -> FileHash(name='sha256', checksum='2a5a92f2dd500819576a0977b01a06b9a96d1a903f9690ea6fe9b1610dfff2f3')), cache invalidated
2021-01-19 15:43:37.061270 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:37.083966 (MainThread): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:37.094134 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:43:37.106593 (MainThread): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:37.121233 (MainThread): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:37.131841 (MainThread): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:43:37.323606 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:43:37.428339 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:43:37.430819 (MainThread): 
2021-01-19 15:43:37.431279 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:43:37.440039 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:43:37.454270 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:43:37.454432 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:43:37.454626 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:43:38.869457 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.41 seconds
2021-01-19 15:43:38.873883 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:43:39.164203 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:43:39.172662 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:43:39.172829 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:43:39.172943 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:43:40.512073 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.34 seconds
2021-01-19 15:43:40.519672 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:43:41.071227 (MainThread): Using snowflake connection "master".
2021-01-19 15:43:41.071422 (MainThread): On master: BEGIN
2021-01-19 15:43:41.071552 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:43:42.281000 (MainThread): SQL status: SUCCESS 1 in 1.21 seconds
2021-01-19 15:43:42.281324 (MainThread): On master: COMMIT
2021-01-19 15:43:42.281602 (MainThread): Using snowflake connection "master".
2021-01-19 15:43:42.281765 (MainThread): On master: COMMIT
2021-01-19 15:43:42.604336 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:43:42.604568 (MainThread): On master: Close
2021-01-19 15:43:43.067919 (MainThread): 16:43:43 | Concurrency: 1 threads (target='dev')
2021-01-19 15:43:43.068188 (MainThread): 16:43:43 | 
2021-01-19 15:43:43.070626 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:43:43.071963 (Thread-1): 16:43:43 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:43:43.072298 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:43.072435 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:43:43.096325 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:43:43.096837 (Thread-1): finished collecting timing info
2021-01-19 15:43:43.132970 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:43:43.134238 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:43.134353 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:43:43.134446 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:43:44.008749 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2021-01-19 15:43:44.009003 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:44.009153 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, 'True' as first_variable
from source_data
where id >= '1'

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:43:45.049734 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 15:43:45.051866 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:43:45.052167 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:43:45.052331 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:43:45.324607 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-01-19 15:43:45.340404 (Thread-1): finished collecting timing info
2021-01-19 15:43:45.340714 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:43:45.642556 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb98f63c-6940-4946-a278-e96964413248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4cdca0>]}
2021-01-19 15:43:45.644112 (Thread-1): 16:43:45 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 2.57s]
2021-01-19 15:43:45.644307 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:43:45.644527 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:43:45.646167 (Thread-1): 16:43:45 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:43:45.646606 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:45.646746 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:43:45.655175 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:43:45.655659 (Thread-1): finished collecting timing info
2021-01-19 15:43:45.660496 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:43:45.661500 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:45.661656 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:43:45.661814 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:43:46.662136 (Thread-1): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 15:43:46.662389 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:46.662537 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:43:48.235867 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2021-01-19 15:43:48.237232 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:43:48.237416 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:43:48.237518 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:43:48.412606 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:43:48.415045 (Thread-1): finished collecting timing info
2021-01-19 15:43:48.415358 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:43:48.703648 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb98f63c-6940-4946-a278-e96964413248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6b69d0>]}
2021-01-19 15:43:48.705226 (Thread-1): 16:43:48 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.06s]
2021-01-19 15:43:48.705414 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:43:48.705576 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 15:43:48.706828 (Thread-1): 16:43:48 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 15:43:48.707257 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:48.707390 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 15:43:48.720172 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 15:43:48.720668 (Thread-1): finished collecting timing info
2021-01-19 15:43:48.753959 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:48.754121 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 15:43:48.754225 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:43:50.363170 (Thread-1): SQL status: SUCCESS 1 in 1.61 seconds
2021-01-19 15:43:50.384578 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:50.384895 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 15:43:50.642563 (Thread-1): SQL status: SUCCESS 28 in 0.26 seconds
2021-01-19 15:43:50.647530 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:50.647646 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:43:51.019377 (Thread-1): SQL status: SUCCESS 28 in 0.37 seconds
2021-01-19 15:43:51.024421 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:51.024559 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:43:51.257875 (Thread-1): SQL status: SUCCESS 28 in 0.23 seconds
2021-01-19 15:43:51.288675 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 15:43:51.291906 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:51.292058 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 15:43:51.474275 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 15:43:51.474454 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:51.474557 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 15:43:51.883478 (Thread-1): SQL status: SUCCESS 0 in 0.41 seconds
2021-01-19 15:43:51.885359 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:43:51.885845 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:43:51.886095 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:43:52.166683 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 15:43:52.172398 (Thread-1): finished collecting timing info
2021-01-19 15:43:52.172792 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 15:43:52.500333 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb98f63c-6940-4946-a278-e96964413248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b615fa0>]}
2021-01-19 15:43:52.501794 (Thread-1): 16:43:52 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.79s]
2021-01-19 15:43:52.501993 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 15:43:52.502164 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 15:43:52.503595 (Thread-1): 16:43:52 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 15:43:52.503967 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:52.504102 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 15:43:52.513127 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:43:52.513608 (Thread-1): finished collecting timing info
2021-01-19 15:43:52.521732 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:52.521905 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 15:43:52.522024 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:43:55.139993 (Thread-1): SQL status: SUCCESS 1 in 2.62 seconds
2021-01-19 15:43:55.142799 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:55.142975 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 15:43:55.351319 (Thread-1): SQL status: SUCCESS 10 in 0.21 seconds
2021-01-19 15:43:55.355062 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:55.355219 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:43:55.540254 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-19 15:43:55.544065 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:55.544193 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:43:55.793061 (Thread-1): SQL status: SUCCESS 10 in 0.25 seconds
2021-01-19 15:43:55.796109 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:43:55.798019 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:55.798157 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 15:43:56.075309 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 15:43:56.075483 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:56.075584 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 15:43:58.272842 (Thread-1): SQL status: SUCCESS 653 in 2.20 seconds
2021-01-19 15:43:58.274203 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:43:58.274427 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:43:58.274546 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:43:58.717848 (Thread-1): SQL status: SUCCESS 1 in 0.44 seconds
2021-01-19 15:43:58.722426 (Thread-1): finished collecting timing info
2021-01-19 15:43:58.722725 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 15:43:59.300380 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb98f63c-6940-4946-a278-e96964413248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6b6340>]}
2021-01-19 15:43:59.302164 (Thread-1): 16:43:59 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 653 in 6.80s]
2021-01-19 15:43:59.302370 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 15:43:59.302559 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:43:59.304006 (Thread-1): 16:43:59 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 15:43:59.304444 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:43:59.304581 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:43:59.311999 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:43:59.312458 (Thread-1): finished collecting timing info
2021-01-19 15:43:59.317900 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:43:59.319178 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:43:59.319296 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 15:43:59.319403 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:44:00.727486 (Thread-1): SQL status: SUCCESS 1 in 1.41 seconds
2021-01-19 15:44:00.727751 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:44:00.727924 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 15:44:02.980246 (Thread-1): SQL status: SUCCESS 1 in 2.25 seconds
2021-01-19 15:44:02.981350 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:44:02.981565 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:44:02.981673 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:44:03.138525 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 15:44:03.141261 (Thread-1): finished collecting timing info
2021-01-19 15:44:03.141592 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 15:44:03.448744 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb98f63c-6940-4946-a278-e96964413248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11195ca60>]}
2021-01-19 15:44:03.450605 (Thread-1): 16:44:03 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 4.14s]
2021-01-19 15:44:03.450828 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:44:03.450990 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:44:03.452649 (Thread-1): 16:44:03 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 15:44:03.452991 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:44:03.453120 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 15:44:03.462281 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:44:03.462748 (Thread-1): finished collecting timing info
2021-01-19 15:44:03.468464 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:44:03.469415 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:44:03.469533 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 15:44:03.469642 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:44:04.801481 (Thread-1): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-19 15:44:04.801670 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:44:04.801771 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 15:44:05.841399 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 15:44:05.842594 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:44:05.842803 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:44:05.842910 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:44:06.017479 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:44:06.020212 (Thread-1): finished collecting timing info
2021-01-19 15:44:06.020537 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 15:44:06.325551 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb98f63c-6940-4946-a278-e96964413248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4cd160>]}
2021-01-19 15:44:06.326648 (Thread-1): 16:44:06 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.87s]
2021-01-19 15:44:06.326780 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:44:06.327983 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:44:06.328264 (MainThread): Using snowflake connection "master".
2021-01-19 15:44:06.328373 (MainThread): On master: BEGIN
2021-01-19 15:44:06.328476 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:44:07.355234 (MainThread): SQL status: SUCCESS 1 in 1.03 seconds
2021-01-19 15:44:07.355425 (MainThread): On master: COMMIT
2021-01-19 15:44:07.355599 (MainThread): Using snowflake connection "master".
2021-01-19 15:44:07.355698 (MainThread): On master: COMMIT
2021-01-19 15:44:07.570938 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 15:44:07.571142 (MainThread): On master: Close
2021-01-19 15:44:07.857080 (MainThread): 16:44:07 | 
2021-01-19 15:44:07.857266 (MainThread): 16:44:07 | Finished running 4 table models, 2 incremental models in 30.43s.
2021-01-19 15:44:07.857452 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:44:07.857601 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 15:44:07.879841 (MainThread): 
2021-01-19 15:44:07.880031 (MainThread): Completed successfully
2021-01-19 15:44:07.880168 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 15:44:07.880368 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5f0910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5f0ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5f0340>]}
2021-01-19 15:44:07.880579 (MainThread): Flushing usage events
2021-01-19 15:45:19.474826 (MainThread): Running with dbt=0.18.1
2021-01-19 15:45:19.576684 (MainThread): Loading KWallet
2021-01-19 15:45:19.577439 (MainThread): Loading SecretService
2021-01-19 15:45:19.578174 (MainThread): Loading Windows
2021-01-19 15:45:19.578954 (MainThread): Loading chainer
2021-01-19 15:45:19.579329 (MainThread): Loading macOS
2021-01-19 15:45:19.928655 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:45:19.930116 (MainThread): Tracking: tracking
2021-01-19 15:45:19.930475 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e96850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050a6040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050a6d90>]}
2021-01-19 15:45:19.978869 (MainThread): Got an acceptable cached parse result
2021-01-19 15:45:20.021961 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:45:20.101518 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:45:20.200366 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:45:20.202497 (MainThread): 
2021-01-19 15:45:20.202991 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:45:20.210183 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:45:20.222259 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:45:20.222380 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:45:20.222460 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:45:22.370228 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.15 seconds
2021-01-19 15:45:22.374820 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:45:23.288445 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:45:23.295943 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:45:23.296081 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:45:23.296192 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:45:25.107509 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.81 seconds
2021-01-19 15:45:25.114113 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:45:25.622066 (MainThread): Using snowflake connection "master".
2021-01-19 15:45:25.622262 (MainThread): On master: BEGIN
2021-01-19 15:45:25.622397 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:45:27.608747 (MainThread): SQL status: SUCCESS 1 in 1.99 seconds
2021-01-19 15:45:27.609017 (MainThread): On master: COMMIT
2021-01-19 15:45:27.609202 (MainThread): Using snowflake connection "master".
2021-01-19 15:45:27.609304 (MainThread): On master: COMMIT
2021-01-19 15:45:27.928540 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:45:27.928830 (MainThread): On master: Close
2021-01-19 15:45:28.366498 (MainThread): 16:45:28 | Concurrency: 1 threads (target='dev')
2021-01-19 15:45:28.366707 (MainThread): 16:45:28 | 
2021-01-19 15:45:28.368461 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:45:28.369746 (Thread-1): 16:45:28 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:45:28.370063 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:45:28.370200 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:45:28.392545 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:45:28.393080 (Thread-1): finished collecting timing info
2021-01-19 15:45:28.474610 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:45:28.475842 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:45:28.475960 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:45:28.476071 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:45:29.572589 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 15:45:29.572847 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:45:29.573002 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data


/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:45:31.353620 (Thread-1): SQL status: SUCCESS 1 in 1.78 seconds
2021-01-19 15:45:31.354964 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:45:31.355158 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:45:31.355264 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:45:31.662655 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 15:45:31.678208 (Thread-1): finished collecting timing info
2021-01-19 15:45:31.678547 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:45:32.194908 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '423d27c9-b3b0-485a-9d3b-49766ab04580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c09a160>]}
2021-01-19 15:45:32.196450 (Thread-1): 16:45:32 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 3.82s]
2021-01-19 15:45:32.196639 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:45:32.196850 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:45:32.198947 (Thread-1): 16:45:32 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:45:32.199512 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:45:32.199655 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:45:32.206985 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:45:32.207440 (Thread-1): finished collecting timing info
2021-01-19 15:45:32.212401 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:45:32.213441 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:45:32.213557 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:45:32.213665 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:45:34.892483 (Thread-1): SQL status: SUCCESS 1 in 2.68 seconds
2021-01-19 15:45:34.892694 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:45:34.892816 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:45:36.978756 (Thread-1): SQL status: SUCCESS 1 in 2.09 seconds
2021-01-19 15:45:36.980567 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:45:36.980815 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:45:36.980940 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:45:37.169559 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-01-19 15:45:37.172406 (Thread-1): finished collecting timing info
2021-01-19 15:45:37.172734 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:45:37.893447 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '423d27c9-b3b0-485a-9d3b-49766ab04580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c14f040>]}
2021-01-19 15:45:37.894967 (Thread-1): 16:45:37 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 5.69s]
2021-01-19 15:45:37.895159 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:45:37.895311 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 15:45:37.896742 (Thread-1): 16:45:37 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 15:45:37.897114 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:37.897244 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 15:45:37.913693 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 15:45:37.914259 (Thread-1): finished collecting timing info
2021-01-19 15:45:37.946627 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:37.946797 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 15:45:37.946913 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:45:40.032363 (Thread-1): SQL status: SUCCESS 1 in 2.09 seconds
2021-01-19 15:45:40.043228 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:40.043386 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 15:45:40.221430 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 15:45:40.227201 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:40.227340 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:45:40.416696 (Thread-1): SQL status: SUCCESS 28 in 0.19 seconds
2021-01-19 15:45:40.422019 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:40.422160 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:45:40.580787 (Thread-1): SQL status: SUCCESS 28 in 0.16 seconds
2021-01-19 15:45:40.608962 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 15:45:40.612124 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:40.612246 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 15:45:40.787277 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:45:40.787496 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:40.787620 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 15:45:41.493329 (Thread-1): SQL status: SUCCESS 0 in 0.71 seconds
2021-01-19 15:45:41.494811 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:45:41.495038 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:45:41.495163 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:45:41.769136 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-01-19 15:45:41.773920 (Thread-1): finished collecting timing info
2021-01-19 15:45:41.774207 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 15:45:42.049779 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '423d27c9-b3b0-485a-9d3b-49766ab04580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1d0e80>]}
2021-01-19 15:45:42.051293 (Thread-1): 16:45:42 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.15s]
2021-01-19 15:45:42.051483 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 15:45:42.051668 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 15:45:42.053020 (Thread-1): 16:45:42 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 15:45:42.053352 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:42.053487 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 15:45:42.062453 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:45:42.062870 (Thread-1): finished collecting timing info
2021-01-19 15:45:42.069544 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:42.069720 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 15:45:42.069839 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:45:45.364199 (Thread-1): SQL status: SUCCESS 1 in 3.29 seconds
2021-01-19 15:45:45.367145 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:45.367301 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 15:45:45.571414 (Thread-1): SQL status: SUCCESS 10 in 0.20 seconds
2021-01-19 15:45:45.574986 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:45.575104 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:45:46.153305 (Thread-1): SQL status: SUCCESS 10 in 0.58 seconds
2021-01-19 15:45:46.157497 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:46.157634 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:45:46.360015 (Thread-1): SQL status: SUCCESS 10 in 0.20 seconds
2021-01-19 15:45:46.363962 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:45:46.366110 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:46.366250 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 15:45:46.684933 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:45:46.685115 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:46.685229 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 15:45:47.493312 (Thread-1): SQL status: SUCCESS 111 in 0.81 seconds
2021-01-19 15:45:47.494617 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:45:47.494872 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:45:47.495000 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:45:48.184963 (Thread-1): SQL status: SUCCESS 1 in 0.69 seconds
2021-01-19 15:45:48.188832 (Thread-1): finished collecting timing info
2021-01-19 15:45:48.189108 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 15:45:49.667948 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '423d27c9-b3b0-485a-9d3b-49766ab04580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105de9790>]}
2021-01-19 15:45:49.669441 (Thread-1): 16:45:49 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 111 in 7.61s]
2021-01-19 15:45:49.669611 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 15:45:49.669771 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:45:49.671398 (Thread-1): 16:45:49 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 15:45:49.671731 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:45:49.671867 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:45:49.680255 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:45:49.680859 (Thread-1): finished collecting timing info
2021-01-19 15:45:49.686090 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:45:49.687289 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:45:49.687406 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 15:45:49.687515 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:45:50.871717 (Thread-1): SQL status: SUCCESS 1 in 1.18 seconds
2021-01-19 15:45:50.871920 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:45:50.872025 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 15:45:52.960275 (Thread-1): SQL status: SUCCESS 1 in 2.09 seconds
2021-01-19 15:45:52.961374 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:45:52.961549 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:45:52.961653 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:45:53.134446 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 15:45:53.136863 (Thread-1): finished collecting timing info
2021-01-19 15:45:53.137159 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 15:45:54.097438 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '423d27c9-b3b0-485a-9d3b-49766ab04580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bd6fa0>]}
2021-01-19 15:45:54.098880 (Thread-1): 16:45:54 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 4.43s]
2021-01-19 15:45:54.099164 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:45:54.099428 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:45:54.101587 (Thread-1): 16:45:54 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 15:45:54.102058 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:45:54.102212 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 15:45:54.114200 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:45:54.114913 (Thread-1): finished collecting timing info
2021-01-19 15:45:54.120239 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:45:54.121159 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:45:54.121272 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 15:45:54.121377 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:45:55.780365 (Thread-1): SQL status: SUCCESS 1 in 1.66 seconds
2021-01-19 15:45:55.780590 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:45:55.780716 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 15:45:56.913375 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2021-01-19 15:45:56.914527 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:45:56.914709 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:45:56.914809 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:45:57.071853 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 15:45:57.074506 (Thread-1): finished collecting timing info
2021-01-19 15:45:57.074786 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 15:45:58.047713 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '423d27c9-b3b0-485a-9d3b-49766ab04580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2a99d0>]}
2021-01-19 15:45:58.048777 (Thread-1): 16:45:58 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.95s]
2021-01-19 15:45:58.048909 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:45:58.050014 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:45:58.050202 (MainThread): Using snowflake connection "master".
2021-01-19 15:45:58.050285 (MainThread): On master: BEGIN
2021-01-19 15:45:58.050367 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:45:58.951763 (MainThread): SQL status: SUCCESS 1 in 0.90 seconds
2021-01-19 15:45:58.951931 (MainThread): On master: COMMIT
2021-01-19 15:45:58.952077 (MainThread): Using snowflake connection "master".
2021-01-19 15:45:58.952157 (MainThread): On master: COMMIT
2021-01-19 15:45:59.176433 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 15:45:59.176581 (MainThread): On master: Close
2021-01-19 15:45:59.474111 (MainThread): 16:45:59 | 
2021-01-19 15:45:59.474283 (MainThread): 16:45:59 | Finished running 4 table models, 2 incremental models in 39.27s.
2021-01-19 15:45:59.474409 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:45:59.474546 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 15:45:59.494313 (MainThread): 
2021-01-19 15:45:59.494617 (MainThread): Completed successfully
2021-01-19 15:45:59.494752 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 15:45:59.494924 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c86460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c28d040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c28d580>]}
2021-01-19 15:45:59.495106 (MainThread): Flushing usage events
2021-01-19 15:47:15.488227 (MainThread): Running with dbt=0.18.1
2021-01-19 15:47:15.571033 (MainThread): Loading KWallet
2021-01-19 15:47:15.571674 (MainThread): Loading SecretService
2021-01-19 15:47:15.572168 (MainThread): Loading Windows
2021-01-19 15:47:15.572793 (MainThread): Loading chainer
2021-01-19 15:47:15.573116 (MainThread): Loading macOS
2021-01-19 15:47:15.869674 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 15:47:15.870624 (MainThread): Tracking: tracking
2021-01-19 15:47:15.870885 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c511850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c721040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c721d90>]}
2021-01-19 15:47:15.909922 (MainThread): Got an acceptable cached parse result
2021-01-19 15:47:15.997649 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:47:16.094741 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:47:16.096375 (MainThread): 
2021-01-19 15:47:16.096848 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:47:16.111421 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:47:16.124766 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:47:16.124888 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:47:16.124965 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 15:47:18.657395 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 2.53 seconds
2021-01-19 15:47:18.668521 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:47:19.037417 (MainThread): 16:47:19 | Concurrency: 1 threads (target='dev')
2021-01-19 15:47:19.037651 (MainThread): 16:47:19 | 
2021-01-19 15:47:19.039945 (Thread-1): Began running node test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:47:19.040157 (Thread-1): 16:47:19 | 1 of 8 START test not_null_cumulative_orders_by_date_date............ [RUN]
2021-01-19 15:47:19.040454 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:47:19.040597 (Thread-1): Compiling test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:47:19.079522 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_cumulative_orders_by_date_date"
2021-01-19 15:47:19.080142 (Thread-1): finished collecting timing info
2021-01-19 15:47:19.080810 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:47:19.080917 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: BEGIN
2021-01-19 15:47:19.081021 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:20.395280 (Thread-1): SQL status: SUCCESS 1 in 1.31 seconds
2021-01-19 15:47:20.395520 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:47:20.395642 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_cumulative_orders_by_date_date"} */

    
    



select count(*) as validation_errors
from analytics.dbt.cumulative_orders_by_date
where date is null
2021-01-19 15:47:20.984832 (Thread-1): Snowflake query id: 0199b773-0693-3ea8-0000-00398903471d
2021-01-19 15:47:20.985033 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 3 at position 6
invalid identifier 'DATE'
2021-01-19 15:47:20.985201 (Thread-1): finished collecting timing info
2021-01-19 15:47:20.985573 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: ROLLBACK
2021-01-19 15:47:21.282880 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: Close
2021-01-19 15:47:22.131268 (Thread-1): Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 3 at position 6
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 3 at position 6
invalid identifier 'DATE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 3 at position 6
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
2021-01-19 15:47:22.135591 (Thread-1): 16:47:22 | 1 of 8 ERROR not_null_cumulative_orders_by_date_date................. [ERROR in 3.10s]
2021-01-19 15:47:22.135808 (Thread-1): Finished running node test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:47:22.136002 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:47:22.136500 (Thread-1): 16:47:22 | 2 of 8 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 15:47:22.137074 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:47:22.137262 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:47:22.148649 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 15:47:22.149131 (Thread-1): finished collecting timing info
2021-01-19 15:47:22.149765 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:47:22.149874 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 15:47:22.149976 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:23.440231 (Thread-1): SQL status: SUCCESS 1 in 1.29 seconds
2021-01-19 15:47:23.440426 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:47:23.440531 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 15:47:25.895125 (Thread-1): SQL status: SUCCESS 1 in 2.45 seconds
2021-01-19 15:47:25.895620 (Thread-1): finished collecting timing info
2021-01-19 15:47:25.896071 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:47:26.148664 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 15:47:26.487922 (Thread-1): 16:47:26 | 2 of 8 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 4.35s]
2021-01-19 15:47:26.488165 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:47:26.488359 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:47:26.488681 (Thread-1): 16:47:26 | 3 of 8 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 15:47:26.489080 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:47:26.489239 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:47:26.500916 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 15:47:26.501409 (Thread-1): finished collecting timing info
2021-01-19 15:47:26.502063 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:47:26.502175 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 15:47:26.502280 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:27.836005 (Thread-1): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-19 15:47:27.836217 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:47:27.836337 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 15:47:28.663370 (Thread-1): SQL status: SUCCESS 1 in 0.83 seconds
2021-01-19 15:47:28.663797 (Thread-1): finished collecting timing info
2021-01-19 15:47:28.664117 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:47:29.040472 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 15:47:29.591443 (Thread-1): 16:47:29 | 3 of 8 PASS not_null_my_second_dbt_model_id.......................... [PASS in 3.10s]
2021-01-19 15:47:29.591686 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:47:29.591876 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:47:29.592191 (Thread-1): 16:47:29 | 4 of 8 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 15:47:29.592671 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:47:29.592869 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:47:29.604468 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 15:47:29.604954 (Thread-1): finished collecting timing info
2021-01-19 15:47:29.605644 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:47:29.605755 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:47:29.605859 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:30.734700 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2021-01-19 15:47:30.734934 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:47:30.735058 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 15:47:31.051152 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:47:31.051493 (Thread-1): finished collecting timing info
2021-01-19 15:47:31.051806 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:47:31.318048 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:47:31.576443 (Thread-1): 16:47:31 | 4 of 8 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 1.98s]
2021-01-19 15:47:31.576682 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:47:31.576911 (Thread-1): Began running node test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:47:31.577333 (Thread-1): 16:47:31 | 5 of 8 START test unique_cumulative_orders_by_date_date.............. [RUN]
2021-01-19 15:47:31.577765 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:47:31.577947 (Thread-1): Compiling test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:47:31.594386 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_cumulative_orders_by_date_date"
2021-01-19 15:47:31.594992 (Thread-1): finished collecting timing info
2021-01-19 15:47:31.595937 (Thread-1): Using snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:47:31.596064 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: BEGIN
2021-01-19 15:47:31.596173 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:32.859455 (Thread-1): SQL status: SUCCESS 1 in 1.26 seconds
2021-01-19 15:47:32.859679 (Thread-1): Using snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:47:32.859803 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_cumulative_orders_by_date_date"} */

    
    



select count(*) as validation_errors
from (

    select
        date

    from analytics.dbt.cumulative_orders_by_date
    where date is not null
    group by date
    having count(*) > 1

) validation_errors
2021-01-19 15:47:33.074996 (Thread-1): Snowflake query id: 0199b773-0660-642a-0000-003989037821
2021-01-19 15:47:33.075229 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 5 at position 8
invalid identifier 'DATE'
2021-01-19 15:47:33.075414 (Thread-1): finished collecting timing info
2021-01-19 15:47:33.075987 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: ROLLBACK
2021-01-19 15:47:33.306230 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: Close
2021-01-19 15:47:33.678366 (Thread-1): Database Error in test unique_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 5 at position 8
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/unique_cumulative_orders_by_date_date.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 5 at position 8
invalid identifier 'DATE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in test unique_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 5 at position 8
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/unique_cumulative_orders_by_date_date.sql
2021-01-19 15:47:33.679033 (Thread-1): 16:47:33 | 5 of 8 ERROR unique_cumulative_orders_by_date_date................... [ERROR in 2.10s]
2021-01-19 15:47:33.679197 (Thread-1): Finished running node test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:47:33.679481 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:47:33.679995 (Thread-1): 16:47:33 | 6 of 8 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 15:47:33.680574 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:47:33.680779 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:47:33.692112 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 15:47:33.692588 (Thread-1): finished collecting timing info
2021-01-19 15:47:33.693396 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:47:33.693509 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 15:47:33.693614 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:34.905067 (Thread-1): SQL status: SUCCESS 1 in 1.21 seconds
2021-01-19 15:47:34.905334 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:47:34.905486 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 15:47:35.204085 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 15:47:35.204463 (Thread-1): finished collecting timing info
2021-01-19 15:47:35.204827 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:47:35.451900 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 15:47:35.802352 (Thread-1): 16:47:35 | 6 of 8 PASS unique_my_first_dbt_model_id............................. [PASS in 2.12s]
2021-01-19 15:47:35.802601 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:47:35.803062 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:47:35.803444 (Thread-1): 16:47:35 | 7 of 8 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 15:47:35.803964 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:47:35.804145 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:47:35.815480 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 15:47:35.815987 (Thread-1): finished collecting timing info
2021-01-19 15:47:35.816800 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:47:35.816911 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 15:47:35.817016 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:36.952912 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 15:47:36.953177 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:47:36.953369 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 15:47:37.695249 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2021-01-19 15:47:37.695746 (Thread-1): finished collecting timing info
2021-01-19 15:47:37.696202 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:47:40.345509 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 15:47:40.639316 (Thread-1): 16:47:40 | 7 of 8 PASS unique_my_second_dbt_model_id............................ [PASS in 4.84s]
2021-01-19 15:47:40.639561 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:47:40.639751 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:47:40.640092 (Thread-1): 16:47:40 | 8 of 8 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 15:47:40.640659 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:47:40.640866 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:47:40.652547 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 15:47:40.653056 (Thread-1): finished collecting timing info
2021-01-19 15:47:40.653936 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:47:40.654046 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:47:40.654149 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:47:41.695446 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 15:47:41.695844 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:47:41.695977 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 15:47:42.538980 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-01-19 15:47:42.539451 (Thread-1): finished collecting timing info
2021-01-19 15:47:42.539894 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:47:43.351244 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:47:43.937541 (Thread-1): 16:47:43 | 8 of 8 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 3.30s]
2021-01-19 15:47:43.937736 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:47:43.939502 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:47:43.939983 (MainThread): 16:47:43 | 
2021-01-19 15:47:43.940151 (MainThread): 16:47:43 | Finished running 8 tests in 27.84s.
2021-01-19 15:47:43.940277 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:47:43.940369 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 15:47:43.968937 (MainThread): 
2021-01-19 15:47:43.969120 (MainThread): Completed with 3 errors and 0 warnings:
2021-01-19 15:47:43.969346 (MainThread): 
2021-01-19 15:47:43.969473 (MainThread): Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
2021-01-19 15:47:43.969583 (MainThread):   000904 (42000): SQL compilation error: error line 3 at position 6
2021-01-19 15:47:43.969682 (MainThread):   invalid identifier 'DATE'
2021-01-19 15:47:43.969777 (MainThread):   compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
2021-01-19 15:47:43.969880 (MainThread): 
2021-01-19 15:47:43.969997 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-01-19 15:47:43.970126 (MainThread):   Got 1 result, expected 0.
2021-01-19 15:47:43.970231 (MainThread): 
2021-01-19 15:47:43.970337 (MainThread):   compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-01-19 15:47:43.970443 (MainThread): 
2021-01-19 15:47:43.970548 (MainThread): Database Error in test unique_cumulative_orders_by_date_date (models/example/schema.yml)
2021-01-19 15:47:43.970648 (MainThread):   000904 (42000): SQL compilation error: error line 5 at position 8
2021-01-19 15:47:43.970742 (MainThread):   invalid identifier 'DATE'
2021-01-19 15:47:43.970834 (MainThread):   compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/unique_cumulative_orders_by_date_date.sql
2021-01-19 15:47:43.970943 (MainThread): 
Done. PASS=5 WARN=0 ERROR=3 SKIP=0 TOTAL=8
2021-01-19 15:47:43.971121 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d681940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d681520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d681340>]}
2021-01-19 15:47:43.971327 (MainThread): Flushing usage events
2021-01-19 15:48:04.196666 (MainThread): Running with dbt=0.18.1
2021-01-19 15:48:04.272072 (MainThread): Loading KWallet
2021-01-19 15:48:04.272715 (MainThread): Loading SecretService
2021-01-19 15:48:04.273196 (MainThread): Loading Windows
2021-01-19 15:48:04.273816 (MainThread): Loading chainer
2021-01-19 15:48:04.274132 (MainThread): Loading macOS
2021-01-19 15:48:04.565151 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 15:48:04.566084 (MainThread): Tracking: tracking
2021-01-19 15:48:04.566389 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d834ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da43310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da430d0>]}
2021-01-19 15:48:04.605058 (MainThread): Got an acceptable cached parse result
2021-01-19 15:48:04.641873 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:48:04.720434 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:48:04.823126 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:48:04.824681 (MainThread): 
2021-01-19 15:48:04.825044 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:48:04.843092 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:48:04.857712 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:48:04.857860 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:48:04.857956 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 15:48:06.040242 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.18 seconds
2021-01-19 15:48:06.050462 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:48:06.314998 (MainThread): 16:48:06 | Concurrency: 1 threads (target='dev')
2021-01-19 15:48:06.315207 (MainThread): 16:48:06 | 
2021-01-19 15:48:06.317434 (Thread-1): Began running node test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:48:06.317635 (Thread-1): 16:48:06 | 1 of 8 START test not_null_cumulative_orders_by_date_date............ [RUN]
2021-01-19 15:48:06.317984 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:48:06.318145 (Thread-1): Compiling test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:48:06.355252 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_cumulative_orders_by_date_date"
2021-01-19 15:48:06.355878 (Thread-1): finished collecting timing info
2021-01-19 15:48:06.356554 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:48:06.356679 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: BEGIN
2021-01-19 15:48:06.356783 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:08.183552 (Thread-1): SQL status: SUCCESS 1 in 1.83 seconds
2021-01-19 15:48:08.183749 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:48:08.183860 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_cumulative_orders_by_date_date"} */

    
    



select count(*) as validation_errors
from analytics.dbt.cumulative_orders_by_date
where date is null
2021-01-19 15:48:08.388192 (Thread-1): Snowflake query id: 0199b774-0626-28b6-0000-003989037831
2021-01-19 15:48:08.388361 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 3 at position 6
invalid identifier 'DATE'
2021-01-19 15:48:08.388500 (Thread-1): finished collecting timing info
2021-01-19 15:48:08.388812 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: ROLLBACK
2021-01-19 15:48:08.796550 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: Close
2021-01-19 15:48:09.096944 (Thread-1): Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 3 at position 6
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 3 at position 6
invalid identifier 'DATE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 3 at position 6
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
2021-01-19 15:48:09.099525 (Thread-1): 16:48:09 | 1 of 8 ERROR not_null_cumulative_orders_by_date_date................. [ERROR in 2.78s]
2021-01-19 15:48:09.099734 (Thread-1): Finished running node test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:48:09.099979 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:48:09.100367 (Thread-1): 16:48:09 | 2 of 8 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 15:48:09.100828 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:48:09.101051 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:48:09.112266 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 15:48:09.112862 (Thread-1): finished collecting timing info
2021-01-19 15:48:09.113537 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:48:09.113654 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 15:48:09.113803 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:10.586554 (Thread-1): SQL status: SUCCESS 1 in 1.47 seconds
2021-01-19 15:48:10.586775 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:48:10.586903 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 15:48:10.894562 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 15:48:10.895063 (Thread-1): finished collecting timing info
2021-01-19 15:48:10.895533 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:48:11.406316 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 15:48:11.755084 (Thread-1): 16:48:11 | 2 of 8 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 2.65s]
2021-01-19 15:48:11.755295 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:48:11.755458 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:48:11.755704 (Thread-1): 16:48:11 | 3 of 8 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 15:48:11.756265 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:48:11.756477 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:48:11.812744 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 15:48:11.813282 (Thread-1): finished collecting timing info
2021-01-19 15:48:11.814013 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:48:11.814134 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 15:48:11.814250 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:12.753199 (Thread-1): SQL status: SUCCESS 1 in 0.94 seconds
2021-01-19 15:48:12.753464 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:48:12.753621 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 15:48:13.003698 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 15:48:13.004176 (Thread-1): finished collecting timing info
2021-01-19 15:48:13.004623 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:48:13.228143 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 15:48:13.508850 (Thread-1): 16:48:13 | 3 of 8 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.75s]
2021-01-19 15:48:13.509095 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:48:13.509319 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:48:13.509639 (Thread-1): 16:48:13 | 4 of 8 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 15:48:13.510109 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:48:13.510324 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:48:13.522484 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 15:48:13.522978 (Thread-1): finished collecting timing info
2021-01-19 15:48:13.523781 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:48:13.523916 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:48:13.524033 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:14.648036 (Thread-1): SQL status: SUCCESS 1 in 1.12 seconds
2021-01-19 15:48:14.648250 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:48:14.648377 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 15:48:14.828071 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 15:48:14.828453 (Thread-1): finished collecting timing info
2021-01-19 15:48:14.828767 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:48:15.242523 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:48:15.811249 (Thread-1): 16:48:15 | 4 of 8 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 2.30s]
2021-01-19 15:48:15.811461 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:48:15.811629 (Thread-1): Began running node test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:48:15.812129 (Thread-1): 16:48:15 | 5 of 8 START test unique_cumulative_orders_by_date_date.............. [RUN]
2021-01-19 15:48:15.812611 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:48:15.812766 (Thread-1): Compiling test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:48:15.828878 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_cumulative_orders_by_date_date"
2021-01-19 15:48:15.829398 (Thread-1): finished collecting timing info
2021-01-19 15:48:15.830321 (Thread-1): Using snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:48:15.830447 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: BEGIN
2021-01-19 15:48:15.830663 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:15.873842 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:48:15.874045 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:48:16.575627 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:48:16.575757 (MainThread): Connection 'test.dbt_learn.unique_cumulative_orders_by_date_date' was properly closed.
2021-01-19 15:48:16.575834 (MainThread): Flushing usage events
2021-01-19 15:48:17.009835 (MainThread): ctrl-c
2021-01-19 15:48:17.010242 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.10', 64954), raddr=('34.199.231.102', 443)>
2021-01-19 15:48:17.012218 (MainThread): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.10', 64953), raddr=('35.153.221.211', 443)>
2021-01-19 15:48:20.328039 (MainThread): Running with dbt=0.18.1
2021-01-19 15:48:20.405187 (MainThread): Loading KWallet
2021-01-19 15:48:20.405829 (MainThread): Loading SecretService
2021-01-19 15:48:20.406299 (MainThread): Loading Windows
2021-01-19 15:48:20.406918 (MainThread): Loading chainer
2021-01-19 15:48:20.407237 (MainThread): Loading macOS
2021-01-19 15:48:20.697820 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:48:20.698878 (MainThread): Tracking: tracking
2021-01-19 15:48:20.699107 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd0e4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf1dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf1d2e0>]}
2021-01-19 15:48:20.739036 (MainThread): Got an acceptable cached parse result
2021-01-19 15:48:20.824570 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:48:20.938955 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:48:20.940077 (MainThread): 
2021-01-19 15:48:20.940444 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:48:20.948251 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:48:20.964245 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:48:20.964423 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:48:20.964532 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:48:22.240293 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.28 seconds
2021-01-19 15:48:22.245389 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:48:22.584432 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:48:22.592684 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:48:22.592839 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:48:22.592957 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:48:23.930920 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.34 seconds
2021-01-19 15:48:23.937260 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:48:24.276638 (MainThread): Using snowflake connection "master".
2021-01-19 15:48:24.276812 (MainThread): On master: BEGIN
2021-01-19 15:48:24.276928 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:48:25.188760 (MainThread): SQL status: SUCCESS 1 in 0.91 seconds
2021-01-19 15:48:25.189049 (MainThread): On master: COMMIT
2021-01-19 15:48:25.189294 (MainThread): Using snowflake connection "master".
2021-01-19 15:48:25.189418 (MainThread): On master: COMMIT
2021-01-19 15:48:25.414100 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 15:48:25.414360 (MainThread): On master: Close
2021-01-19 15:48:25.780636 (MainThread): 16:48:25 | Concurrency: 1 threads (target='dev')
2021-01-19 15:48:25.780873 (MainThread): 16:48:25 | 
2021-01-19 15:48:25.783179 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:48:25.784597 (Thread-1): 16:48:25 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:48:25.784937 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:48:25.785094 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:48:25.816486 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:48:25.816946 (Thread-1): finished collecting timing info
2021-01-19 15:48:25.857599 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:48:25.858819 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:48:25.858946 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:48:25.859057 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:26.861419 (Thread-1): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 15:48:26.861607 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:48:26.861707 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
where id is not null


/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:48:29.588932 (Thread-1): SQL status: SUCCESS 1 in 2.73 seconds
2021-01-19 15:48:29.590142 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:48:29.590329 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:48:29.590435 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:48:29.773109 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 15:48:29.788763 (Thread-1): finished collecting timing info
2021-01-19 15:48:29.789085 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:48:30.701221 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29dcc0ec-e55f-4127-ab98-54155fc7c320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2416d0>]}
2021-01-19 15:48:30.702533 (Thread-1): 16:48:30 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 4.92s]
2021-01-19 15:48:30.702696 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:48:30.702851 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:48:30.704315 (Thread-1): 16:48:30 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:48:30.704765 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:48:30.704902 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:48:30.712251 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:48:30.712744 (Thread-1): finished collecting timing info
2021-01-19 15:48:30.717579 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:48:30.718775 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:48:30.718898 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:48:30.719007 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:32.087319 (Thread-1): SQL status: SUCCESS 1 in 1.37 seconds
2021-01-19 15:48:32.087517 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:48:32.087621 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:48:35.732601 (Thread-1): SQL status: SUCCESS 1 in 3.64 seconds
2021-01-19 15:48:35.733734 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:48:35.733925 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:48:35.734030 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:48:35.993038 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-19 15:48:35.996041 (Thread-1): finished collecting timing info
2021-01-19 15:48:35.996394 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:48:36.313474 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29dcc0ec-e55f-4127-ab98-54155fc7c320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9f6e50>]}
2021-01-19 15:48:36.314796 (Thread-1): 16:48:36 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 5.61s]
2021-01-19 15:48:36.314962 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:48:36.315122 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 15:48:36.316507 (Thread-1): 16:48:36 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 15:48:36.317007 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:36.317155 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 15:48:36.333935 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 15:48:36.334437 (Thread-1): finished collecting timing info
2021-01-19 15:48:36.364928 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:36.365105 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 15:48:36.365215 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:39.157142 (Thread-1): SQL status: SUCCESS 1 in 2.79 seconds
2021-01-19 15:48:39.169120 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:39.169290 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 15:48:39.722295 (Thread-1): SQL status: SUCCESS 28 in 0.55 seconds
2021-01-19 15:48:39.728268 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:39.728426 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:48:39.899781 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 15:48:39.905354 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:39.905475 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:48:40.401920 (Thread-1): SQL status: SUCCESS 28 in 0.50 seconds
2021-01-19 15:48:40.429357 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 15:48:40.432536 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:40.432652 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 15:48:40.653509 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 15:48:40.653750 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:40.653870 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 15:48:41.336503 (Thread-1): SQL status: SUCCESS 0 in 0.68 seconds
2021-01-19 15:48:41.338041 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:48:41.338315 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:48:41.338432 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:48:41.614142 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 15:48:41.618766 (Thread-1): finished collecting timing info
2021-01-19 15:48:41.619070 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 15:48:41.939578 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29dcc0ec-e55f-4127-ab98-54155fc7c320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9f6e50>]}
2021-01-19 15:48:41.940654 (Thread-1): 16:48:41 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 5.62s]
2021-01-19 15:48:41.940781 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 15:48:41.940939 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 15:48:41.942092 (Thread-1): 16:48:41 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 15:48:41.942493 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:41.942637 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 15:48:41.951367 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:48:41.951868 (Thread-1): finished collecting timing info
2021-01-19 15:48:41.958315 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:41.958442 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 15:48:41.958551 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:44.409263 (Thread-1): SQL status: SUCCESS 1 in 2.45 seconds
2021-01-19 15:48:44.412708 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:44.412844 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 15:48:44.648839 (Thread-1): SQL status: SUCCESS 10 in 0.24 seconds
2021-01-19 15:48:44.652675 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:44.652809 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:48:44.892730 (Thread-1): SQL status: SUCCESS 10 in 0.24 seconds
2021-01-19 15:48:44.897769 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:44.897959 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:48:45.198518 (Thread-1): SQL status: SUCCESS 10 in 0.30 seconds
2021-01-19 15:48:45.202027 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:48:45.203751 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:45.203850 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 15:48:45.948950 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2021-01-19 15:48:45.949153 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:45.949268 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 15:48:46.972557 (Thread-1): SQL status: SUCCESS 179 in 1.02 seconds
2021-01-19 15:48:46.974026 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:48:46.974223 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:48:46.974326 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:48:47.307743 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 15:48:47.312698 (Thread-1): finished collecting timing info
2021-01-19 15:48:47.313061 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 15:48:47.615990 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29dcc0ec-e55f-4127-ab98-54155fc7c320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db49580>]}
2021-01-19 15:48:47.617303 (Thread-1): 16:48:47 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 179 in 5.67s]
2021-01-19 15:48:47.617461 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 15:48:47.617614 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:48:47.618933 (Thread-1): 16:48:47 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 15:48:47.619352 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:48:47.619495 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:48:47.627136 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:48:47.627703 (Thread-1): finished collecting timing info
2021-01-19 15:48:47.633060 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:48:47.634326 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:48:47.634438 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 15:48:47.634540 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:49.051590 (Thread-1): SQL status: SUCCESS 1 in 1.42 seconds
2021-01-19 15:48:49.051799 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:48:49.051917 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 15:48:50.810161 (Thread-1): SQL status: SUCCESS 1 in 1.76 seconds
2021-01-19 15:48:50.811720 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:48:50.811978 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:48:50.812095 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:48:50.964347 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 15:48:50.967119 (Thread-1): finished collecting timing info
2021-01-19 15:48:50.967406 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 15:48:51.320237 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29dcc0ec-e55f-4127-ab98-54155fc7c320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc2ab20>]}
2021-01-19 15:48:51.321564 (Thread-1): 16:48:51 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.70s]
2021-01-19 15:48:51.321729 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:48:51.321884 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:48:51.323218 (Thread-1): 16:48:51 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 15:48:51.323557 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:48:51.323678 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 15:48:51.333362 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:48:51.333889 (Thread-1): finished collecting timing info
2021-01-19 15:48:51.338812 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:48:51.339620 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:48:51.339728 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 15:48:51.339832 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:48:52.292419 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2021-01-19 15:48:52.292700 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:48:52.292849 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 15:48:53.390691 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 15:48:53.392255 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:48:53.392534 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:48:53.392661 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:48:53.556049 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 15:48:53.559168 (Thread-1): finished collecting timing info
2021-01-19 15:48:53.559488 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 15:48:53.861096 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29dcc0ec-e55f-4127-ab98-54155fc7c320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df5b070>]}
2021-01-19 15:48:53.862486 (Thread-1): 16:48:53 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.54s]
2021-01-19 15:48:53.862700 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:48:53.864019 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:48:53.864358 (MainThread): Using snowflake connection "master".
2021-01-19 15:48:53.864462 (MainThread): On master: BEGIN
2021-01-19 15:48:53.864563 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:48:55.183583 (MainThread): SQL status: SUCCESS 1 in 1.32 seconds
2021-01-19 15:48:55.183776 (MainThread): On master: COMMIT
2021-01-19 15:48:55.183943 (MainThread): Using snowflake connection "master".
2021-01-19 15:48:55.184038 (MainThread): On master: COMMIT
2021-01-19 15:48:55.541232 (MainThread): SQL status: SUCCESS 1 in 0.36 seconds
2021-01-19 15:48:55.541514 (MainThread): On master: Close
2021-01-19 15:48:55.891863 (MainThread): 16:48:55 | 
2021-01-19 15:48:55.892058 (MainThread): 16:48:55 | Finished running 4 table models, 2 incremental models in 34.95s.
2021-01-19 15:48:55.892182 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:48:55.892297 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 15:48:55.913521 (MainThread): 
2021-01-19 15:48:55.913716 (MainThread): Completed successfully
2021-01-19 15:48:55.913854 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 15:48:55.914041 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc08cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db70970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dad9820>]}
2021-01-19 15:48:55.914252 (MainThread): Flushing usage events
2021-01-19 15:49:04.520623 (MainThread): Running with dbt=0.18.1
2021-01-19 15:49:04.596086 (MainThread): Loading KWallet
2021-01-19 15:49:04.596765 (MainThread): Loading SecretService
2021-01-19 15:49:04.597242 (MainThread): Loading Windows
2021-01-19 15:49:04.597874 (MainThread): Loading chainer
2021-01-19 15:49:04.598193 (MainThread): Loading macOS
2021-01-19 15:49:04.889253 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 15:49:04.890155 (MainThread): Tracking: tracking
2021-01-19 15:49:04.890387 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb039a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3ac7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc360d0>]}
2021-01-19 15:49:04.930769 (MainThread): Got an acceptable cached parse result
2021-01-19 15:49:05.015015 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:49:05.123259 (MainThread): Found 6 models, 8 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:49:05.125483 (MainThread): 
2021-01-19 15:49:05.126224 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:49:05.142409 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:49:05.157319 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:49:05.157447 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:49:05.157533 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 15:49:06.898848 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.74 seconds
2021-01-19 15:49:06.909521 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:49:07.423020 (MainThread): 16:49:07 | Concurrency: 1 threads (target='dev')
2021-01-19 15:49:07.423256 (MainThread): 16:49:07 | 
2021-01-19 15:49:07.425818 (Thread-1): Began running node test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:49:07.426074 (Thread-1): 16:49:07 | 1 of 8 START test not_null_cumulative_orders_by_date_date............ [RUN]
2021-01-19 15:49:07.426689 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:49:07.427062 (Thread-1): Compiling test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:49:07.467054 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_cumulative_orders_by_date_date"
2021-01-19 15:49:07.467538 (Thread-1): finished collecting timing info
2021-01-19 15:49:07.468218 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:49:07.468327 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: BEGIN
2021-01-19 15:49:07.468430 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:09.077912 (Thread-1): SQL status: SUCCESS 1 in 1.61 seconds
2021-01-19 15:49:09.078144 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_cumulative_orders_by_date_date".
2021-01-19 15:49:09.078273 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_cumulative_orders_by_date_date"} */

    
    



select count(*) as validation_errors
from analytics.dbt.cumulative_orders_by_date
where date is null
2021-01-19 15:49:09.366539 (Thread-1): Snowflake query id: 0199b775-0630-0569-0000-0039890357e1
2021-01-19 15:49:09.366771 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 3 at position 6
invalid identifier 'DATE'
2021-01-19 15:49:09.366969 (Thread-1): finished collecting timing info
2021-01-19 15:49:09.367424 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: ROLLBACK
2021-01-19 15:49:09.866180 (Thread-1): On test.dbt_learn.not_null_cumulative_orders_by_date_date: Close
2021-01-19 15:49:10.171637 (Thread-1): Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 3 at position 6
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 3 at position 6
invalid identifier 'DATE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 3 at position 6
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
2021-01-19 15:49:10.173860 (Thread-1): 16:49:10 | 1 of 8 ERROR not_null_cumulative_orders_by_date_date................. [ERROR in 2.75s]
2021-01-19 15:49:10.174031 (Thread-1): Finished running node test.dbt_learn.not_null_cumulative_orders_by_date_date
2021-01-19 15:49:10.174190 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:49:10.174568 (Thread-1): 16:49:10 | 2 of 8 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 15:49:10.175274 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:49:10.175505 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:49:10.188149 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 15:49:10.188642 (Thread-1): finished collecting timing info
2021-01-19 15:49:10.189281 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:49:10.189391 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 15:49:10.189496 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:11.852441 (Thread-1): SQL status: SUCCESS 1 in 1.66 seconds
2021-01-19 15:49:11.852641 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:49:11.852748 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 15:49:12.311497 (Thread-1): SQL status: SUCCESS 1 in 0.46 seconds
2021-01-19 15:49:12.311981 (Thread-1): finished collecting timing info
2021-01-19 15:49:12.312504 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:49:12.594179 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 15:49:12.901807 (Thread-1): 16:49:12 | 2 of 8 PASS not_null_my_first_dbt_model_id........................... [PASS in 2.73s]
2021-01-19 15:49:12.902021 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:49:12.902228 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:49:12.902560 (Thread-1): 16:49:12 | 3 of 8 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 15:49:12.903083 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:49:12.903249 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:49:12.914345 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 15:49:12.914878 (Thread-1): finished collecting timing info
2021-01-19 15:49:12.915541 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:49:12.915658 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 15:49:12.915766 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:14.309637 (Thread-1): SQL status: SUCCESS 1 in 1.39 seconds
2021-01-19 15:49:14.309903 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:49:14.310053 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 15:49:14.792164 (Thread-1): SQL status: SUCCESS 1 in 0.48 seconds
2021-01-19 15:49:14.792609 (Thread-1): finished collecting timing info
2021-01-19 15:49:14.792926 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:49:15.304549 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 15:49:15.873061 (Thread-1): 16:49:15 | 3 of 8 PASS not_null_my_second_dbt_model_id.......................... [PASS in 2.97s]
2021-01-19 15:49:15.873291 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:49:15.873517 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:49:15.873941 (Thread-1): 16:49:15 | 4 of 8 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 15:49:15.874407 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:49:15.874622 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:49:15.886320 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 15:49:15.886831 (Thread-1): finished collecting timing info
2021-01-19 15:49:15.887533 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:49:15.887649 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:49:15.887757 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:17.098683 (Thread-1): SQL status: SUCCESS 1 in 1.21 seconds
2021-01-19 15:49:17.098878 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:49:17.098986 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 15:49:17.660465 (Thread-1): SQL status: SUCCESS 1 in 0.56 seconds
2021-01-19 15:49:17.660962 (Thread-1): finished collecting timing info
2021-01-19 15:49:17.661551 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:49:17.996195 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:49:18.267214 (Thread-1): 16:49:18 | 4 of 8 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 2.39s]
2021-01-19 15:49:18.267464 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:49:18.267676 (Thread-1): Began running node test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:49:18.268050 (Thread-1): 16:49:18 | 5 of 8 START test unique_cumulative_orders_by_date_date.............. [RUN]
2021-01-19 15:49:18.268632 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:49:18.268858 (Thread-1): Compiling test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:49:18.284517 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_cumulative_orders_by_date_date"
2021-01-19 15:49:18.285027 (Thread-1): finished collecting timing info
2021-01-19 15:49:18.285867 (Thread-1): Using snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:49:18.285980 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: BEGIN
2021-01-19 15:49:18.286087 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:19.249561 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2021-01-19 15:49:19.249747 (Thread-1): Using snowflake connection "test.dbt_learn.unique_cumulative_orders_by_date_date".
2021-01-19 15:49:19.249853 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_cumulative_orders_by_date_date"} */

    
    



select count(*) as validation_errors
from (

    select
        date

    from analytics.dbt.cumulative_orders_by_date
    where date is not null
    group by date
    having count(*) > 1

) validation_errors
2021-01-19 15:49:19.493843 (Thread-1): Snowflake query id: 0199b775-0671-46a8-0000-0039890357f5
2021-01-19 15:49:19.494077 (Thread-1): Snowflake error: 000904 (42000): SQL compilation error: error line 5 at position 8
invalid identifier 'DATE'
2021-01-19 15:49:19.494264 (Thread-1): finished collecting timing info
2021-01-19 15:49:19.494749 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: ROLLBACK
2021-01-19 15:49:19.762968 (Thread-1): On test.dbt_learn.unique_cumulative_orders_by_date_date: Close
2021-01-19 15:49:20.195422 (Thread-1): Database Error in test unique_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 5 at position 8
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/unique_cumulative_orders_by_date_date.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): SQL compilation error: error line 5 at position 8
invalid identifier 'DATE'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in test unique_cumulative_orders_by_date_date (models/example/schema.yml)
  000904 (42000): SQL compilation error: error line 5 at position 8
  invalid identifier 'DATE'
  compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/unique_cumulative_orders_by_date_date.sql
2021-01-19 15:49:20.196108 (Thread-1): 16:49:20 | 5 of 8 ERROR unique_cumulative_orders_by_date_date................... [ERROR in 1.93s]
2021-01-19 15:49:20.196273 (Thread-1): Finished running node test.dbt_learn.unique_cumulative_orders_by_date_date
2021-01-19 15:49:20.196514 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:49:20.196971 (Thread-1): 16:49:20 | 6 of 8 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 15:49:20.197498 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:49:20.197781 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:49:20.209224 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 15:49:20.209717 (Thread-1): finished collecting timing info
2021-01-19 15:49:20.210649 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:49:20.210778 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 15:49:20.210890 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:21.316065 (Thread-1): SQL status: SUCCESS 1 in 1.11 seconds
2021-01-19 15:49:21.316283 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:49:21.316407 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 15:49:21.638559 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:49:21.639034 (Thread-1): finished collecting timing info
2021-01-19 15:49:21.639480 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:49:21.912167 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 15:49:22.219753 (Thread-1): 16:49:22 | 6 of 8 PASS unique_my_first_dbt_model_id............................. [PASS in 2.02s]
2021-01-19 15:49:22.219989 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:49:22.220220 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:49:22.220588 (Thread-1): 16:49:22 | 7 of 8 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 15:49:22.221072 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:49:22.221291 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:49:22.233681 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 15:49:22.234168 (Thread-1): finished collecting timing info
2021-01-19 15:49:22.234985 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:49:22.235096 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 15:49:22.235207 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:23.217545 (Thread-1): SQL status: SUCCESS 1 in 0.98 seconds
2021-01-19 15:49:23.217805 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:49:23.217957 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 15:49:23.598527 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2021-01-19 15:49:23.599006 (Thread-1): finished collecting timing info
2021-01-19 15:49:23.599372 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:49:23.865884 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 15:49:24.578471 (Thread-1): 16:49:24 | 7 of 8 PASS unique_my_second_dbt_model_id............................ [PASS in 2.36s]
2021-01-19 15:49:24.578715 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:49:24.578911 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:49:24.579092 (Thread-1): 16:49:24 | 8 of 8 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 15:49:24.579711 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:49:24.579886 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:49:24.591660 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 15:49:24.592183 (Thread-1): finished collecting timing info
2021-01-19 15:49:24.593105 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:49:24.593228 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:49:24.593337 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:25.715073 (Thread-1): SQL status: SUCCESS 1 in 1.12 seconds
2021-01-19 15:49:25.715263 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:49:25.715370 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 15:49:26.807071 (Thread-1): SQL status: SUCCESS 1 in 1.09 seconds
2021-01-19 15:49:26.807462 (Thread-1): finished collecting timing info
2021-01-19 15:49:26.807829 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:49:27.136155 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:49:27.488002 (Thread-1): 16:49:27 | 8 of 8 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 2.91s]
2021-01-19 15:49:27.488237 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:49:27.489714 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:49:27.490159 (MainThread): 16:49:27 | 
2021-01-19 15:49:27.490318 (MainThread): 16:49:27 | Finished running 8 tests in 22.36s.
2021-01-19 15:49:27.490443 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:49:27.490538 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 15:49:27.518232 (MainThread): 
2021-01-19 15:49:27.518415 (MainThread): Completed with 2 errors and 0 warnings:
2021-01-19 15:49:27.518543 (MainThread): 
2021-01-19 15:49:27.518664 (MainThread): Database Error in test not_null_cumulative_orders_by_date_date (models/example/schema.yml)
2021-01-19 15:49:27.518772 (MainThread):   000904 (42000): SQL compilation error: error line 3 at position 6
2021-01-19 15:49:27.518873 (MainThread):   invalid identifier 'DATE'
2021-01-19 15:49:27.518970 (MainThread):   compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_cumulative_orders_by_date_date.sql
2021-01-19 15:49:27.519075 (MainThread): 
2021-01-19 15:49:27.519186 (MainThread): Database Error in test unique_cumulative_orders_by_date_date (models/example/schema.yml)
2021-01-19 15:49:27.519289 (MainThread):   000904 (42000): SQL compilation error: error line 5 at position 8
2021-01-19 15:49:27.519386 (MainThread):   invalid identifier 'DATE'
2021-01-19 15:49:27.519482 (MainThread):   compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/unique_cumulative_orders_by_date_date.sql
2021-01-19 15:49:27.519597 (MainThread): 
Done. PASS=6 WARN=0 ERROR=2 SKIP=0 TOTAL=8
2021-01-19 15:49:27.519779 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ba2910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ba2a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ba2430>]}
2021-01-19 15:49:27.519982 (MainThread): Flushing usage events
2021-01-19 15:49:46.389911 (MainThread): Running with dbt=0.18.1
2021-01-19 15:49:46.467759 (MainThread): Loading KWallet
2021-01-19 15:49:46.468400 (MainThread): Loading SecretService
2021-01-19 15:49:46.468879 (MainThread): Loading Windows
2021-01-19 15:49:46.469499 (MainThread): Loading chainer
2021-01-19 15:49:46.469809 (MainThread): Loading macOS
2021-01-19 15:49:46.764822 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 15:49:46.765768 (MainThread): Tracking: tracking
2021-01-19 15:49:46.766027 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a3b760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c4bd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c4bdc0>]}
2021-01-19 15:49:46.805536 (MainThread): Got an acceptable cached parse result
2021-01-19 15:49:47.005721 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:49:47.101946 (MainThread): Found 6 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:49:47.103281 (MainThread): 
2021-01-19 15:49:47.103674 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:49:47.112455 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 15:49:47.127770 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 15:49:47.127942 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 15:49:47.128117 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 15:49:48.536512 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.41 seconds
2021-01-19 15:49:48.541541 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 15:49:48.827173 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:49:48.835199 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:49:48.835360 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:49:48.835467 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 15:49:50.414974 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.58 seconds
2021-01-19 15:49:50.422028 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:49:50.756502 (MainThread): Using snowflake connection "master".
2021-01-19 15:49:50.756700 (MainThread): On master: BEGIN
2021-01-19 15:49:50.756831 (MainThread): Opening a new connection, currently in state init
2021-01-19 15:49:51.833152 (MainThread): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 15:49:51.833387 (MainThread): On master: COMMIT
2021-01-19 15:49:51.833592 (MainThread): Using snowflake connection "master".
2021-01-19 15:49:51.833706 (MainThread): On master: COMMIT
2021-01-19 15:49:52.176361 (MainThread): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 15:49:52.176628 (MainThread): On master: Close
2021-01-19 15:49:52.531392 (MainThread): 16:49:52 | Concurrency: 1 threads (target='dev')
2021-01-19 15:49:52.531611 (MainThread): 16:49:52 | 
2021-01-19 15:49:52.533619 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:49:52.534999 (Thread-1): 16:49:52 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 15:49:52.535341 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:49:52.535479 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 15:49:52.567256 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:49:52.567759 (Thread-1): finished collecting timing info
2021-01-19 15:49:52.603753 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 15:49:52.604825 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:49:52.604935 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 15:49:52.605031 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:53.893593 (Thread-1): SQL status: SUCCESS 1 in 1.29 seconds
2021-01-19 15:49:53.893888 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:49:53.894071 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
where id is not null


/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 15:49:54.830825 (Thread-1): SQL status: SUCCESS 1 in 0.94 seconds
2021-01-19 15:49:54.832365 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:49:54.832582 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 15:49:54.832704 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 15:49:55.090741 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-19 15:49:55.105426 (Thread-1): finished collecting timing info
2021-01-19 15:49:55.105758 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 15:49:55.413895 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41039dda-7a68-4864-899d-251924e5cfad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3b2820>]}
2021-01-19 15:49:55.415230 (Thread-1): 16:49:55 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 2.88s]
2021-01-19 15:49:55.415395 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 15:49:55.415598 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:49:55.417295 (Thread-1): 16:49:55 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 15:49:55.417769 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:49:55.417913 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:49:55.424693 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:49:55.425163 (Thread-1): finished collecting timing info
2021-01-19 15:49:55.430846 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 15:49:55.431973 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:49:55.432096 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 15:49:55.432204 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:49:56.430776 (Thread-1): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 15:49:56.430996 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:49:56.431122 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 15:49:58.146776 (Thread-1): SQL status: SUCCESS 1 in 1.72 seconds
2021-01-19 15:49:58.147900 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:49:58.148077 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 15:49:58.148180 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 15:49:58.305001 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 15:49:58.308090 (Thread-1): finished collecting timing info
2021-01-19 15:49:58.308422 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 15:49:58.686829 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41039dda-7a68-4864-899d-251924e5cfad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d2f820>]}
2021-01-19 15:49:58.688356 (Thread-1): 16:49:58 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.27s]
2021-01-19 15:49:58.688545 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 15:49:58.688731 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 15:49:58.690613 (Thread-1): 16:49:58 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 15:49:58.690950 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 15:49:58.691078 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 15:49:58.707905 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 15:49:58.708413 (Thread-1): finished collecting timing info
2021-01-19 15:49:58.739962 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:49:58.740131 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 15:49:58.740235 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:00.233209 (Thread-1): SQL status: SUCCESS 1 in 1.49 seconds
2021-01-19 15:50:00.244051 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:50:00.244261 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 15:50:00.420696 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 15:50:00.426100 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:50:00.426273 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:50:00.585364 (Thread-1): SQL status: SUCCESS 28 in 0.16 seconds
2021-01-19 15:50:00.590601 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:50:00.590741 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 15:50:00.757516 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 15:50:00.786519 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 15:50:00.789700 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:50:00.789833 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 15:50:01.028311 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 15:50:01.028497 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:50:01.028604 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 15:50:01.746229 (Thread-1): SQL status: SUCCESS 0 in 0.72 seconds
2021-01-19 15:50:01.747284 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:50:01.747493 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 15:50:01.747613 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 15:50:01.998687 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 15:50:02.003010 (Thread-1): finished collecting timing info
2021-01-19 15:50:02.003255 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 15:50:02.447454 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41039dda-7a68-4864-899d-251924e5cfad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d2f250>]}
2021-01-19 15:50:02.448989 (Thread-1): 16:50:02 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.76s]
2021-01-19 15:50:02.449183 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 15:50:02.449423 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 15:50:02.452134 (Thread-1): 16:50:02 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 15:50:02.452844 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:02.453016 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 15:50:02.462364 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:50:02.462888 (Thread-1): finished collecting timing info
2021-01-19 15:50:02.469409 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:02.469535 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 15:50:02.469648 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:04.716927 (Thread-1): SQL status: SUCCESS 1 in 2.25 seconds
2021-01-19 15:50:04.719841 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:04.719970 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 15:50:04.925062 (Thread-1): SQL status: SUCCESS 10 in 0.20 seconds
2021-01-19 15:50:04.929314 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:04.929489 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:50:05.124677 (Thread-1): SQL status: SUCCESS 10 in 0.20 seconds
2021-01-19 15:50:05.128878 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:05.129031 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 15:50:05.523739 (Thread-1): SQL status: SUCCESS 10 in 0.39 seconds
2021-01-19 15:50:05.526902 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 15:50:05.528840 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:05.528969 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 15:50:05.756602 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 15:50:05.756760 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:05.756862 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 15:50:06.465490 (Thread-1): SQL status: SUCCESS 80 in 0.71 seconds
2021-01-19 15:50:06.466618 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:50:06.466822 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 15:50:06.466925 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 15:50:07.020817 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-01-19 15:50:07.024766 (Thread-1): finished collecting timing info
2021-01-19 15:50:07.025300 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 15:50:07.367273 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41039dda-7a68-4864-899d-251924e5cfad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118a3b20>]}
2021-01-19 15:50:07.368567 (Thread-1): 16:50:07 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 80 in 4.91s]
2021-01-19 15:50:07.368734 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 15:50:07.368892 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:50:07.370387 (Thread-1): 16:50:07 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 15:50:07.370835 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:50:07.370976 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:50:07.379906 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:50:07.380419 (Thread-1): finished collecting timing info
2021-01-19 15:50:07.385562 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 15:50:07.386793 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:50:07.386915 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 15:50:07.387028 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:08.404039 (Thread-1): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-19 15:50:08.404224 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:50:08.404327 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 15:50:09.880571 (Thread-1): SQL status: SUCCESS 1 in 1.48 seconds
2021-01-19 15:50:09.881848 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:50:09.882058 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 15:50:09.882179 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 15:50:10.039409 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 15:50:10.042486 (Thread-1): finished collecting timing info
2021-01-19 15:50:10.042814 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 15:50:10.395072 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41039dda-7a68-4864-899d-251924e5cfad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118b1ac0>]}
2021-01-19 15:50:10.396395 (Thread-1): 16:50:10 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.02s]
2021-01-19 15:50:10.396559 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 15:50:10.396773 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:50:10.398062 (Thread-1): 16:50:10 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 15:50:10.398408 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:50:10.398539 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 15:50:10.407874 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:50:10.408317 (Thread-1): finished collecting timing info
2021-01-19 15:50:10.413432 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 15:50:10.414303 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:50:10.414420 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 15:50:10.414528 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:11.517926 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 15:50:11.518136 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:50:11.518238 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 15:50:12.946426 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-01-19 15:50:12.947688 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:50:12.947907 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 15:50:12.948028 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 15:50:13.112909 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 15:50:13.115777 (Thread-1): finished collecting timing info
2021-01-19 15:50:13.116140 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 15:50:13.432420 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41039dda-7a68-4864-899d-251924e5cfad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111957be0>]}
2021-01-19 15:50:13.433965 (Thread-1): 16:50:13 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 3.03s]
2021-01-19 15:50:13.434133 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 15:50:13.435328 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:50:13.435573 (MainThread): Using snowflake connection "master".
2021-01-19 15:50:13.435681 (MainThread): On master: BEGIN
2021-01-19 15:50:13.435787 (MainThread): Opening a new connection, currently in state closed
2021-01-19 15:50:15.183615 (MainThread): SQL status: SUCCESS 1 in 1.75 seconds
2021-01-19 15:50:15.183901 (MainThread): On master: COMMIT
2021-01-19 15:50:15.184163 (MainThread): Using snowflake connection "master".
2021-01-19 15:50:15.184313 (MainThread): On master: COMMIT
2021-01-19 15:50:16.073586 (MainThread): SQL status: SUCCESS 1 in 0.89 seconds
2021-01-19 15:50:16.073874 (MainThread): On master: Close
2021-01-19 15:50:16.376550 (MainThread): 16:50:16 | 
2021-01-19 15:50:16.376792 (MainThread): 16:50:16 | Finished running 4 table models, 2 incremental models in 29.27s.
2021-01-19 15:50:16.376946 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:50:16.377114 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 15:50:16.399377 (MainThread): 
2021-01-19 15:50:16.399568 (MainThread): Completed successfully
2021-01-19 15:50:16.399706 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 15:50:16.399900 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118e2760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110810d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117f72e0>]}
2021-01-19 15:50:16.400117 (MainThread): Flushing usage events
2021-01-19 15:50:21.941991 (MainThread): Running with dbt=0.18.1
2021-01-19 15:50:22.021560 (MainThread): Loading KWallet
2021-01-19 15:50:22.022167 (MainThread): Loading SecretService
2021-01-19 15:50:22.022638 (MainThread): Loading Windows
2021-01-19 15:50:22.023263 (MainThread): Loading chainer
2021-01-19 15:50:22.023562 (MainThread): Loading macOS
2021-01-19 15:50:22.328962 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 15:50:22.330041 (MainThread): Tracking: tracking
2021-01-19 15:50:22.330277 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c409a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074da7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d730d0>]}
2021-01-19 15:50:22.369189 (MainThread): Got an acceptable cached parse result
2021-01-19 15:50:22.455855 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 15:50:22.556803 (MainThread): Found 6 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 15:50:22.558840 (MainThread): 
2021-01-19 15:50:22.559346 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:50:22.576596 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 15:50:22.592702 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 15:50:22.592911 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 15:50:22.593109 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 15:50:23.968199 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.38 seconds
2021-01-19 15:50:23.979361 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 15:50:24.401584 (MainThread): 16:50:24 | Concurrency: 1 threads (target='dev')
2021-01-19 15:50:24.401780 (MainThread): 16:50:24 | 
2021-01-19 15:50:24.403956 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:50:24.404154 (Thread-1): 16:50:24 | 1 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 15:50:24.404455 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:50:24.404597 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:50:24.445003 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 15:50:24.445529 (Thread-1): finished collecting timing info
2021-01-19 15:50:24.446179 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:50:24.446291 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 15:50:24.446395 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:25.607214 (Thread-1): SQL status: SUCCESS 1 in 1.16 seconds
2021-01-19 15:50:25.607476 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 15:50:25.607623 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 15:50:25.929816 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 15:50:25.930176 (Thread-1): finished collecting timing info
2021-01-19 15:50:25.930487 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:50:26.778934 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 15:50:27.325249 (Thread-1): 16:50:27 | 1 of 6 PASS not_null_my_first_dbt_model_id........................... [PASS in 2.92s]
2021-01-19 15:50:27.325465 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 15:50:27.325696 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:50:27.326170 (Thread-1): 16:50:27 | 2 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 15:50:27.326687 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:50:27.326994 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:50:27.339125 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 15:50:27.339599 (Thread-1): finished collecting timing info
2021-01-19 15:50:27.340237 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:50:27.340349 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 15:50:27.340452 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:29.866719 (Thread-1): SQL status: SUCCESS 1 in 2.53 seconds
2021-01-19 15:50:29.866979 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 15:50:29.867127 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 15:50:30.836185 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-01-19 15:50:30.836648 (Thread-1): finished collecting timing info
2021-01-19 15:50:30.837091 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:50:31.171540 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 15:50:31.441687 (Thread-1): 16:50:31 | 2 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 4.12s]
2021-01-19 15:50:31.441883 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 15:50:31.442075 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:50:31.442424 (Thread-1): 16:50:31 | 3 of 6 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 15:50:31.443074 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:50:31.443280 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:50:31.455329 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 15:50:31.455814 (Thread-1): finished collecting timing info
2021-01-19 15:50:31.456497 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:50:31.456608 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:50:31.456713 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:32.887325 (Thread-1): SQL status: SUCCESS 1 in 1.43 seconds
2021-01-19 15:50:32.887582 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 15:50:32.887732 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 15:50:35.260621 (Thread-1): SQL status: SUCCESS 1 in 2.37 seconds
2021-01-19 15:50:35.261044 (Thread-1): finished collecting timing info
2021-01-19 15:50:35.261427 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:50:35.792556 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:50:36.130635 (Thread-1): 16:50:36 | 3 of 6 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 4.69s]
2021-01-19 15:50:36.130878 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 15:50:36.131070 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:50:36.131371 (Thread-1): 16:50:36 | 4 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 15:50:36.131933 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:50:36.132105 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:50:36.186728 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 15:50:36.187229 (Thread-1): finished collecting timing info
2021-01-19 15:50:36.188110 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:50:36.188251 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 15:50:36.188365 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:37.577779 (Thread-1): SQL status: SUCCESS 1 in 1.39 seconds
2021-01-19 15:50:37.578034 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 15:50:37.578187 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 15:50:37.801224 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 15:50:37.801677 (Thread-1): finished collecting timing info
2021-01-19 15:50:37.802111 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 15:50:38.022914 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 15:50:38.351246 (Thread-1): 16:50:38 | 4 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 2.22s]
2021-01-19 15:50:38.351480 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 15:50:38.351689 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:50:38.352061 (Thread-1): 16:50:38 | 5 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 15:50:38.352570 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:50:38.352777 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:50:38.364629 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 15:50:38.365113 (Thread-1): finished collecting timing info
2021-01-19 15:50:38.365923 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:50:38.366035 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 15:50:38.366140 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:39.410026 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 15:50:39.410291 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 15:50:39.410445 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 15:50:39.624163 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 15:50:39.624659 (Thread-1): finished collecting timing info
2021-01-19 15:50:39.625109 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 15:50:40.113116 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 15:50:40.605562 (Thread-1): 16:50:40 | 5 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 2.25s]
2021-01-19 15:50:40.605798 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 15:50:40.606001 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:50:40.606185 (Thread-1): 16:50:40 | 6 of 6 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 15:50:40.606815 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:50:40.607010 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:50:40.618505 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 15:50:40.618987 (Thread-1): finished collecting timing info
2021-01-19 15:50:40.619856 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:50:40.619968 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 15:50:40.620074 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 15:50:42.447368 (Thread-1): SQL status: SUCCESS 1 in 1.83 seconds
2021-01-19 15:50:42.447634 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 15:50:42.447799 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 15:50:42.807546 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-01-19 15:50:42.808013 (Thread-1): finished collecting timing info
2021-01-19 15:50:42.808451 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 15:50:43.375660 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 15:50:44.718064 (Thread-1): 16:50:44 | 6 of 6 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 4.11s]
2021-01-19 15:50:44.718269 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 15:50:44.719702 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 15:50:44.720031 (MainThread): 16:50:44 | 
2021-01-19 15:50:44.720170 (MainThread): 16:50:44 | Finished running 6 tests in 22.16s.
2021-01-19 15:50:44.720285 (MainThread): Connection 'master' was properly closed.
2021-01-19 15:50:44.720373 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 15:50:44.741496 (MainThread): 
2021-01-19 15:50:44.741678 (MainThread): Completed successfully
2021-01-19 15:50:44.741817 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 15:50:44.742013 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109909b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10999b190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10999b2b0>]}
2021-01-19 15:50:44.742230 (MainThread): Flushing usage events
2021-01-19 17:03:05.798399 (MainThread): Running with dbt=0.18.1
2021-01-19 17:03:05.962031 (MainThread): Loading KWallet
2021-01-19 17:03:05.963004 (MainThread): Loading SecretService
2021-01-19 17:03:05.963818 (MainThread): Loading Windows
2021-01-19 17:03:05.964859 (MainThread): Loading chainer
2021-01-19 17:03:05.965438 (MainThread): Loading macOS
2021-01-19 17:03:06.456850 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 17:03:06.458167 (MainThread): Tracking: tracking
2021-01-19 17:03:06.458586 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e93970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f72d7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fc70a0>]}
2021-01-19 17:03:06.506476 (MainThread): Got an acceptable cached parse result
2021-01-19 17:03:06.597667 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:03:06.706628 (MainThread): Found 6 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:03:06.708794 (MainThread): 
2021-01-19 17:03:06.709369 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:03:06.727263 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:03:06.743918 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:03:06.744060 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:03:06.744156 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 17:03:08.011263 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.27 seconds
2021-01-19 17:03:08.021903 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:03:08.282515 (MainThread): 18:03:08 | Concurrency: 1 threads (target='dev')
2021-01-19 17:03:08.282726 (MainThread): 18:03:08 | 
2021-01-19 17:03:08.286232 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:03:08.286647 (Thread-1): 18:03:08 | 1 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 17:03:08.287624 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:03:08.288108 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:03:08.334780 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 17:03:08.335746 (Thread-1): finished collecting timing info
2021-01-19 17:03:08.336531 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:03:08.336648 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 17:03:08.336748 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:09.370288 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-01-19 17:03:09.370519 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:03:09.370643 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 17:03:09.577063 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 17:03:09.577411 (Thread-1): finished collecting timing info
2021-01-19 17:03:09.577731 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:03:09.781774 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 17:03:10.039439 (Thread-1): 18:03:10 | 1 of 6 PASS not_null_my_first_dbt_model_id........................... [PASS in 1.75s]
2021-01-19 17:03:10.039635 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:03:10.039832 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:03:10.040108 (Thread-1): 18:03:10 | 2 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 17:03:10.040491 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:03:10.040672 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:03:10.054398 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 17:03:10.054920 (Thread-1): finished collecting timing info
2021-01-19 17:03:10.055669 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:03:10.055857 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 17:03:10.056068 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:10.932005 (Thread-1): SQL status: SUCCESS 1 in 0.88 seconds
2021-01-19 17:03:10.932197 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:03:10.932299 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 17:03:11.158530 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 17:03:11.158866 (Thread-1): finished collecting timing info
2021-01-19 17:03:11.159180 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:03:11.394467 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 17:03:11.649975 (Thread-1): 18:03:11 | 2 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.61s]
2021-01-19 17:03:11.650149 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:03:11.650286 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:03:11.650644 (Thread-1): 18:03:11 | 3 of 6 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 17:03:11.651113 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:03:11.651345 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:03:11.662068 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 17:03:11.663186 (Thread-1): finished collecting timing info
2021-01-19 17:03:11.663750 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:03:11.663836 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:03:11.663980 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:12.727726 (Thread-1): SQL status: SUCCESS 1 in 1.06 seconds
2021-01-19 17:03:12.727892 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:03:12.727976 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 17:03:12.936905 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 17:03:12.937372 (Thread-1): finished collecting timing info
2021-01-19 17:03:12.937821 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:03:13.185560 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:03:13.436587 (Thread-1): 18:03:13 | 3 of 6 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 1.79s]
2021-01-19 17:03:13.436814 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:03:13.437074 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:03:13.437509 (Thread-1): 18:03:13 | 4 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 17:03:13.438044 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:03:13.438254 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:03:13.498535 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 17:03:13.499413 (Thread-1): finished collecting timing info
2021-01-19 17:03:13.500637 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:03:13.500785 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 17:03:13.500902 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:14.553830 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-01-19 17:03:14.554019 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:03:14.554123 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:03:14.755698 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 17:03:14.756020 (Thread-1): finished collecting timing info
2021-01-19 17:03:14.756324 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:03:14.958391 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 17:03:15.404432 (Thread-1): 18:03:15 | 4 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 1.97s]
2021-01-19 17:03:15.404665 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:03:15.404859 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:03:15.405130 (Thread-1): 18:03:15 | 5 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 17:03:15.405469 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:03:15.405613 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:03:15.417124 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 17:03:15.417625 (Thread-1): finished collecting timing info
2021-01-19 17:03:15.418498 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:03:15.418634 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 17:03:15.418745 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:16.408969 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 17:03:16.409147 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:03:16.409252 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:03:16.716671 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 17:03:16.717022 (Thread-1): finished collecting timing info
2021-01-19 17:03:16.717382 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:03:16.929428 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 17:03:17.183929 (Thread-1): 18:03:17 | 5 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 1.78s]
2021-01-19 17:03:17.184170 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:03:17.184641 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:03:17.185006 (Thread-1): 18:03:17 | 6 of 6 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 17:03:17.185415 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:03:17.185574 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:03:17.197137 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 17:03:17.197987 (Thread-1): finished collecting timing info
2021-01-19 17:03:17.198831 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:03:17.198937 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:03:17.199037 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:18.442395 (Thread-1): SQL status: SUCCESS 1 in 1.24 seconds
2021-01-19 17:03:18.442608 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:03:18.442731 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 17:03:18.660572 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 17:03:18.660909 (Thread-1): finished collecting timing info
2021-01-19 17:03:18.661216 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:03:19.051714 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:03:19.309870 (Thread-1): 18:03:19 | 6 of 6 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 2.12s]
2021-01-19 17:03:19.310076 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:03:19.311328 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:03:19.311648 (MainThread): 18:03:19 | 
2021-01-19 17:03:19.311786 (MainThread): 18:03:19 | Finished running 6 tests in 12.60s.
2021-01-19 17:03:19.311905 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:03:19.311994 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 17:03:19.333495 (MainThread): 
2021-01-19 17:03:19.333682 (MainThread): Completed successfully
2021-01-19 17:03:19.333820 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 17:03:19.334011 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cbde80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111be4130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111be4880>]}
2021-01-19 17:03:19.334232 (MainThread): Flushing usage events
2021-01-19 17:03:49.648774 (MainThread): Running with dbt=0.18.1
2021-01-19 17:03:49.727625 (MainThread): Loading KWallet
2021-01-19 17:03:49.728276 (MainThread): Loading SecretService
2021-01-19 17:03:49.728756 (MainThread): Loading Windows
2021-01-19 17:03:49.729370 (MainThread): Loading chainer
2021-01-19 17:03:49.729680 (MainThread): Loading macOS
2021-01-19 17:03:50.018582 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 17:03:50.019653 (MainThread): Tracking: tracking
2021-01-19 17:03:50.019983 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c29550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e39040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e39d90>]}
2021-01-19 17:03:50.061555 (MainThread): Got an acceptable cached parse result
2021-01-19 17:03:50.148423 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:03:50.247077 (MainThread): Found 6 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:03:50.248513 (MainThread): 
2021-01-19 17:03:50.249228 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:03:50.258033 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 17:03:50.271920 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 17:03:50.272045 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 17:03:50.272125 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 17:03:51.375391 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.10 seconds
2021-01-19 17:03:51.379740 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 17:03:51.681812 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:03:51.688575 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:03:51.688710 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:03:51.688794 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 17:03:52.795860 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.11 seconds
2021-01-19 17:03:52.802130 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:03:53.066699 (MainThread): Using snowflake connection "master".
2021-01-19 17:03:53.067467 (MainThread): On master: BEGIN
2021-01-19 17:03:53.067579 (MainThread): Opening a new connection, currently in state init
2021-01-19 17:03:54.247525 (MainThread): SQL status: SUCCESS 1 in 1.18 seconds
2021-01-19 17:03:54.247721 (MainThread): On master: COMMIT
2021-01-19 17:03:54.247894 (MainThread): Using snowflake connection "master".
2021-01-19 17:03:54.247996 (MainThread): On master: COMMIT
2021-01-19 17:03:54.474921 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 17:03:54.475212 (MainThread): On master: Close
2021-01-19 17:03:54.753336 (MainThread): 18:03:54 | Concurrency: 1 threads (target='dev')
2021-01-19 17:03:54.753550 (MainThread): 18:03:54 | 
2021-01-19 17:03:54.755695 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:03:54.756994 (Thread-1): 18:03:54 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 17:03:54.757321 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:03:54.757457 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 17:03:54.787727 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:03:54.788572 (Thread-1): finished collecting timing info
2021-01-19 17:03:54.820412 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:03:54.821333 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:03:54.821415 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 17:03:54.821489 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:56.429355 (Thread-1): SQL status: SUCCESS 1 in 1.61 seconds
2021-01-19 17:03:56.429617 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:03:56.429772 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
where id is not null


/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 17:03:57.659970 (Thread-1): SQL status: SUCCESS 1 in 1.23 seconds
2021-01-19 17:03:57.660876 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:03:57.661003 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:03:57.661076 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:03:57.804057 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-01-19 17:03:57.818236 (Thread-1): finished collecting timing info
2021-01-19 17:03:57.818546 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 17:03:58.087760 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4a34dd-ab7f-4f09-8569-9b4d2b1ac4ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111de1e50>]}
2021-01-19 17:03:58.089069 (Thread-1): 18:03:58 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 3.33s]
2021-01-19 17:03:58.089237 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:03:58.089392 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:03:58.091056 (Thread-1): 18:03:58 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 17:03:58.091580 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:03:58.091722 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:03:58.136965 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:03:58.137756 (Thread-1): finished collecting timing info
2021-01-19 17:03:58.142694 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:03:58.143765 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:03:58.143879 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 17:03:58.143987 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:03:59.118545 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-01-19 17:03:59.118822 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:03:59.118986 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 17:04:01.650197 (Thread-1): SQL status: SUCCESS 1 in 2.53 seconds
2021-01-19 17:04:01.651058 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:04:01.651200 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:04:01.651275 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:04:01.818697 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 17:04:01.820924 (Thread-1): finished collecting timing info
2021-01-19 17:04:01.821197 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 17:04:02.102346 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4a34dd-ab7f-4f09-8569-9b4d2b1ac4ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a556d0>]}
2021-01-19 17:04:02.103985 (Thread-1): 18:04:02 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 4.01s]
2021-01-19 17:04:02.104187 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:04:02.104361 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 17:04:02.105632 (Thread-1): 18:04:02 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 17:04:02.105970 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:02.106099 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 17:04:02.122750 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 17:04:02.124168 (Thread-1): finished collecting timing info
2021-01-19 17:04:02.154712 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:02.154864 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 17:04:02.154961 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:03.563771 (Thread-1): SQL status: SUCCESS 1 in 1.41 seconds
2021-01-19 17:04:03.572618 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:03.572743 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 17:04:03.834232 (Thread-1): SQL status: SUCCESS 28 in 0.26 seconds
2021-01-19 17:04:03.839589 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:03.839726 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:04:04.014754 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 17:04:04.019801 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:04.019941 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:04:04.259380 (Thread-1): SQL status: SUCCESS 28 in 0.24 seconds
2021-01-19 17:04:04.286530 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 17:04:04.290391 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:04.290508 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 17:04:04.509172 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 17:04:04.509353 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:04.509454 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 17:04:05.219353 (Thread-1): SQL status: SUCCESS 0 in 0.71 seconds
2021-01-19 17:04:05.220749 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:04:05.220971 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:04:05.221093 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:04:05.524790 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 17:04:05.529073 (Thread-1): finished collecting timing info
2021-01-19 17:04:05.529340 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 17:04:05.791689 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4a34dd-ab7f-4f09-8569-9b4d2b1ac4ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f21b50>]}
2021-01-19 17:04:05.792989 (Thread-1): 18:04:05 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.69s]
2021-01-19 17:04:05.793153 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 17:04:05.793431 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 17:04:05.795021 (Thread-1): 18:04:05 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 17:04:05.795359 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:05.795488 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 17:04:05.805244 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:04:05.806205 (Thread-1): finished collecting timing info
2021-01-19 17:04:05.812543 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:05.812679 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 17:04:05.812787 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:07.973498 (Thread-1): SQL status: SUCCESS 1 in 2.16 seconds
2021-01-19 17:04:07.976499 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:07.976614 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 17:04:08.158623 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-19 17:04:08.162128 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:08.162275 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:04:08.319387 (Thread-1): SQL status: SUCCESS 10 in 0.16 seconds
2021-01-19 17:04:08.324181 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:08.324319 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:04:08.479919 (Thread-1): SQL status: SUCCESS 10 in 0.16 seconds
2021-01-19 17:04:08.483129 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:04:08.485950 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:08.486098 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 17:04:08.661830 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 17:04:08.661980 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:08.662064 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 17:04:09.689844 (Thread-1): SQL status: SUCCESS 4443 in 1.03 seconds
2021-01-19 17:04:09.690899 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:04:09.691074 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:04:09.691170 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:04:10.029626 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 17:04:10.033404 (Thread-1): finished collecting timing info
2021-01-19 17:04:10.033697 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 17:04:10.336384 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4a34dd-ab7f-4f09-8569-9b4d2b1ac4ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119112b0>]}
2021-01-19 17:04:10.337593 (Thread-1): 18:04:10 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 4443 in 4.54s]
2021-01-19 17:04:10.337731 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 17:04:10.337864 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:04:10.339304 (Thread-1): 18:04:10 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 17:04:10.339670 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:04:10.339784 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:04:10.346499 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:04:10.347227 (Thread-1): finished collecting timing info
2021-01-19 17:04:10.351267 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:04:10.352784 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:04:10.352885 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 17:04:10.353018 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:11.345417 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 17:04:11.345615 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:04:11.345732 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 17:04:13.227088 (Thread-1): SQL status: SUCCESS 1 in 1.88 seconds
2021-01-19 17:04:13.228023 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:04:13.228173 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:04:13.228255 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:04:13.391048 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 17:04:13.393012 (Thread-1): finished collecting timing info
2021-01-19 17:04:13.393246 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 17:04:13.666155 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4a34dd-ab7f-4f09-8569-9b4d2b1ac4ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a7bc70>]}
2021-01-19 17:04:13.667235 (Thread-1): 18:04:13 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.33s]
2021-01-19 17:04:13.667357 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:04:13.667471 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:04:13.668515 (Thread-1): 18:04:13 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 17:04:13.668884 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:04:13.668984 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 17:04:13.676308 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:04:13.677702 (Thread-1): finished collecting timing info
2021-01-19 17:04:13.681140 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:04:13.682160 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:04:13.682255 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 17:04:13.682368 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:14.688850 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-01-19 17:04:14.688988 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:04:14.689059 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 17:04:15.614493 (Thread-1): SQL status: SUCCESS 1 in 0.93 seconds
2021-01-19 17:04:15.615472 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:04:15.615626 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:04:15.615709 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:04:15.772102 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 17:04:15.774360 (Thread-1): finished collecting timing info
2021-01-19 17:04:15.774624 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 17:04:16.036327 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4a34dd-ab7f-4f09-8569-9b4d2b1ac4ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111de1e80>]}
2021-01-19 17:04:16.037871 (Thread-1): 18:04:16 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.37s]
2021-01-19 17:04:16.038057 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:04:16.039882 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:04:16.040241 (MainThread): Using snowflake connection "master".
2021-01-19 17:04:16.040416 (MainThread): On master: BEGIN
2021-01-19 17:04:16.040596 (MainThread): Opening a new connection, currently in state closed
2021-01-19 17:04:17.041246 (MainThread): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 17:04:17.041405 (MainThread): On master: COMMIT
2021-01-19 17:04:17.041544 (MainThread): Using snowflake connection "master".
2021-01-19 17:04:17.041619 (MainThread): On master: COMMIT
2021-01-19 17:04:17.353796 (MainThread): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 17:04:17.353947 (MainThread): On master: Close
2021-01-19 17:04:17.623495 (MainThread): 18:04:17 | 
2021-01-19 17:04:17.623662 (MainThread): 18:04:17 | Finished running 4 table models, 2 incremental models in 27.37s.
2021-01-19 17:04:17.623768 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:04:17.623900 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 17:04:17.640629 (MainThread): 
2021-01-19 17:04:17.640764 (MainThread): Completed successfully
2021-01-19 17:04:17.640853 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 17:04:17.641117 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dbf940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119f88b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119f81c0>]}
2021-01-19 17:04:17.641287 (MainThread): Flushing usage events
2021-01-19 17:04:28.110655 (MainThread): Running with dbt=0.18.1
2021-01-19 17:04:28.191762 (MainThread): Loading KWallet
2021-01-19 17:04:28.192310 (MainThread): Loading SecretService
2021-01-19 17:04:28.192712 (MainThread): Loading Windows
2021-01-19 17:04:28.193248 (MainThread): Loading chainer
2021-01-19 17:04:28.193508 (MainThread): Loading macOS
2021-01-19 17:04:28.504959 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 17:04:28.508247 (MainThread): Tracking: tracking
2021-01-19 17:04:28.508543 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126d7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f737c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11280b0a0>]}
2021-01-19 17:04:28.567908 (MainThread): Got an acceptable cached parse result
2021-01-19 17:04:28.659905 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:04:28.758057 (MainThread): Found 6 models, 6 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:04:28.759919 (MainThread): 
2021-01-19 17:04:28.760414 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:04:28.777266 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:04:28.794236 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:04:28.794443 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:04:28.794600 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 17:04:29.929384 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.13 seconds
2021-01-19 17:04:29.940030 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:04:30.211429 (MainThread): 18:04:30 | Concurrency: 1 threads (target='dev')
2021-01-19 17:04:30.211630 (MainThread): 18:04:30 | 
2021-01-19 17:04:30.213741 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:04:30.213934 (Thread-1): 18:04:30 | 1 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 17:04:30.214235 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:04:30.214384 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:04:30.253577 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 17:04:30.254281 (Thread-1): finished collecting timing info
2021-01-19 17:04:30.254898 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:04:30.255001 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 17:04:30.255097 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:31.046306 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-01-19 17:04:31.046490 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:04:31.046594 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 17:04:31.325405 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-19 17:04:31.325815 (Thread-1): finished collecting timing info
2021-01-19 17:04:31.326174 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:04:31.558063 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 17:04:31.815673 (Thread-1): 18:04:31 | 1 of 6 PASS not_null_my_first_dbt_model_id........................... [PASS in 1.60s]
2021-01-19 17:04:31.815916 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:04:31.816118 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:04:31.816512 (Thread-1): 18:04:31 | 2 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 17:04:31.817113 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:04:31.817411 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:04:31.827083 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 17:04:31.827535 (Thread-1): finished collecting timing info
2021-01-19 17:04:31.828043 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:04:31.828129 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 17:04:31.828225 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:32.861524 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-01-19 17:04:32.861685 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:04:32.861775 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 17:04:33.238138 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2021-01-19 17:04:33.238434 (Thread-1): finished collecting timing info
2021-01-19 17:04:33.238701 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:04:33.439262 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 17:04:33.696200 (Thread-1): 18:04:33 | 2 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.88s]
2021-01-19 17:04:33.696435 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:04:33.696751 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:04:33.697163 (Thread-1): 18:04:33 | 3 of 6 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 17:04:33.697697 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:04:33.697914 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:04:33.709651 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 17:04:33.710159 (Thread-1): finished collecting timing info
2021-01-19 17:04:33.710850 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:04:33.710962 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:04:33.711068 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:34.529542 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 17:04:34.529796 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:04:34.529950 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 17:04:34.998055 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2021-01-19 17:04:34.998519 (Thread-1): finished collecting timing info
2021-01-19 17:04:34.999012 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:04:35.216007 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:04:35.492770 (Thread-1): 18:04:35 | 3 of 6 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 1.80s]
2021-01-19 17:04:35.492971 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:04:35.493205 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:04:35.493569 (Thread-1): 18:04:35 | 4 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 17:04:35.494002 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:04:35.494241 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:04:35.547269 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 17:04:35.547796 (Thread-1): finished collecting timing info
2021-01-19 17:04:35.548815 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:04:35.548949 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 17:04:35.549059 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:36.354609 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-01-19 17:04:36.354816 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:04:36.354953 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:04:36.559068 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 17:04:36.559444 (Thread-1): finished collecting timing info
2021-01-19 17:04:36.559794 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:04:36.778857 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 17:04:37.032339 (Thread-1): 18:04:37 | 4 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 1.54s]
2021-01-19 17:04:37.032661 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:04:37.032988 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:04:37.033465 (Thread-1): 18:04:37 | 5 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 17:04:37.034239 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:04:37.034542 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:04:37.045945 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 17:04:37.046427 (Thread-1): finished collecting timing info
2021-01-19 17:04:37.047246 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:04:37.047360 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 17:04:37.047477 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:37.834060 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-01-19 17:04:37.834275 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:04:37.834381 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:04:38.173687 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 17:04:38.174077 (Thread-1): finished collecting timing info
2021-01-19 17:04:38.174444 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:04:38.387632 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 17:04:38.642169 (Thread-1): 18:04:38 | 5 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 1.61s]
2021-01-19 17:04:38.642367 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:04:38.642602 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:04:38.643067 (Thread-1): 18:04:38 | 6 of 6 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 17:04:38.643670 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:04:38.643984 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:04:38.653900 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 17:04:38.654313 (Thread-1): finished collecting timing info
2021-01-19 17:04:38.655007 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:04:38.655095 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:04:38.655177 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:04:39.729707 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2021-01-19 17:04:39.729970 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:04:39.730092 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 17:04:40.016670 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2021-01-19 17:04:40.017150 (Thread-1): finished collecting timing info
2021-01-19 17:04:40.017615 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:04:40.232708 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:04:40.501430 (Thread-1): 18:04:40 | 6 of 6 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 1.86s]
2021-01-19 17:04:40.501609 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:04:40.502685 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:04:40.503000 (MainThread): 18:04:40 | 
2021-01-19 17:04:40.503182 (MainThread): 18:04:40 | Finished running 6 tests in 11.74s.
2021-01-19 17:04:40.503320 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:04:40.503455 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 17:04:40.522592 (MainThread): 
2021-01-19 17:04:40.522734 (MainThread): Completed successfully
2021-01-19 17:04:40.522832 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 17:04:40.522971 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113472e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198ef940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b5850>]}
2021-01-19 17:04:40.523128 (MainThread): Flushing usage events
2021-01-19 17:06:20.436716 (MainThread): Running with dbt=0.18.1
2021-01-19 17:06:20.514442 (MainThread): Loading KWallet
2021-01-19 17:06:20.515010 (MainThread): Loading SecretService
2021-01-19 17:06:20.515464 (MainThread): Loading Windows
2021-01-19 17:06:20.516034 (MainThread): Loading chainer
2021-01-19 17:06:20.516310 (MainThread): Loading macOS
2021-01-19 17:06:20.798033 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 17:06:20.799062 (MainThread): Tracking: tracking
2021-01-19 17:06:20.799334 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eecd760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0ddd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0dd2e0>]}
2021-01-19 17:06:20.836625 (MainThread): Got an acceptable cached parse result
2021-01-19 17:06:20.959677 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc88280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd4f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd4f670>]}
2021-01-19 17:06:20.959897 (MainThread): Flushing usage events
2021-01-19 17:06:21.583066 (MainThread): Encountered an error:
2021-01-19 17:06:21.583326 (MainThread): Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('relationships', None), ('to', "ref('my_first_dbt_model')"), ('field', 'id')] instead (3 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)
2021-01-19 17:06:21.589268 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 369, in _parse_generic_test
    builder = TestBuilder(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schema_test_builders.py", line 197, in __init__
    test_name, test_args = self.extract_test_args(test, column_name)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schema_test_builders.py", line 246, in extract_test_args
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  test definition dictionary must have exactly one key, got [('relationships', None), ('to', "ref('my_first_dbt_model')"), ('field', 'id')] instead (3 keys)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 399, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 118, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 78, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 65, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 748, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 349, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 204, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 177, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 133, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 558, in parse_file
    self.parse_tests(test_block)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 519, in parse_tests
    self.parse_column_tests(block, column)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 247, in parse_column_tests
    self.parse_test(block, test, column)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 515, in parse_test
    self.parse_node(block)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 461, in parse_node
    node = self._parse_generic_test(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 383, in _parse_generic_test
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('relationships', None), ('to', "ref('my_first_dbt_model')"), ('field', 'id')] instead (3 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)

2021-01-19 17:06:33.416619 (MainThread): Running with dbt=0.18.1
2021-01-19 17:06:33.502518 (MainThread): Loading KWallet
2021-01-19 17:06:33.503193 (MainThread): Loading SecretService
2021-01-19 17:06:33.503714 (MainThread): Loading Windows
2021-01-19 17:06:33.504407 (MainThread): Loading chainer
2021-01-19 17:06:33.504772 (MainThread): Loading macOS
2021-01-19 17:06:33.798599 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 17:06:33.799562 (MainThread): Tracking: tracking
2021-01-19 17:06:33.799836 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1229a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c332310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3320d0>]}
2021-01-19 17:06:33.839675 (MainThread): Got an acceptable cached parse result
2021-01-19 17:06:34.057443 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:06:34.148989 (MainThread): Found 6 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:06:34.150336 (MainThread): 
2021-01-19 17:06:34.150736 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:06:34.158216 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 17:06:34.170925 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 17:06:34.171039 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 17:06:34.171117 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 17:06:35.319381 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.15 seconds
2021-01-19 17:06:35.323931 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 17:06:35.602154 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:06:35.654251 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:06:35.654445 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:06:35.654570 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 17:06:36.675396 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.02 seconds
2021-01-19 17:06:36.681984 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:06:36.942990 (MainThread): Using snowflake connection "master".
2021-01-19 17:06:36.943178 (MainThread): On master: BEGIN
2021-01-19 17:06:36.943309 (MainThread): Opening a new connection, currently in state init
2021-01-19 17:06:37.931393 (MainThread): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 17:06:37.931594 (MainThread): On master: COMMIT
2021-01-19 17:06:37.931770 (MainThread): Using snowflake connection "master".
2021-01-19 17:06:37.931869 (MainThread): On master: COMMIT
2021-01-19 17:06:38.282169 (MainThread): SQL status: SUCCESS 1 in 0.35 seconds
2021-01-19 17:06:38.282404 (MainThread): On master: Close
2021-01-19 17:06:38.768420 (MainThread): 18:06:38 | Concurrency: 1 threads (target='dev')
2021-01-19 17:06:38.768650 (MainThread): 18:06:38 | 
2021-01-19 17:06:38.770699 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:06:38.772000 (Thread-1): 18:06:38 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 17:06:38.772320 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:06:38.772457 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 17:06:38.803868 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:06:38.805611 (Thread-1): finished collecting timing info
2021-01-19 17:06:38.840906 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:06:38.841963 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:06:38.842063 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 17:06:38.842155 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:06:39.708218 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2021-01-19 17:06:39.708481 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:06:39.708629 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
where id is not null


/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2021-01-19 17:06:41.237708 (Thread-1): SQL status: SUCCESS 1 in 1.53 seconds
2021-01-19 17:06:41.238924 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:06:41.239106 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:06:41.239210 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:06:41.409842 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 17:06:41.424435 (Thread-1): finished collecting timing info
2021-01-19 17:06:41.424762 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 17:06:41.684907 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f220d510-62ea-4bbc-8084-14fc1bd2856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1dec10>]}
2021-01-19 17:06:41.686254 (Thread-1): 18:06:41 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 2.91s]
2021-01-19 17:06:41.686431 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:06:41.686620 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:06:41.688255 (Thread-1): 18:06:41 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 17:06:41.688709 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:06:41.688852 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:06:41.695500 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:06:41.695998 (Thread-1): finished collecting timing info
2021-01-19 17:06:41.700843 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:06:41.702036 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:06:41.702158 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 17:06:41.702266 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:06:42.503264 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2021-01-19 17:06:42.503483 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:06:42.503606 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 17:06:45.671274 (Thread-1): SQL status: SUCCESS 1 in 3.17 seconds
2021-01-19 17:06:45.672425 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:06:45.672611 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:06:45.672736 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:06:45.821949 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 17:06:45.824289 (Thread-1): finished collecting timing info
2021-01-19 17:06:45.824571 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 17:06:46.324212 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f220d510-62ea-4bbc-8084-14fc1bd2856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce1db20>]}
2021-01-19 17:06:46.325671 (Thread-1): 18:06:46 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 4.64s]
2021-01-19 17:06:46.325834 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:06:46.325993 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 17:06:46.327667 (Thread-1): 18:06:46 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 17:06:46.328076 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:46.328208 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 17:06:46.345171 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 17:06:46.345674 (Thread-1): finished collecting timing info
2021-01-19 17:06:46.376815 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:46.376976 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 17:06:46.377081 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:06:48.404858 (Thread-1): SQL status: SUCCESS 1 in 2.03 seconds
2021-01-19 17:06:48.415934 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:48.416108 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 17:06:48.602327 (Thread-1): SQL status: SUCCESS 28 in 0.19 seconds
2021-01-19 17:06:48.607883 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:48.608011 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:06:48.830142 (Thread-1): SQL status: SUCCESS 28 in 0.22 seconds
2021-01-19 17:06:48.835433 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:48.835566 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:06:49.043556 (Thread-1): SQL status: SUCCESS 28 in 0.21 seconds
2021-01-19 17:06:49.072058 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 17:06:49.075289 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:49.075413 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 17:06:49.301890 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2021-01-19 17:06:49.302099 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:49.302218 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 17:06:50.019342 (Thread-1): SQL status: SUCCESS 0 in 0.72 seconds
2021-01-19 17:06:50.020778 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:06:50.020989 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:06:50.021109 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:06:50.260202 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 17:06:50.264224 (Thread-1): finished collecting timing info
2021-01-19 17:06:50.264523 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 17:06:50.650737 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f220d510-62ea-4bbc-8084-14fc1bd2856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d056be0>]}
2021-01-19 17:06:50.652046 (Thread-1): 18:06:50 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.32s]
2021-01-19 17:06:50.652219 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 17:06:50.652380 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 17:06:50.653883 (Thread-1): 18:06:50 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 17:06:50.654206 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:50.654333 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 17:06:50.663158 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:06:50.663709 (Thread-1): finished collecting timing info
2021-01-19 17:06:50.670489 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:50.670645 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 17:06:50.670763 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:06:52.993823 (Thread-1): SQL status: SUCCESS 1 in 2.32 seconds
2021-01-19 17:06:52.996548 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:52.996683 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 17:06:53.183392 (Thread-1): SQL status: SUCCESS 10 in 0.19 seconds
2021-01-19 17:06:53.186388 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:53.186501 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:06:53.365524 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-19 17:06:53.370781 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:53.370921 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:06:53.522194 (Thread-1): SQL status: SUCCESS 10 in 0.15 seconds
2021-01-19 17:06:53.524714 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:06:53.526148 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:53.526233 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 17:06:53.684245 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 17:06:53.684500 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:53.684658 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 17:06:54.533779 (Thread-1): SQL status: SUCCESS 165 in 0.85 seconds
2021-01-19 17:06:54.534871 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:06:54.535057 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:06:54.535161 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:06:54.852526 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 17:06:54.856388 (Thread-1): finished collecting timing info
2021-01-19 17:06:54.856676 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 17:06:55.130893 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f220d510-62ea-4bbc-8084-14fc1bd2856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cec6580>]}
2021-01-19 17:06:55.132358 (Thread-1): 18:06:55 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 165 in 4.48s]
2021-01-19 17:06:55.132532 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 17:06:55.132692 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:06:55.134307 (Thread-1): 18:06:55 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 17:06:55.134658 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:06:55.134790 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:06:55.142672 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:06:55.143166 (Thread-1): finished collecting timing info
2021-01-19 17:06:55.148262 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:06:55.149532 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:06:55.149652 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 17:06:55.149757 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:06:56.248922 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 17:06:56.249147 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:06:56.249272 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 17:06:57.903771 (Thread-1): SQL status: SUCCESS 1 in 1.65 seconds
2021-01-19 17:06:57.905061 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:06:57.905269 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:06:57.905402 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:06:58.050401 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-01-19 17:06:58.052825 (Thread-1): finished collecting timing info
2021-01-19 17:06:58.053119 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 17:06:58.310169 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f220d510-62ea-4bbc-8084-14fc1bd2856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0f8730>]}
2021-01-19 17:06:58.311539 (Thread-1): 18:06:58 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.18s]
2021-01-19 17:06:58.311710 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:06:58.311871 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:06:58.313988 (Thread-1): 18:06:58 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 17:06:58.314389 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:06:58.314546 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 17:06:58.324201 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:06:58.324676 (Thread-1): finished collecting timing info
2021-01-19 17:06:58.329761 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:06:58.330640 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:06:58.330756 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 17:06:58.330861 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:06:59.341162 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-01-19 17:06:59.341387 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:06:59.341515 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 17:07:00.310914 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-01-19 17:07:00.312502 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:07:00.312787 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:07:00.313132 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:07:00.460409 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 17:07:00.462766 (Thread-1): finished collecting timing info
2021-01-19 17:07:00.463044 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 17:07:00.717026 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f220d510-62ea-4bbc-8084-14fc1bd2856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4523d0>]}
2021-01-19 17:07:00.718364 (Thread-1): 18:07:00 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.40s]
2021-01-19 17:07:00.718534 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:07:00.719973 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:07:00.720212 (MainThread): Using snowflake connection "master".
2021-01-19 17:07:00.720318 (MainThread): On master: BEGIN
2021-01-19 17:07:00.720424 (MainThread): Opening a new connection, currently in state closed
2021-01-19 17:07:01.541896 (MainThread): SQL status: SUCCESS 1 in 0.82 seconds
2021-01-19 17:07:01.542167 (MainThread): On master: COMMIT
2021-01-19 17:07:01.542415 (MainThread): Using snowflake connection "master".
2021-01-19 17:07:01.542560 (MainThread): On master: COMMIT
2021-01-19 17:07:01.794212 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-19 17:07:01.794503 (MainThread): On master: Close
2021-01-19 17:07:02.056889 (MainThread): 18:07:02 | 
2021-01-19 17:07:02.057108 (MainThread): 18:07:02 | Finished running 4 table models, 2 incremental models in 27.91s.
2021-01-19 17:07:02.057271 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:07:02.057425 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 17:07:02.078951 (MainThread): 
2021-01-19 17:07:02.079139 (MainThread): Completed successfully
2021-01-19 17:07:02.079275 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 17:07:02.079599 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d027af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0298b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d029af0>]}
2021-01-19 17:07:02.079864 (MainThread): Flushing usage events
2021-01-19 17:07:12.114226 (MainThread): Running with dbt=0.18.1
2021-01-19 17:07:12.193430 (MainThread): Loading KWallet
2021-01-19 17:07:12.194006 (MainThread): Loading SecretService
2021-01-19 17:07:12.194473 (MainThread): Loading Windows
2021-01-19 17:07:12.195058 (MainThread): Loading chainer
2021-01-19 17:07:12.195367 (MainThread): Loading macOS
2021-01-19 17:07:12.481340 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 17:07:12.482337 (MainThread): Tracking: tracking
2021-01-19 17:07:12.482672 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5227f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d447ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6550a0>]}
2021-01-19 17:07:12.522023 (MainThread): Got an acceptable cached parse result
2021-01-19 17:07:12.635542 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:07:12.738468 (MainThread): Found 6 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:07:12.740563 (MainThread): 
2021-01-19 17:07:12.741005 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:07:12.757213 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:07:12.769755 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:07:12.769879 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:07:12.769956 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 17:07:13.914964 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.14 seconds
2021-01-19 17:07:13.926060 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:07:14.186556 (MainThread): 18:07:14 | Concurrency: 1 threads (target='dev')
2021-01-19 17:07:14.186768 (MainThread): 18:07:14 | 
2021-01-19 17:07:14.189015 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:07:14.189217 (Thread-1): 18:07:14 | 1 of 7 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-01-19 17:07:14.189526 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:07:14.189669 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:07:14.229139 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 17:07:14.229609 (Thread-1): finished collecting timing info
2021-01-19 17:07:14.230224 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:07:14.230323 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 17:07:14.230415 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:15.328970 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 17:07:15.329248 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:07:15.329356 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 17:07:15.620631 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2021-01-19 17:07:15.621112 (Thread-1): finished collecting timing info
2021-01-19 17:07:15.621509 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:07:15.838947 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 17:07:16.094869 (Thread-1): 18:07:16 | 1 of 7 PASS not_null_my_first_dbt_model_id........................... [PASS in 1.91s]
2021-01-19 17:07:16.095068 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:07:16.095267 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:07:16.095687 (Thread-1): 18:07:16 | 2 of 7 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 17:07:16.096282 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:07:16.096450 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:07:16.107415 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 17:07:16.107884 (Thread-1): finished collecting timing info
2021-01-19 17:07:16.108545 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:07:16.108654 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 17:07:16.108755 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:16.989181 (Thread-1): SQL status: SUCCESS 1 in 0.88 seconds
2021-01-19 17:07:16.989340 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:07:16.989421 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 17:07:17.630412 (Thread-1): SQL status: SUCCESS 1 in 0.64 seconds
2021-01-19 17:07:17.630737 (Thread-1): finished collecting timing info
2021-01-19 17:07:17.631041 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:07:17.926172 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 17:07:18.242047 (Thread-1): 18:07:18 | 2 of 7 PASS not_null_my_second_dbt_model_id.......................... [PASS in 2.15s]
2021-01-19 17:07:18.242270 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:07:18.242504 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:07:18.242849 (Thread-1): 18:07:18 | 3 of 7 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 17:07:18.243310 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:07:18.243477 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:07:18.255182 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 17:07:18.255669 (Thread-1): finished collecting timing info
2021-01-19 17:07:18.256347 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:07:18.256451 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:07:18.256548 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:19.113242 (Thread-1): SQL status: SUCCESS 1 in 0.86 seconds
2021-01-19 17:07:19.113495 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:07:19.113640 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 17:07:19.661641 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2021-01-19 17:07:19.661966 (Thread-1): finished collecting timing info
2021-01-19 17:07:19.662314 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:07:19.873666 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:07:20.138520 (Thread-1): 18:07:20 | 3 of 7 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 1.90s]
2021-01-19 17:07:20.138956 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:07:20.139212 (Thread-1): Began running node test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:07:20.139637 (Thread-1): 18:07:20 | 4 of 7 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-01-19 17:07:20.140013 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:07:20.140135 (Thread-1): Compiling test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:07:20.164147 (Thread-1): Writing injected SQL for node "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-01-19 17:07:20.164631 (Thread-1): finished collecting timing info
2021-01-19 17:07:20.165601 (Thread-1): Using snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:07:20.165714 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: BEGIN
2021-01-19 17:07:20.165812 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:21.171758 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-01-19 17:07:21.171943 (Thread-1): Using snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:07:21.172045 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from analytics.dbt.my_second_dbt_model
) as child
left join (
    select id as id from analytics.dbt.first_model
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null
2021-01-19 17:07:21.745168 (Thread-1): SQL status: SUCCESS 1 in 0.57 seconds
2021-01-19 17:07:21.745710 (Thread-1): finished collecting timing info
2021-01-19 17:07:21.746276 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: ROLLBACK
2021-01-19 17:07:22.033046 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: Close
2021-01-19 17:07:22.296856 (Thread-1): 18:07:22 | 4 of 7 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 2.16s]
2021-01-19 17:07:22.297081 (Thread-1): Finished running node test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:07:22.297332 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:07:22.297647 (Thread-1): 18:07:22 | 5 of 7 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 17:07:22.298132 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:07:22.298294 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:07:22.313939 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 17:07:22.314421 (Thread-1): finished collecting timing info
2021-01-19 17:07:22.315242 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:07:22.315361 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 17:07:22.315463 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:23.272434 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2021-01-19 17:07:23.272692 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:07:23.272847 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:07:23.773760 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-01-19 17:07:23.774214 (Thread-1): finished collecting timing info
2021-01-19 17:07:23.774649 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:07:24.000121 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 17:07:24.284129 (Thread-1): 18:07:24 | 5 of 7 PASS unique_my_first_dbt_model_id............................. [PASS in 1.99s]
2021-01-19 17:07:24.284331 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:07:24.284519 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:07:24.284951 (Thread-1): 18:07:24 | 6 of 7 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 17:07:24.285360 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:07:24.285509 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:07:24.296332 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 17:07:24.296829 (Thread-1): finished collecting timing info
2021-01-19 17:07:24.297643 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:07:24.297752 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 17:07:24.297854 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:25.297667 (Thread-1): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 17:07:25.297856 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:07:25.297960 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:07:25.711836 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2021-01-19 17:07:25.712305 (Thread-1): finished collecting timing info
2021-01-19 17:07:25.712837 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:07:25.945764 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 17:07:26.198990 (Thread-1): 18:07:26 | 6 of 7 PASS unique_my_second_dbt_model_id............................ [PASS in 1.91s]
2021-01-19 17:07:26.199446 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:07:26.199822 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:07:26.200203 (Thread-1): 18:07:26 | 7 of 7 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 17:07:26.200588 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:07:26.200794 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:07:26.212916 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 17:07:26.213459 (Thread-1): finished collecting timing info
2021-01-19 17:07:26.214364 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:07:26.214485 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:07:26.214595 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:07:27.017530 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2021-01-19 17:07:27.017755 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:07:27.017892 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 17:07:27.361172 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 17:07:27.361577 (Thread-1): finished collecting timing info
2021-01-19 17:07:27.361959 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:07:27.581627 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:07:27.848301 (Thread-1): 18:07:27 | 7 of 7 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 1.65s]
2021-01-19 17:07:27.848561 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:07:27.849831 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:07:27.850206 (MainThread): 18:07:27 | 
2021-01-19 17:07:27.850398 (MainThread): 18:07:27 | Finished running 7 tests in 15.11s.
2021-01-19 17:07:27.850560 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:07:27.850657 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 17:07:27.875062 (MainThread): 
2021-01-19 17:07:27.875244 (MainThread): Completed successfully
2021-01-19 17:07:27.875381 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-01-19 17:07:27.875571 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7c4d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7c49a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7aac10>]}
2021-01-19 17:07:27.875783 (MainThread): Flushing usage events
2021-01-19 17:11:39.886376 (MainThread): Running with dbt=0.18.1
2021-01-19 17:11:39.959603 (MainThread): Loading KWallet
2021-01-19 17:11:39.960129 (MainThread): Loading SecretService
2021-01-19 17:11:39.960519 (MainThread): Loading Windows
2021-01-19 17:11:39.961063 (MainThread): Loading chainer
2021-01-19 17:11:39.961316 (MainThread): Loading macOS
2021-01-19 17:11:40.246514 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 17:11:40.247319 (MainThread): Tracking: tracking
2021-01-19 17:11:40.247555 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba28c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc38d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc38310>]}
2021-01-19 17:11:40.283649 (MainThread): Got an acceptable cached parse result
2021-01-19 17:11:40.320660 (MainThread): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:11:40.351226 (MainThread): Acquiring new snowflake connection "test.dbt_learn.assert_under_10_percent_null".
2021-01-19 17:11:40.521083 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:11:40.610948 (MainThread): Found 6 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:11:40.613114 (MainThread): 
2021-01-19 17:11:40.613530 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:11:40.620798 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 17:11:40.633666 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 17:11:40.633787 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 17:11:40.633865 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 17:11:41.748545 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.11 seconds
2021-01-19 17:11:41.753490 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 17:11:42.105964 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:11:42.114424 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:11:42.114585 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:11:42.114702 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 17:11:42.918732 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 0.80 seconds
2021-01-19 17:11:42.925536 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:11:43.212370 (MainThread): Using snowflake connection "master".
2021-01-19 17:11:43.212541 (MainThread): On master: BEGIN
2021-01-19 17:11:43.212654 (MainThread): Opening a new connection, currently in state init
2021-01-19 17:11:43.992322 (MainThread): SQL status: SUCCESS 1 in 0.78 seconds
2021-01-19 17:11:43.992600 (MainThread): On master: COMMIT
2021-01-19 17:11:43.992867 (MainThread): Using snowflake connection "master".
2021-01-19 17:11:43.993004 (MainThread): On master: COMMIT
2021-01-19 17:11:44.229803 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-19 17:11:44.230083 (MainThread): On master: Close
2021-01-19 17:11:44.594070 (MainThread): 18:11:44 | Concurrency: 1 threads (target='dev')
2021-01-19 17:11:44.594321 (MainThread): 18:11:44 | 
2021-01-19 17:11:44.596544 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:11:44.597840 (Thread-1): 18:11:44 | 1 of 6 START table model dbt.first_model............................. [RUN]
2021-01-19 17:11:44.598238 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:11:44.598391 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 17:11:44.621590 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:11:44.622112 (Thread-1): finished collecting timing info
2021-01-19 17:11:44.657149 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:11:44.658183 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:11:44.658285 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 17:11:44.658379 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:11:46.465346 (Thread-1): SQL status: SUCCESS 1 in 1.81 seconds
2021-01-19 17:11:46.465604 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:11:46.465754 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
      );
2021-01-19 17:11:48.240735 (Thread-1): SQL status: SUCCESS 1 in 1.77 seconds
2021-01-19 17:11:48.242270 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:11:48.242485 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:11:48.242607 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:11:48.386629 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-01-19 17:11:48.401123 (Thread-1): finished collecting timing info
2021-01-19 17:11:48.401454 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 17:11:48.664805 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30e74e9-58d0-4eb4-a554-ac20e1c9af14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cafa7c0>]}
2021-01-19 17:11:48.666363 (Thread-1): 18:11:48 | 1 of 6 OK created table model dbt.first_model........................ [SUCCESS 1 in 4.07s]
2021-01-19 17:11:48.666554 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:11:48.666740 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:11:48.668547 (Thread-1): 18:11:48 | 2 of 6 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 17:11:48.668996 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:11:48.669134 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:11:48.676666 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:11:48.677167 (Thread-1): finished collecting timing info
2021-01-19 17:11:48.682001 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:11:48.683127 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:11:48.683243 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 17:11:48.683352 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:11:49.787732 (Thread-1): SQL status: SUCCESS 1 in 1.10 seconds
2021-01-19 17:11:49.787963 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:11:49.788086 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 17:11:51.630263 (Thread-1): SQL status: SUCCESS 1 in 1.84 seconds
2021-01-19 17:11:51.631845 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:11:51.632114 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:11:51.632235 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:11:51.784313 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 17:11:51.787058 (Thread-1): finished collecting timing info
2021-01-19 17:11:51.787425 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 17:11:52.049073 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30e74e9-58d0-4eb4-a554-ac20e1c9af14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7ebdf0>]}
2021-01-19 17:11:52.050396 (Thread-1): 18:11:52 | 2 of 6 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.38s]
2021-01-19 17:11:52.050561 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:11:52.050742 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 17:11:52.052291 (Thread-1): 18:11:52 | 3 of 6 START incremental model dbt.dates............................. [RUN]
2021-01-19 17:11:52.052649 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:52.052802 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 17:11:52.069642 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 17:11:52.070147 (Thread-1): finished collecting timing info
2021-01-19 17:11:52.101878 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:52.102051 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 17:11:52.102162 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:11:54.067455 (Thread-1): SQL status: SUCCESS 1 in 1.97 seconds
2021-01-19 17:11:54.077240 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:54.077367 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 17:11:54.253681 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-19 17:11:54.260107 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:54.260269 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:11:54.427552 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 17:11:54.433128 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:54.433258 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:11:54.590864 (Thread-1): SQL status: SUCCESS 28 in 0.16 seconds
2021-01-19 17:11:54.619320 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 17:11:54.643421 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:54.643555 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 17:11:54.813836 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 17:11:54.814017 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:54.814122 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 17:11:55.557645 (Thread-1): SQL status: SUCCESS 0 in 0.74 seconds
2021-01-19 17:11:55.558997 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:11:55.559227 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:11:55.559353 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:11:55.776489 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 17:11:55.781102 (Thread-1): finished collecting timing info
2021-01-19 17:11:55.781431 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 17:11:56.038098 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30e74e9-58d0-4eb4-a554-ac20e1c9af14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccec850>]}
2021-01-19 17:11:56.039596 (Thread-1): 18:11:56 | 3 of 6 OK created incremental model dbt.dates........................ [SUCCESS 0 in 3.99s]
2021-01-19 17:11:56.039769 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 17:11:56.039930 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 17:11:56.041934 (Thread-1): 18:11:56 | 4 of 6 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 17:11:56.042309 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:56.042440 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 17:11:56.051678 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:11:56.052189 (Thread-1): finished collecting timing info
2021-01-19 17:11:56.059048 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:56.059225 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 17:11:56.059341 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:11:57.916645 (Thread-1): SQL status: SUCCESS 1 in 1.86 seconds
2021-01-19 17:11:57.920040 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:57.920186 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 17:11:58.115090 (Thread-1): SQL status: SUCCESS 10 in 0.19 seconds
2021-01-19 17:11:58.119703 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:58.119834 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:11:58.714730 (Thread-1): SQL status: SUCCESS 10 in 0.59 seconds
2021-01-19 17:11:58.718995 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:58.719123 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:11:58.877052 (Thread-1): SQL status: SUCCESS 10 in 0.16 seconds
2021-01-19 17:11:58.880307 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:11:58.882180 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:58.882292 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 17:11:59.087474 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 17:11:59.087662 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:11:59.087766 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 17:12:00.545500 (Thread-1): SQL status: SUCCESS 305 in 1.46 seconds
2021-01-19 17:12:00.547148 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:12:00.547429 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:12:00.547553 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:12:00.886585 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 17:12:00.890967 (Thread-1): finished collecting timing info
2021-01-19 17:12:00.891302 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 17:12:01.149727 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30e74e9-58d0-4eb4-a554-ac20e1c9af14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c94fb80>]}
2021-01-19 17:12:01.150819 (Thread-1): 18:12:01 | 4 of 6 OK created incremental model dbt.incremental_time............. [SUCCESS 305 in 5.11s]
2021-01-19 17:12:01.150968 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 17:12:01.151118 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:12:01.152869 (Thread-1): 18:12:01 | 5 of 6 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 17:12:01.153190 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:12:01.153379 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:12:01.161441 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:12:01.161923 (Thread-1): finished collecting timing info
2021-01-19 17:12:01.166891 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:12:01.168066 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:12:01.168178 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 17:12:01.168285 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:02.278084 (Thread-1): SQL status: SUCCESS 1 in 1.11 seconds
2021-01-19 17:12:02.278290 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:12:02.278421 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 17:12:04.960589 (Thread-1): SQL status: SUCCESS 1 in 2.68 seconds
2021-01-19 17:12:04.961973 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:12:04.962182 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:12:04.962305 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:12:05.112093 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 17:12:05.114047 (Thread-1): finished collecting timing info
2021-01-19 17:12:05.114276 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 17:12:05.384066 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30e74e9-58d0-4eb4-a554-ac20e1c9af14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8a8d00>]}
2021-01-19 17:12:05.385358 (Thread-1): 18:12:05 | 5 of 6 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 4.23s]
2021-01-19 17:12:05.385516 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:12:05.385669 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:12:05.387646 (Thread-1): 18:12:05 | 6 of 6 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 17:12:05.388027 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:12:05.388318 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 17:12:05.397809 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:12:05.398320 (Thread-1): finished collecting timing info
2021-01-19 17:12:05.403246 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:12:05.404095 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:12:05.404207 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 17:12:05.404320 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:06.700254 (Thread-1): SQL status: SUCCESS 1 in 1.30 seconds
2021-01-19 17:12:06.700446 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:12:06.700547 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 17:12:07.713831 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-01-19 17:12:07.715238 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:12:07.715453 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:12:07.715572 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:12:07.883121 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2021-01-19 17:12:07.886313 (Thread-1): finished collecting timing info
2021-01-19 17:12:07.886669 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 17:12:08.170598 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30e74e9-58d0-4eb4-a554-ac20e1c9af14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c89e250>]}
2021-01-19 17:12:08.172157 (Thread-1): 18:12:08 | 6 of 6 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.78s]
2021-01-19 17:12:08.172336 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:12:08.173795 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:12:08.174043 (MainThread): Using snowflake connection "master".
2021-01-19 17:12:08.174154 (MainThread): On master: BEGIN
2021-01-19 17:12:08.174261 (MainThread): Opening a new connection, currently in state closed
2021-01-19 17:12:09.161662 (MainThread): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 17:12:09.161894 (MainThread): On master: COMMIT
2021-01-19 17:12:09.162094 (MainThread): Using snowflake connection "master".
2021-01-19 17:12:09.162212 (MainThread): On master: COMMIT
2021-01-19 17:12:09.425118 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-19 17:12:09.425406 (MainThread): On master: Close
2021-01-19 17:12:09.702711 (MainThread): 18:12:09 | 
2021-01-19 17:12:09.702942 (MainThread): 18:12:09 | Finished running 4 table models, 2 incremental models in 29.09s.
2021-01-19 17:12:09.703093 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:12:09.703217 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 17:12:09.725623 (MainThread): 
2021-01-19 17:12:09.725811 (MainThread): Completed successfully
2021-01-19 17:12:09.726001 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-01-19 17:12:09.726196 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c73a700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c73abe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c73a8b0>]}
2021-01-19 17:12:09.726403 (MainThread): Flushing usage events
2021-01-19 17:12:16.647977 (MainThread): Running with dbt=0.18.1
2021-01-19 17:12:16.721867 (MainThread): Loading KWallet
2021-01-19 17:12:16.722658 (MainThread): Loading SecretService
2021-01-19 17:12:16.723069 (MainThread): Loading Windows
2021-01-19 17:12:16.723637 (MainThread): Loading chainer
2021-01-19 17:12:16.724003 (MainThread): Loading macOS
2021-01-19 17:12:17.002202 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 17:12:17.002970 (MainThread): Tracking: tracking
2021-01-19 17:12:17.003211 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10952eb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10973d070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10973de20>]}
2021-01-19 17:12:17.039592 (MainThread): Got an acceptable cached parse result
2021-01-19 17:12:17.122018 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:12:17.217802 (MainThread): Found 6 models, 7 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:12:17.219977 (MainThread): 
2021-01-19 17:12:17.220783 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:12:17.236337 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:12:17.249367 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:12:17.249494 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:12:17.249575 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 17:12:18.401209 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.15 seconds
2021-01-19 17:12:18.412603 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:12:18.791899 (MainThread): 18:12:18 | Concurrency: 1 threads (target='dev')
2021-01-19 17:12:18.792104 (MainThread): 18:12:18 | 
2021-01-19 17:12:18.794293 (Thread-1): Began running node test.dbt_learn.assert_under_10_percent_null
2021-01-19 17:12:18.794497 (Thread-1): 18:12:18 | 1 of 7 START test assert_under_10_percent_null....................... [RUN]
2021-01-19 17:12:18.794806 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.assert_under_10_percent_null".
2021-01-19 17:12:18.794950 (Thread-1): Compiling test.dbt_learn.assert_under_10_percent_null
2021-01-19 17:12:18.824465 (Thread-1): Writing injected SQL for node "test.dbt_learn.assert_under_10_percent_null"
2021-01-19 17:12:18.825015 (Thread-1): finished collecting timing info
2021-01-19 17:12:18.825823 (Thread-1): Using snowflake connection "test.dbt_learn.assert_under_10_percent_null".
2021-01-19 17:12:18.825932 (Thread-1): On test.dbt_learn.assert_under_10_percent_null: BEGIN
2021-01-19 17:12:18.826033 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:19.848487 (Thread-1): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-19 17:12:19.848702 (Thread-1): Using snowflake connection "test.dbt_learn.assert_under_10_percent_null".
2021-01-19 17:12:19.848825 (Thread-1): On test.dbt_learn.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.assert_under_10_percent_null"} */

with dbt__CTE__INTERNAL_test as (
SELECT 
	sum( case when id is null then 1 else 0 )/ count(*) as total_nulls

	FROM analytics.dbt.first_model

	HAVING total_nulls <= .1
)select count(*) from dbt__CTE__INTERNAL_test
2021-01-19 17:12:20.091844 (Thread-1): Snowflake query id: 0199b7c8-06a1-7e84-0000-003989036845
2021-01-19 17:12:20.092039 (Thread-1): Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 3 at position 41 unexpected ')'.
2021-01-19 17:12:20.092202 (Thread-1): finished collecting timing info
2021-01-19 17:12:20.092562 (Thread-1): On test.dbt_learn.assert_under_10_percent_null: ROLLBACK
2021-01-19 17:12:20.311752 (Thread-1): On test.dbt_learn.assert_under_10_percent_null: Close
2021-01-19 17:12:20.597621 (Thread-1): Database Error in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)
  001003 (42000): SQL compilation error:
  syntax error line 3 at position 41 unexpected ')'.
  compiled SQL at target/compiled/dbt_learn/tests/assert_under_10_percent_null.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 161, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 78, in add_query
    cursor.execute(sql, bindings)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 594, in execute
    Error.errorhandler_wrapper(self.connection, self,
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 123, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/snowflake/connector/errors.py", line 83, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 001003 (42000): SQL compilation error:
syntax error line 3 at position 41 unexpected ')'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 123, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 309, in add_query
    connection, cursor = super().add_query(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 86, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.6_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/snowflake/connections.py", line 178, in exception_handler
    raise DatabaseException(msg)
dbt.exceptions.DatabaseException: Database Error in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)
  001003 (42000): SQL compilation error:
  syntax error line 3 at position 41 unexpected ')'.
  compiled SQL at target/compiled/dbt_learn/tests/assert_under_10_percent_null.sql
2021-01-19 17:12:20.608569 (Thread-1): 18:12:20 | 1 of 7 ERROR assert_under_10_percent_null............................ [ERROR in 1.81s]
2021-01-19 17:12:20.608759 (Thread-1): Finished running node test.dbt_learn.assert_under_10_percent_null
2021-01-19 17:12:20.608996 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:12:20.609462 (Thread-1): 18:12:20 | 2 of 7 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-01-19 17:12:20.609970 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:12:20.610149 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:12:20.635325 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 17:12:20.635844 (Thread-1): finished collecting timing info
2021-01-19 17:12:20.636524 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:12:20.636643 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 17:12:20.636751 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:21.645119 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2021-01-19 17:12:21.645373 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:12:21.645526 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 17:12:21.943316 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 17:12:21.943786 (Thread-1): finished collecting timing info
2021-01-19 17:12:21.944225 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:12:22.178872 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 17:12:22.430300 (Thread-1): 18:12:22 | 2 of 7 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.82s]
2021-01-19 17:12:22.430535 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:12:22.430789 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:12:22.431390 (Thread-1): 18:12:22 | 3 of 7 START test not_null_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 17:12:22.431972 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:12:22.432172 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:12:22.443049 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 17:12:22.443564 (Thread-1): finished collecting timing info
2021-01-19 17:12:22.444259 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:12:22.444371 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:12:22.444484 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:23.692686 (Thread-1): SQL status: SUCCESS 1 in 1.25 seconds
2021-01-19 17:12:23.692944 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:12:23.693096 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 17:12:24.481359 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-01-19 17:12:24.481827 (Thread-1): finished collecting timing info
2021-01-19 17:12:24.482271 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:12:24.855222 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:12:25.166065 (Thread-1): 18:12:25 | 3 of 7 PASS not_null_snowflake_customer_purchases_c_custkey.......... [PASS in 2.73s]
2021-01-19 17:12:25.166300 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:12:25.166539 (Thread-1): Began running node test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:12:25.167415 (Thread-1): 18:12:25 | 4 of 7 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-01-19 17:12:25.167931 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:12:25.168101 (Thread-1): Compiling test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:12:25.186528 (Thread-1): Writing injected SQL for node "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-01-19 17:12:25.187083 (Thread-1): finished collecting timing info
2021-01-19 17:12:25.188033 (Thread-1): Using snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:12:25.188147 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: BEGIN
2021-01-19 17:12:25.188259 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:26.239842 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-01-19 17:12:26.240038 (Thread-1): Using snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:12:26.240143 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from analytics.dbt.my_second_dbt_model
) as child
left join (
    select id as id from analytics.dbt.first_model
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null
2021-01-19 17:12:26.598335 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-01-19 17:12:26.598799 (Thread-1): finished collecting timing info
2021-01-19 17:12:26.599242 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: ROLLBACK
2021-01-19 17:12:27.291462 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: Close
2021-01-19 17:12:27.556750 (Thread-1): 18:12:27 | 4 of 7 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 2.39s]
2021-01-19 17:12:27.556994 (Thread-1): Finished running node test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:12:27.557228 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:12:27.557497 (Thread-1): 18:12:27 | 5 of 7 START test unique_my_first_dbt_model_id....................... [RUN]
2021-01-19 17:12:27.558036 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:12:27.558289 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:12:27.573531 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 17:12:27.574026 (Thread-1): finished collecting timing info
2021-01-19 17:12:27.574822 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:12:27.574933 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 17:12:27.575038 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:28.916433 (Thread-1): SQL status: SUCCESS 1 in 1.34 seconds
2021-01-19 17:12:28.916686 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:12:28.916836 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:12:29.245759 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2021-01-19 17:12:29.246100 (Thread-1): finished collecting timing info
2021-01-19 17:12:29.246416 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:12:29.497750 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 17:12:29.882601 (Thread-1): 18:12:29 | 5 of 7 PASS unique_my_first_dbt_model_id............................. [PASS in 2.32s]
2021-01-19 17:12:29.882831 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:12:29.883019 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:12:29.883203 (Thread-1): 18:12:29 | 6 of 7 START test unique_my_second_dbt_model_id...................... [RUN]
2021-01-19 17:12:29.883787 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:12:29.883999 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:12:29.895860 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 17:12:29.896364 (Thread-1): finished collecting timing info
2021-01-19 17:12:29.897163 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:12:29.897274 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 17:12:29.897380 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:31.370496 (Thread-1): SQL status: SUCCESS 1 in 1.47 seconds
2021-01-19 17:12:31.370769 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:12:31.371018 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:12:31.666265 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 17:12:31.666713 (Thread-1): finished collecting timing info
2021-01-19 17:12:31.667141 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:12:31.890001 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 17:12:32.143616 (Thread-1): 18:12:32 | 6 of 7 PASS unique_my_second_dbt_model_id............................ [PASS in 2.26s]
2021-01-19 17:12:32.143816 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:12:32.144029 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:12:32.144523 (Thread-1): 18:12:32 | 7 of 7 START test unique_snowflake_customer_purchases_c_custkey...... [RUN]
2021-01-19 17:12:32.144966 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:12:32.145147 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:12:32.156229 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 17:12:32.156742 (Thread-1): finished collecting timing info
2021-01-19 17:12:32.157614 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:12:32.157722 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:12:32.157822 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:12:33.195681 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 17:12:33.195889 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:12:33.196005 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 17:12:33.538388 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 17:12:33.538717 (Thread-1): finished collecting timing info
2021-01-19 17:12:33.539033 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:12:33.770562 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:12:34.180270 (Thread-1): 18:12:34 | 7 of 7 PASS unique_snowflake_customer_purchases_c_custkey............ [PASS in 2.04s]
2021-01-19 17:12:34.180472 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:12:34.181899 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:12:34.182363 (MainThread): 18:12:34 | 
2021-01-19 17:12:34.182512 (MainThread): 18:12:34 | Finished running 7 tests in 16.96s.
2021-01-19 17:12:34.182632 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:12:34.182719 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 17:12:34.206443 (MainThread): 
2021-01-19 17:12:34.206621 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 17:12:34.206744 (MainThread): 
2021-01-19 17:12:34.206861 (MainThread): Database Error in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)
2021-01-19 17:12:34.206968 (MainThread):   001003 (42000): SQL compilation error:
2021-01-19 17:12:34.207065 (MainThread):   syntax error line 3 at position 41 unexpected ')'.
2021-01-19 17:12:34.207160 (MainThread):   compiled SQL at target/compiled/dbt_learn/tests/assert_under_10_percent_null.sql
2021-01-19 17:12:34.207274 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-01-19 17:12:34.207456 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4470a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a69cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a69cf40>]}
2021-01-19 17:12:34.207666 (MainThread): Flushing usage events
2021-01-19 17:20:36.005444 (MainThread): Running with dbt=0.18.1
2021-01-19 17:20:36.073562 (MainThread): Loading KWallet
2021-01-19 17:20:36.073994 (MainThread): Loading SecretService
2021-01-19 17:20:36.074346 (MainThread): Loading Windows
2021-01-19 17:20:36.074814 (MainThread): Loading chainer
2021-01-19 17:20:36.075044 (MainThread): Loading macOS
2021-01-19 17:20:36.326745 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 17:20:36.327756 (MainThread): Tracking: tracking
2021-01-19 17:20:36.328004 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a82820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c92310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c920d0>]}
2021-01-19 17:20:36.361722 (MainThread): Got an acceptable cached parse result
2021-01-19 17:20:36.396320 (MainThread): Acquiring new snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-19 17:20:36.548878 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10783e4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10792bc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079205e0>]}
2021-01-19 17:20:36.549091 (MainThread): Flushing usage events
2021-01-19 17:20:37.158007 (MainThread): Connection 'model.dbt_learn.playing_with_tests' was properly closed.
2021-01-19 17:20:37.158252 (MainThread): Encountered an error:
2021-01-19 17:20:37.158441 (MainThread): Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['BUILDING', 'AUTOMOBILE', 'MACHINERY', 'HOUSEHOLD', 'FURNITURE'])] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)
2021-01-19 17:20:37.160585 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 369, in _parse_generic_test
    builder = TestBuilder(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schema_test_builders.py", line 197, in __init__
    test_name, test_args = self.extract_test_args(test, column_name)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schema_test_builders.py", line 246, in extract_test_args
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['BUILDING', 'AUTOMOBILE', 'MACHINERY', 'HOUSEHOLD', 'FURNITURE'])] instead (2 keys)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 399, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 118, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 78, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 65, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 748, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 349, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 204, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 177, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 133, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 558, in parse_file
    self.parse_tests(test_block)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 519, in parse_tests
    self.parse_column_tests(block, column)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 247, in parse_column_tests
    self.parse_test(block, test, column)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 515, in parse_test
    self.parse_node(block)
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 461, in parse_node
    node = self._parse_generic_test(
  File "/usr/local/Cellar/dbt/0.18.1_1/libexec/lib/python3.8/site-packages/dbt/parser/schemas.py", line 383, in _parse_generic_test
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['BUILDING', 'AUTOMOBILE', 'MACHINERY', 'HOUSEHOLD', 'FURNITURE'])] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)

2021-01-19 17:21:15.955160 (MainThread): Running with dbt=0.18.1
2021-01-19 17:21:16.019292 (MainThread): Loading KWallet
2021-01-19 17:21:16.019763 (MainThread): Loading SecretService
2021-01-19 17:21:16.020264 (MainThread): Loading Windows
2021-01-19 17:21:16.020779 (MainThread): Loading chainer
2021-01-19 17:21:16.021035 (MainThread): Loading macOS
2021-01-19 17:21:16.280206 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-19 17:21:16.281052 (MainThread): Tracking: tracking
2021-01-19 17:21:16.281299 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11144f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11165e040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11165ed90>]}
2021-01-19 17:21:16.314594 (MainThread): Got an acceptable cached parse result
2021-01-19 17:21:16.350365 (MainThread): Acquiring new snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-19 17:21:16.573510 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:21:16.668255 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:21:16.670489 (MainThread): 
2021-01-19 17:21:16.670930 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:21:16.679512 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-19 17:21:16.691451 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-19 17:21:16.691574 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-19 17:21:16.691650 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-19 17:21:17.941972 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.25 seconds
2021-01-19 17:21:17.946535 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-19 17:21:18.291853 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:21:18.299020 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:21:18.299234 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:21:18.299336 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-19 17:21:19.734100 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 6 in 1.43 seconds
2021-01-19 17:21:19.741247 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:21:20.256943 (MainThread): Using snowflake connection "master".
2021-01-19 17:21:20.257140 (MainThread): On master: BEGIN
2021-01-19 17:21:20.257275 (MainThread): Opening a new connection, currently in state init
2021-01-19 17:21:21.130772 (MainThread): SQL status: SUCCESS 1 in 0.87 seconds
2021-01-19 17:21:21.131048 (MainThread): On master: COMMIT
2021-01-19 17:21:21.131296 (MainThread): Using snowflake connection "master".
2021-01-19 17:21:21.131442 (MainThread): On master: COMMIT
2021-01-19 17:21:21.521381 (MainThread): SQL status: SUCCESS 1 in 0.39 seconds
2021-01-19 17:21:21.521612 (MainThread): On master: Close
2021-01-19 17:21:21.914378 (MainThread): 18:21:21 | Concurrency: 1 threads (target='dev')
2021-01-19 17:21:21.914616 (MainThread): 18:21:21 | 
2021-01-19 17:21:21.917258 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:21:21.918588 (Thread-1): 18:21:21 | 1 of 7 START table model dbt.first_model............................. [RUN]
2021-01-19 17:21:21.918977 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:21:21.919132 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-19 17:21:21.943813 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:21:21.944323 (Thread-1): finished collecting timing info
2021-01-19 17:21:21.980792 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-19 17:21:21.981759 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:21:21.981859 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-19 17:21:21.981952 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:23.069695 (Thread-1): SQL status: SUCCESS 1 in 1.09 seconds
2021-01-19 17:21:23.069963 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:21:23.070114 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
      );
2021-01-19 17:21:24.919164 (Thread-1): SQL status: SUCCESS 1 in 1.85 seconds
2021-01-19 17:21:24.920665 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:21:24.921012 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-19 17:21:24.921166 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-19 17:21:25.106077 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 17:21:25.121326 (Thread-1): finished collecting timing info
2021-01-19 17:21:25.121739 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-19 17:21:25.569803 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122223d0>]}
2021-01-19 17:21:25.571352 (Thread-1): 18:21:25 | 1 of 7 OK created table model dbt.first_model........................ [SUCCESS 1 in 3.65s]
2021-01-19 17:21:25.571564 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-19 17:21:25.571830 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:21:25.573381 (Thread-1): 18:21:25 | 2 of 7 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-19 17:21:25.573819 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:21:25.573957 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:21:25.580891 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:21:25.581355 (Thread-1): finished collecting timing info
2021-01-19 17:21:25.586157 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-19 17:21:25.587155 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:21:25.587267 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-19 17:21:25.587374 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:26.388557 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2021-01-19 17:21:26.388772 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:21:26.388894 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-19 17:21:28.557981 (Thread-1): SQL status: SUCCESS 1 in 2.17 seconds
2021-01-19 17:21:28.559336 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:21:28.559546 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-19 17:21:28.559668 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-19 17:21:28.712370 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2021-01-19 17:21:28.715390 (Thread-1): finished collecting timing info
2021-01-19 17:21:28.715719 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-19 17:21:28.974087 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122c6460>]}
2021-01-19 17:21:28.975428 (Thread-1): 18:21:28 | 2 of 7 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 3.40s]
2021-01-19 17:21:28.975587 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-19 17:21:28.975742 (Thread-1): Began running node model.dbt_learn.dates
2021-01-19 17:21:28.977250 (Thread-1): 18:21:28 | 3 of 7 START incremental model dbt.dates............................. [RUN]
2021-01-19 17:21:28.977600 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:28.977743 (Thread-1): Compiling model.dbt_learn.dates
2021-01-19 17:21:28.994261 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-19 17:21:28.994739 (Thread-1): finished collecting timing info
2021-01-19 17:21:29.023247 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:29.023393 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-19 17:21:29.023492 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:31.764918 (Thread-1): SQL status: SUCCESS 1 in 2.74 seconds
2021-01-19 17:21:31.776130 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:31.776254 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-19 17:21:31.974045 (Thread-1): SQL status: SUCCESS 28 in 0.20 seconds
2021-01-19 17:21:31.980436 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:31.980556 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:21:32.196961 (Thread-1): SQL status: SUCCESS 28 in 0.22 seconds
2021-01-19 17:21:32.204052 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:32.204240 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-19 17:21:32.374679 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-19 17:21:32.402641 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-19 17:21:32.405891 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:32.406033 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-19 17:21:32.603533 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-19 17:21:32.603787 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:32.603941 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-19 17:21:34.234533 (Thread-1): SQL status: SUCCESS 0 in 1.63 seconds
2021-01-19 17:21:34.236086 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:21:34.236370 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-19 17:21:34.236495 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-19 17:21:34.503244 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2021-01-19 17:21:34.508111 (Thread-1): finished collecting timing info
2021-01-19 17:21:34.508440 (Thread-1): On model.dbt_learn.dates: Close
2021-01-19 17:21:34.779290 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122af8b0>]}
2021-01-19 17:21:34.780796 (Thread-1): 18:21:34 | 3 of 7 OK created incremental model dbt.dates........................ [SUCCESS 0 in 5.80s]
2021-01-19 17:21:34.780983 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-19 17:21:34.781167 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-19 17:21:34.782617 (Thread-1): 18:21:34 | 4 of 7 START incremental model dbt.incremental_time.................. [RUN]
2021-01-19 17:21:34.782943 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:34.783074 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-19 17:21:34.792555 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:21:34.792988 (Thread-1): finished collecting timing info
2021-01-19 17:21:34.799265 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:34.799388 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-19 17:21:34.799500 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:36.975438 (Thread-1): SQL status: SUCCESS 1 in 2.18 seconds
2021-01-19 17:21:36.978343 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:36.978460 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-19 17:21:37.178772 (Thread-1): SQL status: SUCCESS 10 in 0.20 seconds
2021-01-19 17:21:37.183221 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:37.183359 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:21:37.343927 (Thread-1): SQL status: SUCCESS 10 in 0.16 seconds
2021-01-19 17:21:37.348269 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:37.348389 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-19 17:21:37.500779 (Thread-1): SQL status: SUCCESS 10 in 0.15 seconds
2021-01-19 17:21:37.504329 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-19 17:21:37.506121 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:37.506231 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-19 17:21:37.683549 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-19 17:21:37.683756 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:37.683878 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-19 17:21:38.800534 (Thread-1): SQL status: SUCCESS 579 in 1.12 seconds
2021-01-19 17:21:38.802062 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:21:38.802327 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-19 17:21:38.802483 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-19 17:21:39.143380 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2021-01-19 17:21:39.147237 (Thread-1): finished collecting timing info
2021-01-19 17:21:39.147518 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-19 17:21:39.409338 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127205b0>]}
2021-01-19 17:21:39.410857 (Thread-1): 18:21:39 | 4 of 7 OK created incremental model dbt.incremental_time............. [SUCCESS 579 in 4.63s]
2021-01-19 17:21:39.411048 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-19 17:21:39.411236 (Thread-1): Began running node model.dbt_learn.playing_with_tests
2021-01-19 17:21:39.412824 (Thread-1): 18:21:39 | 5 of 7 START table model dbt.playing_with_tests...................... [RUN]
2021-01-19 17:21:39.413154 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-19 17:21:39.413288 (Thread-1): Compiling model.dbt_learn.playing_with_tests
2021-01-19 17:21:39.421618 (Thread-1): Writing injected SQL for node "model.dbt_learn.playing_with_tests"
2021-01-19 17:21:39.422032 (Thread-1): finished collecting timing info
2021-01-19 17:21:39.427251 (Thread-1): Writing runtime SQL for node "model.dbt_learn.playing_with_tests"
2021-01-19 17:21:39.428011 (Thread-1): Using snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-19 17:21:39.428123 (Thread-1): On model.dbt_learn.playing_with_tests: BEGIN
2021-01-19 17:21:39.428229 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:40.655964 (Thread-1): SQL status: SUCCESS 1 in 1.23 seconds
2021-01-19 17:21:40.656181 (Thread-1): Using snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-19 17:21:40.656303 (Thread-1): On model.dbt_learn.playing_with_tests: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF001"."CUSTOMER"
      );
2021-01-19 17:21:41.803220 (Thread-1): SQL status: SUCCESS 1 in 1.15 seconds
2021-01-19 17:21:41.804952 (Thread-1): On model.dbt_learn.playing_with_tests: COMMIT
2021-01-19 17:21:41.805253 (Thread-1): Using snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-19 17:21:41.805384 (Thread-1): On model.dbt_learn.playing_with_tests: COMMIT
2021-01-19 17:21:41.961987 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2021-01-19 17:21:41.965203 (Thread-1): finished collecting timing info
2021-01-19 17:21:41.966031 (Thread-1): On model.dbt_learn.playing_with_tests: Close
2021-01-19 17:21:42.328385 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112222dc0>]}
2021-01-19 17:21:42.329724 (Thread-1): 18:21:42 | 5 of 7 OK created table model dbt.playing_with_tests................. [SUCCESS 1 in 2.92s]
2021-01-19 17:21:42.329884 (Thread-1): Finished running node model.dbt_learn.playing_with_tests
2021-01-19 17:21:42.330082 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:21:42.331367 (Thread-1): 18:21:42 | 6 of 7 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-19 17:21:42.331762 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:21:42.331906 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:21:42.341128 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:21:42.341595 (Thread-1): finished collecting timing info
2021-01-19 17:21:42.346406 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-19 17:21:42.347955 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:21:42.348079 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-19 17:21:42.348184 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:43.319186 (Thread-1): SQL status: SUCCESS 1 in 0.97 seconds
2021-01-19 17:21:43.319403 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:21:43.319526 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-19 17:21:45.504124 (Thread-1): SQL status: SUCCESS 1 in 2.18 seconds
2021-01-19 17:21:45.523124 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:21:45.523322 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-19 17:21:45.523414 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-19 17:21:45.837426 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-19 17:21:45.840164 (Thread-1): finished collecting timing info
2021-01-19 17:21:45.840492 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-19 17:21:46.101615 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112460c70>]}
2021-01-19 17:21:46.102851 (Thread-1): 18:21:46 | 6 of 7 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 3.77s]
2021-01-19 17:21:46.103064 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-19 17:21:46.103295 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:21:46.105328 (Thread-1): 18:21:46 | 7 of 7 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-19 17:21:46.105761 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:21:46.106096 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-19 17:21:46.115682 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:21:46.116386 (Thread-1): finished collecting timing info
2021-01-19 17:21:46.121406 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-19 17:21:46.122348 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:21:46.122499 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-19 17:21:46.122608 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:47.124063 (Thread-1): SQL status: SUCCESS 1 in 1.00 seconds
2021-01-19 17:21:47.124333 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:21:47.124483 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-19 17:21:48.479211 (Thread-1): SQL status: SUCCESS 1 in 1.35 seconds
2021-01-19 17:21:48.481240 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:21:48.481477 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-19 17:21:48.481601 (Thread-1): On model.dbt_learn.my_second_dbt_model: COMMIT
2021-01-19 17:21:48.625323 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2021-01-19 17:21:48.628615 (Thread-1): finished collecting timing info
2021-01-19 17:21:48.628930 (Thread-1): On model.dbt_learn.my_second_dbt_model: Close
2021-01-19 17:21:48.883654 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555bd1ba-247d-442b-8319-75b7cfb95aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112218c10>]}
2021-01-19 17:21:48.885769 (Thread-1): 18:21:48 | 7 of 7 OK created table model dbt.my_second_dbt_model................ [SUCCESS 1 in 2.78s]
2021-01-19 17:21:48.885983 (Thread-1): Finished running node model.dbt_learn.my_second_dbt_model
2021-01-19 17:21:48.887655 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:21:48.887894 (MainThread): Using snowflake connection "master".
2021-01-19 17:21:48.887995 (MainThread): On master: BEGIN
2021-01-19 17:21:48.888097 (MainThread): Opening a new connection, currently in state closed
2021-01-19 17:21:49.693699 (MainThread): SQL status: SUCCESS 1 in 0.81 seconds
2021-01-19 17:21:49.693913 (MainThread): On master: COMMIT
2021-01-19 17:21:49.694096 (MainThread): Using snowflake connection "master".
2021-01-19 17:21:49.694193 (MainThread): On master: COMMIT
2021-01-19 17:21:49.917018 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 17:21:49.917304 (MainThread): On master: Close
2021-01-19 17:21:50.170450 (MainThread): 18:21:50 | 
2021-01-19 17:21:50.170661 (MainThread): 18:21:50 | Finished running 5 table models, 2 incremental models in 33.50s.
2021-01-19 17:21:50.170920 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:21:50.171161 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was properly closed.
2021-01-19 17:21:50.197355 (MainThread): 
2021-01-19 17:21:50.197534 (MainThread): Completed successfully
2021-01-19 17:21:50.197663 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-01-19 17:21:50.197846 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112694a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121f5c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11223e580>]}
2021-01-19 17:21:50.198057 (MainThread): Flushing usage events
2021-01-19 17:21:56.376841 (MainThread): Running with dbt=0.18.1
2021-01-19 17:21:56.443348 (MainThread): Loading KWallet
2021-01-19 17:21:56.443866 (MainThread): Loading SecretService
2021-01-19 17:21:56.444237 (MainThread): Loading Windows
2021-01-19 17:21:56.444718 (MainThread): Loading chainer
2021-01-19 17:21:56.445121 (MainThread): Loading macOS
2021-01-19 17:21:56.705925 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-01-19 17:21:56.709597 (MainThread): Tracking: tracking
2021-01-19 17:21:56.709977 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b258b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b468d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b468dc0>]}
2021-01-19 17:21:56.755470 (MainThread): Got an acceptable cached parse result
2021-01-19 17:21:56.831463 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-19 17:21:56.938576 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-19 17:21:56.940777 (MainThread): 
2021-01-19 17:21:56.941415 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:21:56.960636 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-19 17:21:56.972614 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-19 17:21:56.972726 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-19 17:21:56.972800 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-01-19 17:21:58.129639 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 7 in 1.16 seconds
2021-01-19 17:21:58.141049 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-19 17:21:58.407372 (MainThread): 18:21:58 | Concurrency: 1 threads (target='dev')
2021-01-19 17:21:58.407579 (MainThread): 18:21:58 | 
2021-01-19 17:21:58.409698 (Thread-1): Began running node test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE
2021-01-19 17:21:58.409906 (Thread-1): 18:21:58 | 1 of 10 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
2021-01-19 17:21:58.410215 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE".
2021-01-19 17:21:58.410362 (Thread-1): Compiling test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE
2021-01-19 17:21:58.453469 (Thread-1): Writing injected SQL for node "test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE"
2021-01-19 17:21:58.453924 (Thread-1): finished collecting timing info
2021-01-19 17:21:58.454956 (Thread-1): Using snowflake connection "test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE".
2021-01-19 17:21:58.455078 (Thread-1): On test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE: BEGIN
2021-01-19 17:21:58.455182 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:21:59.498973 (Thread-1): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-19 17:21:59.499236 (Thread-1): Using snowflake connection "test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE".
2021-01-19 17:21:59.499389 (Thread-1): On test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE"} */

    
    




with all_values as (

    select distinct
        c_mktsegment as value_field

    from analytics.dbt.playing_with_tests

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
    )
)

select count(*) as validation_errors
from validation_errors
2021-01-19 17:21:59.816294 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 17:21:59.816656 (Thread-1): finished collecting timing info
2021-01-19 17:21:59.816967 (Thread-1): On test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE: ROLLBACK
2021-01-19 17:22:00.064313 (Thread-1): On test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE: Close
2021-01-19 17:22:00.338755 (Thread-1): 18:22:00 | 1 of 10 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [PASS in 1.93s]
2021-01-19 17:22:00.338969 (Thread-1): Finished running node test.dbt_learn.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE
2021-01-19 17:22:00.339154 (Thread-1): Began running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:22:00.339541 (Thread-1): 18:22:00 | 2 of 10 START test not_null_my_first_dbt_model_id.................... [RUN]
2021-01-19 17:22:00.340028 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:22:00.340185 (Thread-1): Compiling test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:22:00.354975 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_first_dbt_model_id"
2021-01-19 17:22:00.355469 (Thread-1): finished collecting timing info
2021-01-19 17:22:00.356160 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:22:00.356288 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: BEGIN
2021-01-19 17:22:00.356400 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:01.145736 (Thread-1): SQL status: SUCCESS 1 in 0.79 seconds
2021-01-19 17:22:01.145924 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_first_dbt_model_id".
2021-01-19 17:22:01.146029 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.first_model
where id is null
2021-01-19 17:22:01.543927 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2021-01-19 17:22:01.544291 (Thread-1): finished collecting timing info
2021-01-19 17:22:01.544609 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:22:01.774520 (Thread-1): On test.dbt_learn.not_null_my_first_dbt_model_id: Close
2021-01-19 17:22:02.052071 (Thread-1): 18:22:02 | 2 of 10 FAIL 1 not_null_my_first_dbt_model_id........................ [FAIL 1 in 1.71s]
2021-01-19 17:22:02.052284 (Thread-1): Finished running node test.dbt_learn.not_null_my_first_dbt_model_id
2021-01-19 17:22:02.052451 (Thread-1): Began running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:22:02.052821 (Thread-1): 18:22:02 | 3 of 10 START test not_null_my_second_dbt_model_id................... [RUN]
2021-01-19 17:22:02.053369 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:22:02.053554 (Thread-1): Compiling test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:22:02.064712 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_my_second_dbt_model_id"
2021-01-19 17:22:02.065206 (Thread-1): finished collecting timing info
2021-01-19 17:22:02.065870 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:22:02.065979 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: BEGIN
2021-01-19 17:22:02.066084 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:02.929747 (Thread-1): SQL status: SUCCESS 1 in 0.86 seconds
2021-01-19 17:22:02.930012 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_my_second_dbt_model_id".
2021-01-19 17:22:02.930171 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from analytics.dbt.my_second_dbt_model
where id is null
2021-01-19 17:22:03.226538 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 17:22:03.227008 (Thread-1): finished collecting timing info
2021-01-19 17:22:03.227450 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:22:03.457435 (Thread-1): On test.dbt_learn.not_null_my_second_dbt_model_id: Close
2021-01-19 17:22:03.720517 (Thread-1): 18:22:03 | 3 of 10 PASS not_null_my_second_dbt_model_id......................... [PASS in 1.67s]
2021-01-19 17:22:03.720764 (Thread-1): Finished running node test.dbt_learn.not_null_my_second_dbt_model_id
2021-01-19 17:22:03.721016 (Thread-1): Began running node test.dbt_learn.not_null_playing_with_tests_c_custkey
2021-01-19 17:22:03.721370 (Thread-1): 18:22:03 | 4 of 10 START test not_null_playing_with_tests_c_custkey............. [RUN]
2021-01-19 17:22:03.722040 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_playing_with_tests_c_custkey".
2021-01-19 17:22:03.722226 (Thread-1): Compiling test.dbt_learn.not_null_playing_with_tests_c_custkey
2021-01-19 17:22:03.734207 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_playing_with_tests_c_custkey"
2021-01-19 17:22:03.734714 (Thread-1): finished collecting timing info
2021-01-19 17:22:03.735416 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_playing_with_tests_c_custkey".
2021-01-19 17:22:03.735535 (Thread-1): On test.dbt_learn.not_null_playing_with_tests_c_custkey: BEGIN
2021-01-19 17:22:03.735648 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:04.816236 (Thread-1): SQL status: SUCCESS 1 in 1.08 seconds
2021-01-19 17:22:04.816418 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_playing_with_tests_c_custkey".
2021-01-19 17:22:04.816522 (Thread-1): On test.dbt_learn.not_null_playing_with_tests_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_playing_with_tests_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.playing_with_tests
where c_custkey is null
2021-01-19 17:22:05.029488 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2021-01-19 17:22:05.029814 (Thread-1): finished collecting timing info
2021-01-19 17:22:05.030122 (Thread-1): On test.dbt_learn.not_null_playing_with_tests_c_custkey: ROLLBACK
2021-01-19 17:22:05.254090 (Thread-1): On test.dbt_learn.not_null_playing_with_tests_c_custkey: Close
2021-01-19 17:22:05.505388 (Thread-1): 18:22:05 | 4 of 10 PASS not_null_playing_with_tests_c_custkey................... [PASS in 1.78s]
2021-01-19 17:22:05.505626 (Thread-1): Finished running node test.dbt_learn.not_null_playing_with_tests_c_custkey
2021-01-19 17:22:05.505864 (Thread-1): Began running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:22:05.506232 (Thread-1): 18:22:05 | 5 of 10 START test not_null_snowflake_customer_purchases_c_custkey... [RUN]
2021-01-19 17:22:05.506717 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:22:05.506880 (Thread-1): Compiling test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:22:05.517966 (Thread-1): Writing injected SQL for node "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"
2021-01-19 17:22:05.518455 (Thread-1): finished collecting timing info
2021-01-19 17:22:05.519136 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:22:05.519247 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:22:05.519357 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:06.536530 (Thread-1): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-19 17:22:06.536798 (Thread-1): Using snowflake connection "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey".
2021-01-19 17:22:06.536954 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null
2021-01-19 17:22:06.799046 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-19 17:22:06.799511 (Thread-1): finished collecting timing info
2021-01-19 17:22:06.799955 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:22:07.019993 (Thread-1): On test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:22:07.275759 (Thread-1): 18:22:07 | 5 of 10 PASS not_null_snowflake_customer_purchases_c_custkey......... [PASS in 1.77s]
2021-01-19 17:22:07.275993 (Thread-1): Finished running node test.dbt_learn.not_null_snowflake_customer_purchases_c_custkey
2021-01-19 17:22:07.276232 (Thread-1): Began running node test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:22:07.276630 (Thread-1): 18:22:07 | 6 of 10 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
2021-01-19 17:22:07.277158 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:22:07.277375 (Thread-1): Compiling test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:22:07.295279 (Thread-1): Writing injected SQL for node "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"
2021-01-19 17:22:07.295762 (Thread-1): finished collecting timing info
2021-01-19 17:22:07.296716 (Thread-1): Using snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:22:07.296829 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: BEGIN
2021-01-19 17:22:07.296939 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:08.286994 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2021-01-19 17:22:08.287256 (Thread-1): Using snowflake connection "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_".
2021-01-19 17:22:08.287425 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_"} */

    
    




select count(*) as validation_errors
from (
    select id as id from analytics.dbt.my_second_dbt_model
) as child
left join (
    select id as id from analytics.dbt.first_model
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null
2021-01-19 17:22:08.607447 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-19 17:22:08.607831 (Thread-1): finished collecting timing info
2021-01-19 17:22:08.608189 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: ROLLBACK
2021-01-19 17:22:08.837219 (Thread-1): On test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_: Close
2021-01-19 17:22:09.090680 (Thread-1): 18:22:09 | 6 of 10 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [PASS in 1.81s]
2021-01-19 17:22:09.090911 (Thread-1): Finished running node test.dbt_learn.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_
2021-01-19 17:22:09.091142 (Thread-1): Began running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:22:09.091603 (Thread-1): 18:22:09 | 7 of 10 START test unique_my_first_dbt_model_id...................... [RUN]
2021-01-19 17:22:09.092014 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:22:09.092187 (Thread-1): Compiling test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:22:09.107682 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_first_dbt_model_id"
2021-01-19 17:22:09.108198 (Thread-1): finished collecting timing info
2021-01-19 17:22:09.109007 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:22:09.109121 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: BEGIN
2021-01-19 17:22:09.109234 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:10.247998 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2021-01-19 17:22:10.248254 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_first_dbt_model_id".
2021-01-19 17:22:10.248405 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.first_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:22:10.466847 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-19 17:22:10.467311 (Thread-1): finished collecting timing info
2021-01-19 17:22:10.467759 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: ROLLBACK
2021-01-19 17:22:10.669742 (Thread-1): On test.dbt_learn.unique_my_first_dbt_model_id: Close
2021-01-19 17:22:10.931094 (Thread-1): 18:22:10 | 7 of 10 PASS unique_my_first_dbt_model_id............................ [PASS in 1.84s]
2021-01-19 17:22:10.931331 (Thread-1): Finished running node test.dbt_learn.unique_my_first_dbt_model_id
2021-01-19 17:22:10.931572 (Thread-1): Began running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:22:10.932020 (Thread-1): 18:22:10 | 8 of 10 START test unique_my_second_dbt_model_id..................... [RUN]
2021-01-19 17:22:10.932418 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:22:10.932575 (Thread-1): Compiling test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:22:10.943998 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_my_second_dbt_model_id"
2021-01-19 17:22:10.944498 (Thread-1): finished collecting timing info
2021-01-19 17:22:10.945300 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:22:10.945411 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: BEGIN
2021-01-19 17:22:10.945516 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:11.752120 (Thread-1): SQL status: SUCCESS 1 in 0.81 seconds
2021-01-19 17:22:11.752380 (Thread-1): Using snowflake connection "test.dbt_learn.unique_my_second_dbt_model_id".
2021-01-19 17:22:11.752532 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from analytics.dbt.my_second_dbt_model
    where id is not null
    group by id
    having count(*) > 1

) validation_errors
2021-01-19 17:22:12.108759 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2021-01-19 17:22:12.109140 (Thread-1): finished collecting timing info
2021-01-19 17:22:12.109573 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: ROLLBACK
2021-01-19 17:22:12.454399 (Thread-1): On test.dbt_learn.unique_my_second_dbt_model_id: Close
2021-01-19 17:22:12.719318 (Thread-1): 18:22:12 | 8 of 10 PASS unique_my_second_dbt_model_id........................... [PASS in 1.79s]
2021-01-19 17:22:12.719559 (Thread-1): Finished running node test.dbt_learn.unique_my_second_dbt_model_id
2021-01-19 17:22:12.719796 (Thread-1): Began running node test.dbt_learn.unique_playing_with_tests_c_custkey
2021-01-19 17:22:12.720192 (Thread-1): 18:22:12 | 9 of 10 START test unique_playing_with_tests_c_custkey............... [RUN]
2021-01-19 17:22:12.720686 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_playing_with_tests_c_custkey".
2021-01-19 17:22:12.720865 (Thread-1): Compiling test.dbt_learn.unique_playing_with_tests_c_custkey
2021-01-19 17:22:12.732400 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_playing_with_tests_c_custkey"
2021-01-19 17:22:12.732936 (Thread-1): finished collecting timing info
2021-01-19 17:22:12.733825 (Thread-1): Using snowflake connection "test.dbt_learn.unique_playing_with_tests_c_custkey".
2021-01-19 17:22:12.733940 (Thread-1): On test.dbt_learn.unique_playing_with_tests_c_custkey: BEGIN
2021-01-19 17:22:12.734051 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:13.570364 (Thread-1): SQL status: SUCCESS 1 in 0.84 seconds
2021-01-19 17:22:13.570627 (Thread-1): Using snowflake connection "test.dbt_learn.unique_playing_with_tests_c_custkey".
2021-01-19 17:22:13.570798 (Thread-1): On test.dbt_learn.unique_playing_with_tests_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_playing_with_tests_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.playing_with_tests
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 17:22:14.075758 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-01-19 17:22:14.076224 (Thread-1): finished collecting timing info
2021-01-19 17:22:14.076668 (Thread-1): On test.dbt_learn.unique_playing_with_tests_c_custkey: ROLLBACK
2021-01-19 17:22:14.287601 (Thread-1): On test.dbt_learn.unique_playing_with_tests_c_custkey: Close
2021-01-19 17:22:14.643844 (Thread-1): 18:22:14 | 9 of 10 PASS unique_playing_with_tests_c_custkey..................... [PASS in 1.92s]
2021-01-19 17:22:14.644079 (Thread-1): Finished running node test.dbt_learn.unique_playing_with_tests_c_custkey
2021-01-19 17:22:14.644325 (Thread-1): Began running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:22:14.644637 (Thread-1): 18:22:14 | 10 of 10 START test unique_snowflake_customer_purchases_c_custkey.... [RUN]
2021-01-19 17:22:14.645148 (Thread-1): Acquiring new snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:22:14.645392 (Thread-1): Compiling test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:22:14.656963 (Thread-1): Writing injected SQL for node "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"
2021-01-19 17:22:14.657482 (Thread-1): finished collecting timing info
2021-01-19 17:22:14.658377 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:22:14.658491 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: BEGIN
2021-01-19 17:22:14.658599 (Thread-1): Opening a new connection, currently in state closed
2021-01-19 17:22:15.462723 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2021-01-19 17:22:15.462986 (Thread-1): Using snowflake connection "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey".
2021-01-19 17:22:15.463141 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "test.dbt_learn.unique_snowflake_customer_purchases_c_custkey"} */

    
    



select count(*) as validation_errors
from (

    select
        c_custkey

    from analytics.dbt.snowflake_customer_purchases
    where c_custkey is not null
    group by c_custkey
    having count(*) > 1

) validation_errors
2021-01-19 17:22:15.765746 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2021-01-19 17:22:15.766206 (Thread-1): finished collecting timing info
2021-01-19 17:22:15.766654 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: ROLLBACK
2021-01-19 17:22:15.976148 (Thread-1): On test.dbt_learn.unique_snowflake_customer_purchases_c_custkey: Close
2021-01-19 17:22:16.234959 (Thread-1): 18:22:16 | 10 of 10 PASS unique_snowflake_customer_purchases_c_custkey.......... [PASS in 1.59s]
2021-01-19 17:22:16.235192 (Thread-1): Finished running node test.dbt_learn.unique_snowflake_customer_purchases_c_custkey
2021-01-19 17:22:16.236804 (MainThread): Acquiring new snowflake connection "master".
2021-01-19 17:22:16.237177 (MainThread): 18:22:16 | 
2021-01-19 17:22:16.237319 (MainThread): 18:22:16 | Finished running 10 tests in 19.30s.
2021-01-19 17:22:16.237441 (MainThread): Connection 'master' was properly closed.
2021-01-19 17:22:16.237532 (MainThread): Connection 'test.dbt_learn.unique_snowflake_customer_purchases_c_custkey' was properly closed.
2021-01-19 17:22:16.271550 (MainThread): 
2021-01-19 17:22:16.271730 (MainThread): Completed with 1 error and 0 warnings:
2021-01-19 17:22:16.271857 (MainThread): 
2021-01-19 17:22:16.271984 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-01-19 17:22:16.272120 (MainThread):   Got 1 result, expected 0.
2021-01-19 17:22:16.272230 (MainThread): 
2021-01-19 17:22:16.272341 (MainThread):   compiled SQL at target/compiled/dbt_learn/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-01-19 17:22:16.272464 (MainThread): 
Done. PASS=9 WARN=0 ERROR=1 SKIP=0 TOTAL=10
2021-01-19 17:22:16.272727 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c169d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c40aca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c40ad90>]}
2021-01-19 17:22:16.272958 (MainThread): Flushing usage events
2021-01-20 18:27:00.046857 (MainThread): Running with dbt=0.18.1
2021-01-20 18:27:00.198590 (MainThread): Loading KWallet
2021-01-20 18:27:00.199509 (MainThread): Loading SecretService
2021-01-20 18:27:00.200229 (MainThread): Loading Windows
2021-01-20 18:27:00.201130 (MainThread): Loading chainer
2021-01-20 18:27:00.201745 (MainThread): Loading macOS
2021-01-20 18:27:00.727481 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['models/example'], partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-20 18:27:00.729025 (MainThread): Tracking: tracking
2021-01-20 18:27:00.729497 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbdb550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdeb040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdebd90>]}
2021-01-20 18:27:00.783079 (MainThread): Got an acceptable cached parse result
2021-01-20 18:27:00.875112 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-20 18:27:00.982693 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-20 18:27:00.984230 (MainThread): 
2021-01-20 18:27:00.984503 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:27:00.993122 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-20 18:27:01.006823 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-20 18:27:01.007010 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-20 18:27:01.007112 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-20 18:27:02.809860 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.80 seconds
2021-01-20 18:27:02.814765 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-20 18:27:03.187752 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-20 18:27:03.196892 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-20 18:27:03.197069 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-20 18:27:03.197178 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-20 18:27:04.229005 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 7 in 1.03 seconds
2021-01-20 18:27:04.238100 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-20 18:27:04.855014 (MainThread): Using snowflake connection "master".
2021-01-20 18:27:04.855215 (MainThread): On master: BEGIN
2021-01-20 18:27:04.855331 (MainThread): Opening a new connection, currently in state init
2021-01-20 18:27:06.298090 (MainThread): SQL status: SUCCESS 1 in 1.44 seconds
2021-01-20 18:27:06.298293 (MainThread): On master: COMMIT
2021-01-20 18:27:06.298464 (MainThread): Using snowflake connection "master".
2021-01-20 18:27:06.298561 (MainThread): On master: COMMIT
2021-01-20 18:27:06.515253 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2021-01-20 18:27:06.515545 (MainThread): On master: Close
2021-01-20 18:27:06.952545 (MainThread): 19:27:06 | Concurrency: 1 threads (target='dev')
2021-01-20 18:27:06.952792 (MainThread): 19:27:06 | 
2021-01-20 18:27:06.956501 (Thread-1): Began running node model.dbt_learn.my_first_dbt_model
2021-01-20 18:27:06.957883 (Thread-1): 19:27:06 | 1 of 7 START table model dbt.first_model............................. [RUN]
2021-01-20 18:27:06.958228 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-20 18:27:06.958371 (Thread-1): Compiling model.dbt_learn.my_first_dbt_model
2021-01-20 18:27:06.992041 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-20 18:27:06.993233 (Thread-1): finished collecting timing info
2021-01-20 18:27:07.034476 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_first_dbt_model"
2021-01-20 18:27:07.036159 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-20 18:27:07.036408 (Thread-1): On model.dbt_learn.my_first_dbt_model: BEGIN
2021-01-20 18:27:07.036599 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:08.394283 (Thread-1): SQL status: SUCCESS 1 in 1.36 seconds
2021-01-20 18:27:08.394475 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-20 18:27:08.394581 (Thread-1): On model.dbt_learn.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
      );
2021-01-20 18:27:09.725020 (Thread-1): SQL status: SUCCESS 1 in 1.33 seconds
2021-01-20 18:27:09.726733 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-20 18:27:09.726987 (Thread-1): Using snowflake connection "model.dbt_learn.my_first_dbt_model".
2021-01-20 18:27:09.727109 (Thread-1): On model.dbt_learn.my_first_dbt_model: COMMIT
2021-01-20 18:27:10.095396 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2021-01-20 18:27:10.111884 (Thread-1): finished collecting timing info
2021-01-20 18:27:10.112239 (Thread-1): On model.dbt_learn.my_first_dbt_model: Close
2021-01-20 18:27:10.401307 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11191f92-a4df-4dc1-afff-c36c7a28df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddec220>]}
2021-01-20 18:27:10.402663 (Thread-1): 19:27:10 | 1 of 7 OK created table model dbt.first_model........................ [SUCCESS 1 in 3.44s]
2021-01-20 18:27:10.402832 (Thread-1): Finished running node model.dbt_learn.my_first_dbt_model
2021-01-20 18:27:10.402994 (Thread-1): Began running node model.dbt_learn.cumulative_orders_by_date
2021-01-20 18:27:10.404649 (Thread-1): 19:27:10 | 2 of 7 START table model dbt.cumulative_orders_by_date............... [RUN]
2021-01-20 18:27:10.405259 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-20 18:27:10.405406 (Thread-1): Compiling model.dbt_learn.cumulative_orders_by_date
2021-01-20 18:27:10.413531 (Thread-1): Writing injected SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-20 18:27:10.415604 (Thread-1): finished collecting timing info
2021-01-20 18:27:10.422328 (Thread-1): Writing runtime SQL for node "model.dbt_learn.cumulative_orders_by_date"
2021-01-20 18:27:10.424020 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-20 18:27:10.424269 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: BEGIN
2021-01-20 18:27:10.424421 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:11.720830 (Thread-1): SQL status: SUCCESS 1 in 1.30 seconds
2021-01-20 18:27:11.721011 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-20 18:27:11.721111 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.cumulative_orders_by_date"} */


      create or replace transient table analytics.dbt.cumulative_orders_by_date  as
      (select distinct
       o_orderdate,
       sum(o_totalprice) over (order by o_orderdate) as cumulative_sales

       FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"

       order by o_orderdate
      );
2021-01-20 18:27:13.754949 (Thread-1): SQL status: SUCCESS 1 in 2.03 seconds
2021-01-20 18:27:13.756225 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-20 18:27:13.756434 (Thread-1): Using snowflake connection "model.dbt_learn.cumulative_orders_by_date".
2021-01-20 18:27:13.756553 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: COMMIT
2021-01-20 18:27:13.991953 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2021-01-20 18:27:13.994626 (Thread-1): finished collecting timing info
2021-01-20 18:27:13.994974 (Thread-1): On model.dbt_learn.cumulative_orders_by_date: Close
2021-01-20 18:27:14.450107 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11191f92-a4df-4dc1-afff-c36c7a28df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d892a30>]}
2021-01-20 18:27:14.451376 (Thread-1): 19:27:14 | 2 of 7 OK created table model dbt.cumulative_orders_by_date.......... [SUCCESS 1 in 4.04s]
2021-01-20 18:27:14.451536 (Thread-1): Finished running node model.dbt_learn.cumulative_orders_by_date
2021-01-20 18:27:14.451692 (Thread-1): Began running node model.dbt_learn.dates
2021-01-20 18:27:14.453523 (Thread-1): 19:27:14 | 3 of 7 START incremental model dbt.dates............................. [RUN]
2021-01-20 18:27:14.453920 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:14.454062 (Thread-1): Compiling model.dbt_learn.dates
2021-01-20 18:27:14.471362 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-20 18:27:14.472684 (Thread-1): finished collecting timing info
2021-01-20 18:27:14.506521 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:14.506713 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-20 18:27:14.506835 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:17.032225 (Thread-1): SQL status: SUCCESS 1 in 2.53 seconds
2021-01-20 18:27:17.043235 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:17.043430 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-20 18:27:17.436772 (Thread-1): SQL status: SUCCESS 28 in 0.39 seconds
2021-01-20 18:27:17.442487 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:17.442669 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:27:17.628182 (Thread-1): SQL status: SUCCESS 28 in 0.19 seconds
2021-01-20 18:27:17.633388 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:17.633508 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:27:17.828726 (Thread-1): SQL status: SUCCESS 28 in 0.20 seconds
2021-01-20 18:27:17.856765 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-20 18:27:17.859671 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:17.859792 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-20 18:27:18.116833 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2021-01-20 18:27:18.117011 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:18.117113 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-20 18:27:19.240157 (Thread-1): SQL status: SUCCESS 1 in 1.12 seconds
2021-01-20 18:27:19.241467 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:27:19.241689 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:27:19.241810 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:27:19.738406 (Thread-1): SQL status: SUCCESS 1 in 0.50 seconds
2021-01-20 18:27:19.743021 (Thread-1): finished collecting timing info
2021-01-20 18:27:19.743363 (Thread-1): On model.dbt_learn.dates: Close
2021-01-20 18:27:20.093229 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11191f92-a4df-4dc1-afff-c36c7a28df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df398e0>]}
2021-01-20 18:27:20.095792 (Thread-1): 19:27:20 | 3 of 7 OK created incremental model dbt.dates........................ [SUCCESS 1 in 5.64s]
2021-01-20 18:27:20.096125 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-20 18:27:20.096341 (Thread-1): Began running node model.dbt_learn.incremental_time
2021-01-20 18:27:20.098592 (Thread-1): 19:27:20 | 4 of 7 START incremental model dbt.incremental_time.................. [RUN]
2021-01-20 18:27:20.099273 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:20.099453 (Thread-1): Compiling model.dbt_learn.incremental_time
2021-01-20 18:27:20.110677 (Thread-1): Writing injected SQL for node "model.dbt_learn.incremental_time"
2021-01-20 18:27:20.112023 (Thread-1): finished collecting timing info
2021-01-20 18:27:20.120564 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:20.120871 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE, ':', T_SECOND)) <= current_time


  and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
2021-01-20 18:27:20.121052 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:22.765876 (Thread-1): SQL status: SUCCESS 1 in 2.64 seconds
2021-01-20 18:27:22.768551 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:22.768702 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
2021-01-20 18:27:22.948256 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-20 18:27:22.952698 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:22.952868 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-20 18:27:23.131202 (Thread-1): SQL status: SUCCESS 10 in 0.18 seconds
2021-01-20 18:27:23.135551 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:23.135748 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

    describe table analytics.dbt.incremental_time
2021-01-20 18:27:23.345273 (Thread-1): SQL status: SUCCESS 10 in 0.21 seconds
2021-01-20 18:27:23.348379 (Thread-1): Writing runtime SQL for node "model.dbt_learn.incremental_time"
2021-01-20 18:27:23.351452 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:23.351579 (Thread-1): On model.dbt_learn.incremental_time: BEGIN
2021-01-20 18:27:23.727533 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2021-01-20 18:27:23.727731 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:23.727853 (Thread-1): On model.dbt_learn.incremental_time: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.incremental_time"} */

        
        
    

    

    merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
2021-01-20 18:27:25.295906 (Thread-1): SQL status: SUCCESS 3946 in 1.57 seconds
2021-01-20 18:27:25.297156 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-20 18:27:25.297376 (Thread-1): Using snowflake connection "model.dbt_learn.incremental_time".
2021-01-20 18:27:25.297497 (Thread-1): On model.dbt_learn.incremental_time: COMMIT
2021-01-20 18:27:25.825393 (Thread-1): SQL status: SUCCESS 1 in 0.53 seconds
2021-01-20 18:27:25.830432 (Thread-1): finished collecting timing info
2021-01-20 18:27:25.830848 (Thread-1): On model.dbt_learn.incremental_time: Close
2021-01-20 18:27:26.096550 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11191f92-a4df-4dc1-afff-c36c7a28df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da91eb0>]}
2021-01-20 18:27:26.097805 (Thread-1): 19:27:26 | 4 of 7 OK created incremental model dbt.incremental_time............. [SUCCESS 3946 in 6.00s]
2021-01-20 18:27:26.097963 (Thread-1): Finished running node model.dbt_learn.incremental_time
2021-01-20 18:27:26.098174 (Thread-1): Began running node model.dbt_learn.playing_with_tests
2021-01-20 18:27:26.099775 (Thread-1): 19:27:26 | 5 of 7 START table model dbt.playing_with_tests...................... [RUN]
2021-01-20 18:27:26.100214 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-20 18:27:26.100364 (Thread-1): Compiling model.dbt_learn.playing_with_tests
2021-01-20 18:27:26.108550 (Thread-1): Writing injected SQL for node "model.dbt_learn.playing_with_tests"
2021-01-20 18:27:26.109576 (Thread-1): finished collecting timing info
2021-01-20 18:27:26.114400 (Thread-1): Writing runtime SQL for node "model.dbt_learn.playing_with_tests"
2021-01-20 18:27:26.115050 (Thread-1): Using snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-20 18:27:26.115161 (Thread-1): On model.dbt_learn.playing_with_tests: BEGIN
2021-01-20 18:27:26.115264 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:27.164014 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2021-01-20 18:27:27.164216 (Thread-1): Using snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-20 18:27:27.164325 (Thread-1): On model.dbt_learn.playing_with_tests: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (SELECT *
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF001"."CUSTOMER"
      );
2021-01-20 18:27:28.501916 (Thread-1): SQL status: SUCCESS 1 in 1.34 seconds
2021-01-20 18:27:28.503412 (Thread-1): On model.dbt_learn.playing_with_tests: COMMIT
2021-01-20 18:27:28.503605 (Thread-1): Using snowflake connection "model.dbt_learn.playing_with_tests".
2021-01-20 18:27:28.503710 (Thread-1): On model.dbt_learn.playing_with_tests: COMMIT
2021-01-20 18:27:28.703310 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2021-01-20 18:27:28.706249 (Thread-1): finished collecting timing info
2021-01-20 18:27:28.706818 (Thread-1): On model.dbt_learn.playing_with_tests: Close
2021-01-20 18:27:29.112930 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11191f92-a4df-4dc1-afff-c36c7a28df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df5cf40>]}
2021-01-20 18:27:29.114230 (Thread-1): 19:27:29 | 5 of 7 OK created table model dbt.playing_with_tests................. [SUCCESS 1 in 3.01s]
2021-01-20 18:27:29.114391 (Thread-1): Finished running node model.dbt_learn.playing_with_tests
2021-01-20 18:27:29.114578 (Thread-1): Began running node model.dbt_learn.snowflake_customer_purchases
2021-01-20 18:27:29.115820 (Thread-1): 19:27:29 | 6 of 7 START table model dbt.snowflake_customer_purchases............ [RUN]
2021-01-20 18:27:29.116137 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-20 18:27:29.116265 (Thread-1): Compiling model.dbt_learn.snowflake_customer_purchases
2021-01-20 18:27:29.123764 (Thread-1): Writing injected SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-20 18:27:29.125528 (Thread-1): finished collecting timing info
2021-01-20 18:27:29.130834 (Thread-1): Writing runtime SQL for node "model.dbt_learn.snowflake_customer_purchases"
2021-01-20 18:27:29.132564 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-20 18:27:29.132699 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: BEGIN
2021-01-20 18:27:29.132822 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:30.429320 (Thread-1): SQL status: SUCCESS 1 in 1.30 seconds
2021-01-20 18:27:30.429593 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-20 18:27:30.429746 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (SELECT
        c.c_custkey,
        c.c_name,
        c.c_nationkey as nation,
       sum(o.o_totalprice) as total_orders
FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
LEFT JOIN "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
ON c.c_custkey = o.o_custkey
GROUP BY
        c.c_custkey,
        c.c_name,
        c.c_nationkey
      );
2021-01-20 18:27:33.581953 (Thread-1): SQL status: SUCCESS 1 in 3.15 seconds
2021-01-20 18:27:33.583049 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-20 18:27:33.583227 (Thread-1): Using snowflake connection "model.dbt_learn.snowflake_customer_purchases".
2021-01-20 18:27:33.583330 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: COMMIT
2021-01-20 18:27:33.769290 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2021-01-20 18:27:33.771665 (Thread-1): finished collecting timing info
2021-01-20 18:27:33.771993 (Thread-1): On model.dbt_learn.snowflake_customer_purchases: Close
2021-01-20 18:27:34.216025 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11191f92-a4df-4dc1-afff-c36c7a28df41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df4fd30>]}
2021-01-20 18:27:34.217664 (Thread-1): 19:27:34 | 6 of 7 OK created table model dbt.snowflake_customer_purchases....... [SUCCESS 1 in 5.10s]
2021-01-20 18:27:34.217831 (Thread-1): Finished running node model.dbt_learn.snowflake_customer_purchases
2021-01-20 18:27:34.218095 (Thread-1): Began running node model.dbt_learn.my_second_dbt_model
2021-01-20 18:27:34.219794 (Thread-1): 19:27:34 | 7 of 7 START table model dbt.my_second_dbt_model..................... [RUN]
2021-01-20 18:27:34.220117 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-20 18:27:34.220369 (Thread-1): Compiling model.dbt_learn.my_second_dbt_model
2021-01-20 18:27:34.229625 (Thread-1): Writing injected SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-20 18:27:34.230817 (Thread-1): finished collecting timing info
2021-01-20 18:27:34.235723 (Thread-1): Writing runtime SQL for node "model.dbt_learn.my_second_dbt_model"
2021-01-20 18:27:34.236555 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-20 18:27:34.236669 (Thread-1): On model.dbt_learn.my_second_dbt_model: BEGIN
2021-01-20 18:27:34.236775 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:27:34.393015 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:27:34.393221 (MainThread): Opening a new connection, currently in state closed
2021-01-20 18:27:34.953392 (MainThread): Connection 'master' was properly closed.
2021-01-20 18:27:34.953752 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was left open.
2021-01-20 18:27:34.953839 (MainThread): On model.dbt_learn.my_second_dbt_model: Close
2021-01-20 18:27:35.169502 (MainThread): Flushing usage events
2021-01-20 18:27:35.262437 (Thread-1): SQL status: SUCCESS 1 in 1.03 seconds
2021-01-20 18:27:35.262681 (Thread-1): Using snowflake connection "model.dbt_learn.my_second_dbt_model".
2021-01-20 18:27:35.262829 (Thread-1): On model.dbt_learn.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models



select *
from analytics.dbt.first_model
where id = 1
      );
2021-01-20 18:27:35.935989 (MainThread): Connection 'master' was properly closed.
2021-01-20 18:27:35.936164 (MainThread): Connection 'model.dbt_learn.my_second_dbt_model' was left open.
2021-01-20 18:27:35.936265 (MainThread): On model.dbt_learn.my_second_dbt_model: ROLLBACK
2021-01-20 18:27:36.310757 (MainThread): On model.dbt_learn.my_second_dbt_model: Close
2021-01-20 18:27:36.312404 (Thread-1): Snowflake query id: 0199bdb3-06da-d11e-0000-003989034835
2021-01-20 18:27:36.312533 (Thread-1): Snowflake error: 000615 (57014): Transaction '05b7eb85-25a7-4b31-8e1b-faf3ea2082a7', id '1611167255090', was aborted, SQL execution canceled.
2021-01-20 18:27:36.312700 (Thread-1): finished collecting timing info
2021-01-20 18:27:36.468654 (MainThread): ctrl-c
2021-01-20 18:27:45.801003 (MainThread): Running with dbt=0.18.1
2021-01-20 18:27:45.871037 (MainThread): Loading KWallet
2021-01-20 18:27:45.871661 (MainThread): Loading SecretService
2021-01-20 18:27:45.872123 (MainThread): Loading Windows
2021-01-20 18:27:45.872718 (MainThread): Loading chainer
2021-01-20 18:27:45.873024 (MainThread): Loading macOS
2021-01-20 18:27:46.130218 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['example'], partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-20 18:27:46.131426 (MainThread): Tracking: tracking
2021-01-20 18:27:46.131705 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123db760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125ebd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125ebdc0>]}
2021-01-20 18:27:46.165888 (MainThread): Got an acceptable cached parse result
2021-01-20 18:27:46.239628 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-20 18:27:46.339189 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-20 18:27:46.341241 (MainThread): 
2021-01-20 18:27:46.341955 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:27:46.349890 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-20 18:27:46.361380 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-20 18:27:46.361476 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-20 18:27:46.361551 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-20 18:27:47.850017 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.49 seconds
2021-01-20 18:27:47.854961 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-20 18:27:48.124307 (MainThread): Connection 'master' was properly closed.
2021-01-20 18:27:48.124477 (MainThread): Connection 'list_analytics' was properly closed.
2021-01-20 18:27:48.124591 (MainThread): Flushing usage events
2021-01-20 18:27:48.896400 (MainThread): ctrl-c
2021-01-20 18:28:00.352897 (MainThread): Running with dbt=0.18.1
2021-01-20 18:28:00.433154 (MainThread): Loading KWallet
2021-01-20 18:28:00.433732 (MainThread): Loading SecretService
2021-01-20 18:28:00.434163 (MainThread): Loading Windows
2021-01-20 18:28:00.434721 (MainThread): Loading chainer
2021-01-20 18:28:00.435003 (MainThread): Loading macOS
2021-01-20 18:28:00.691009 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dates'], partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-20 18:28:00.692028 (MainThread): Tracking: tracking
2021-01-20 18:28:00.692302 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7bff40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9cfd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9cfdc0>]}
2021-01-20 18:28:00.728666 (MainThread): Got an acceptable cached parse result
2021-01-20 18:28:00.806093 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-20 18:28:00.905904 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-20 18:28:00.908431 (MainThread): 
2021-01-20 18:28:00.909160 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:28:00.910941 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-20 18:28:00.924963 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-20 18:28:00.925195 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-20 18:28:00.925277 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-20 18:28:02.252605 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.33 seconds
2021-01-20 18:28:02.255423 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-20 18:28:02.842190 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-20 18:28:02.849018 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-20 18:28:02.849127 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-20 18:28:02.849211 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-20 18:28:04.186971 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 7 in 1.34 seconds
2021-01-20 18:28:04.195135 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-20 18:28:04.630990 (MainThread): Using snowflake connection "master".
2021-01-20 18:28:04.631179 (MainThread): On master: BEGIN
2021-01-20 18:28:04.631312 (MainThread): Opening a new connection, currently in state init
2021-01-20 18:28:05.672581 (MainThread): SQL status: SUCCESS 1 in 1.04 seconds
2021-01-20 18:28:05.672854 (MainThread): On master: COMMIT
2021-01-20 18:28:05.673117 (MainThread): Using snowflake connection "master".
2021-01-20 18:28:05.673268 (MainThread): On master: COMMIT
2021-01-20 18:28:06.306781 (MainThread): SQL status: SUCCESS 1 in 0.63 seconds
2021-01-20 18:28:06.307064 (MainThread): On master: Close
2021-01-20 18:28:06.722306 (MainThread): 19:28:06 | Concurrency: 1 threads (target='dev')
2021-01-20 18:28:06.722544 (MainThread): 19:28:06 | 
2021-01-20 18:28:06.724556 (Thread-1): Began running node model.dbt_learn.dates
2021-01-20 18:28:06.726124 (Thread-1): 19:28:06 | 1 of 1 START incremental model dbt.dates............................. [RUN]
2021-01-20 18:28:06.726452 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:06.726598 (Thread-1): Compiling model.dbt_learn.dates
2021-01-20 18:28:06.761807 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-20 18:28:06.762291 (Thread-1): finished collecting timing info
2021-01-20 18:28:06.808633 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:06.808777 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-20 18:28:06.808856 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:28:08.828842 (Thread-1): SQL status: SUCCESS 1 in 2.02 seconds
2021-01-20 18:28:08.840682 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:08.840805 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-20 18:28:09.068687 (Thread-1): SQL status: SUCCESS 28 in 0.23 seconds
2021-01-20 18:28:09.075109 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:09.075229 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:28:09.243616 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-20 18:28:09.249870 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:09.249988 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:28:09.428315 (Thread-1): SQL status: SUCCESS 28 in 0.18 seconds
2021-01-20 18:28:09.456687 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-20 18:28:09.459539 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:09.459642 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-20 18:28:09.890230 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2021-01-20 18:28:09.890486 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:09.890638 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-20 18:28:10.688469 (Thread-1): SQL status: SUCCESS 0 in 0.80 seconds
2021-01-20 18:28:10.690141 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:28:10.690429 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:28:10.690552 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:28:11.135740 (Thread-1): SQL status: SUCCESS 1 in 0.45 seconds
2021-01-20 18:28:11.151379 (Thread-1): finished collecting timing info
2021-01-20 18:28:11.151656 (Thread-1): On model.dbt_learn.dates: Close
2021-01-20 18:28:11.464659 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d67148e-5590-4066-97e9-687d27215bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc47a00>]}
2021-01-20 18:28:11.466183 (Thread-1): 19:28:11 | 1 of 1 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.74s]
2021-01-20 18:28:11.466369 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-20 18:28:11.467980 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:28:11.468209 (MainThread): Using snowflake connection "master".
2021-01-20 18:28:11.468314 (MainThread): On master: BEGIN
2021-01-20 18:28:11.468421 (MainThread): Opening a new connection, currently in state closed
2021-01-20 18:28:12.687691 (MainThread): SQL status: SUCCESS 1 in 1.22 seconds
2021-01-20 18:28:12.687972 (MainThread): On master: COMMIT
2021-01-20 18:28:12.688224 (MainThread): Using snowflake connection "master".
2021-01-20 18:28:12.688374 (MainThread): On master: COMMIT
2021-01-20 18:28:13.012622 (MainThread): SQL status: SUCCESS 1 in 0.32 seconds
2021-01-20 18:28:13.012903 (MainThread): On master: Close
2021-01-20 18:28:13.283805 (MainThread): 19:28:13 | 
2021-01-20 18:28:13.284050 (MainThread): 19:28:13 | Finished running 1 incremental model in 12.37s.
2021-01-20 18:28:13.284203 (MainThread): Connection 'master' was properly closed.
2021-01-20 18:28:13.284411 (MainThread): Connection 'model.dbt_learn.dates' was properly closed.
2021-01-20 18:28:13.289794 (MainThread): 
2021-01-20 18:28:13.289984 (MainThread): Completed successfully
2021-01-20 18:28:13.290162 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-01-20 18:28:13.290474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc5e160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc5ef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc5e430>]}
2021-01-20 18:28:13.290719 (MainThread): Flushing usage events
2021-01-20 18:30:07.927520 (MainThread): Running with dbt=0.18.1
2021-01-20 18:30:08.050393 (MainThread): Loading KWallet
2021-01-20 18:30:08.051222 (MainThread): Loading SecretService
2021-01-20 18:30:08.051819 (MainThread): Loading Windows
2021-01-20 18:30:08.052623 (MainThread): Loading chainer
2021-01-20 18:30:08.053338 (MainThread): Loading macOS
2021-01-20 18:30:08.523944 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['example.dates'], partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-20 18:30:08.525155 (MainThread): Tracking: tracking
2021-01-20 18:30:08.525638 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10965d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10986dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10986ddc0>]}
2021-01-20 18:30:08.579465 (MainThread): Got an acceptable cached parse result
2021-01-20 18:30:08.679952 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-20 18:30:08.799090 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-20 18:30:08.800516 (MainThread): 
2021-01-20 18:30:08.800888 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:30:08.802442 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-20 18:30:08.817710 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-20 18:30:08.817855 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-20 18:30:08.817950 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-20 18:30:11.506433 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 2.69 seconds
2021-01-20 18:30:11.511120 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-20 18:30:12.022901 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-20 18:30:12.030553 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-20 18:30:12.030680 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-20 18:30:12.030795 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-20 18:30:13.257895 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 7 in 1.23 seconds
2021-01-20 18:30:13.265677 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-20 18:30:13.771150 (MainThread): Using snowflake connection "master".
2021-01-20 18:30:13.771325 (MainThread): On master: BEGIN
2021-01-20 18:30:13.771443 (MainThread): Opening a new connection, currently in state init
2021-01-20 18:30:15.043247 (MainThread): SQL status: SUCCESS 1 in 1.27 seconds
2021-01-20 18:30:15.043450 (MainThread): On master: COMMIT
2021-01-20 18:30:15.043628 (MainThread): Using snowflake connection "master".
2021-01-20 18:30:15.043728 (MainThread): On master: COMMIT
2021-01-20 18:30:15.698981 (MainThread): SQL status: SUCCESS 1 in 0.66 seconds
2021-01-20 18:30:15.699187 (MainThread): On master: Close
2021-01-20 18:30:15.986872 (MainThread): 19:30:15 | Concurrency: 1 threads (target='dev')
2021-01-20 18:30:15.987122 (MainThread): 19:30:15 | 
2021-01-20 18:30:15.989537 (Thread-1): Began running node model.dbt_learn.dates
2021-01-20 18:30:15.990993 (Thread-1): 19:30:15 | 1 of 1 START incremental model dbt.dates............................. [RUN]
2021-01-20 18:30:15.991358 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:15.991510 (Thread-1): Compiling model.dbt_learn.dates
2021-01-20 18:30:16.028005 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-20 18:30:16.028520 (Thread-1): finished collecting timing info
2021-01-20 18:30:16.080822 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:16.080991 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-20 18:30:16.081096 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:30:19.639727 (Thread-1): SQL status: SUCCESS 1 in 3.56 seconds
2021-01-20 18:30:19.650370 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:19.650531 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-20 18:30:19.893195 (Thread-1): SQL status: SUCCESS 28 in 0.24 seconds
2021-01-20 18:30:19.899417 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:19.899585 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:30:20.069150 (Thread-1): SQL status: SUCCESS 28 in 0.17 seconds
2021-01-20 18:30:20.074504 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:20.074660 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:30:20.940748 (Thread-1): SQL status: SUCCESS 28 in 0.87 seconds
2021-01-20 18:30:20.969228 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-20 18:30:20.972505 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:20.972660 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-20 18:30:21.355813 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2021-01-20 18:30:21.355999 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:21.356100 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-20 18:30:22.073589 (Thread-1): SQL status: SUCCESS 0 in 0.72 seconds
2021-01-20 18:30:22.074903 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:30:22.075105 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:30:22.075210 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:30:22.384718 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2021-01-20 18:30:22.401249 (Thread-1): finished collecting timing info
2021-01-20 18:30:22.401582 (Thread-1): On model.dbt_learn.dates: Close
2021-01-20 18:30:22.712352 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed739199-966b-443b-a000-f9678388df81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab03ac0>]}
2021-01-20 18:30:22.713890 (Thread-1): 19:30:22 | 1 of 1 OK created incremental model dbt.dates........................ [SUCCESS 0 in 6.72s]
2021-01-20 18:30:22.714045 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-20 18:30:22.715176 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:30:22.715394 (MainThread): Using snowflake connection "master".
2021-01-20 18:30:22.715497 (MainThread): On master: BEGIN
2021-01-20 18:30:22.715600 (MainThread): Opening a new connection, currently in state closed
2021-01-20 18:30:24.331091 (MainThread): SQL status: SUCCESS 1 in 1.62 seconds
2021-01-20 18:30:24.331373 (MainThread): On master: COMMIT
2021-01-20 18:30:24.331630 (MainThread): Using snowflake connection "master".
2021-01-20 18:30:24.331780 (MainThread): On master: COMMIT
2021-01-20 18:30:24.612666 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2021-01-20 18:30:24.612858 (MainThread): On master: Close
2021-01-20 18:30:25.139816 (MainThread): 19:30:25 | 
2021-01-20 18:30:25.140028 (MainThread): 19:30:25 | Finished running 1 incremental model in 16.34s.
2021-01-20 18:30:25.140160 (MainThread): Connection 'master' was properly closed.
2021-01-20 18:30:25.140268 (MainThread): Connection 'model.dbt_learn.dates' was properly closed.
2021-01-20 18:30:25.144525 (MainThread): 
2021-01-20 18:30:25.144681 (MainThread): Completed successfully
2021-01-20 18:30:25.144818 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-01-20 18:30:25.145022 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab08370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a531a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a531910>]}
2021-01-20 18:30:25.145252 (MainThread): Flushing usage events
2021-01-20 18:32:50.303482 (MainThread): Running with dbt=0.18.1
2021-01-20 18:32:50.375981 (MainThread): Loading KWallet
2021-01-20 18:32:50.376610 (MainThread): Loading SecretService
2021-01-20 18:32:50.377097 (MainThread): Loading Windows
2021-01-20 18:32:50.377723 (MainThread): Loading chainer
2021-01-20 18:32:50.378079 (MainThread): Loading macOS
2021-01-20 18:32:50.656516 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['new'], partial_parse=None, profile=None, profiles_dir='/Users/frandiego/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-01-20 18:32:50.657430 (MainThread): Tracking: tracking
2021-01-20 18:32:50.657658 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c9ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d9040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d9d90>]}
2021-01-20 18:32:50.693802 (MainThread): Got an acceptable cached parse result
2021-01-20 18:32:50.727939 (MainThread): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:50.948615 (MainThread): WARNING: Found documentation for resource "date" which was not found or is disabled
2021-01-20 18:32:51.040188 (MainThread): Found 7 models, 10 tests, 0 snapshots, 0 analyses, 143 macros, 0 operations, 0 seed files, 0 sources
2021-01-20 18:32:51.042261 (MainThread): 
2021-01-20 18:32:51.043105 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:32:51.045168 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_analytics".
2021-01-20 18:32:51.056859 (ThreadPoolExecutor-0_0): Using snowflake connection "list_analytics".
2021-01-20 18:32:51.056971 (ThreadPoolExecutor-0_0): On list_analytics: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
2021-01-20 18:32:51.057047 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-01-20 18:32:52.502083 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 3 in 1.44 seconds
2021-01-20 18:32:52.507825 (ThreadPoolExecutor-0_0): On list_analytics: Close
2021-01-20 18:32:53.016986 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_analytics_dbt".
2021-01-20 18:32:53.024946 (ThreadPoolExecutor-1_0): Using snowflake connection "list_analytics_dbt".
2021-01-20 18:32:53.025079 (ThreadPoolExecutor-1_0): On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
2021-01-20 18:32:53.025300 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-01-20 18:32:54.229203 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 7 in 1.20 seconds
2021-01-20 18:32:54.237357 (ThreadPoolExecutor-1_0): On list_analytics_dbt: Close
2021-01-20 18:32:54.623887 (MainThread): Using snowflake connection "master".
2021-01-20 18:32:54.632789 (MainThread): On master: BEGIN
2021-01-20 18:32:54.633869 (MainThread): Opening a new connection, currently in state init
2021-01-20 18:32:55.653586 (MainThread): SQL status: SUCCESS 1 in 1.02 seconds
2021-01-20 18:32:55.653867 (MainThread): On master: COMMIT
2021-01-20 18:32:55.654131 (MainThread): Using snowflake connection "master".
2021-01-20 18:32:55.654282 (MainThread): On master: COMMIT
2021-01-20 18:32:55.920529 (MainThread): SQL status: SUCCESS 1 in 0.27 seconds
2021-01-20 18:32:55.920815 (MainThread): On master: Close
2021-01-20 18:32:56.423759 (MainThread): 19:32:56 | Concurrency: 1 threads (target='dev')
2021-01-20 18:32:56.423999 (MainThread): 19:32:56 | 
2021-01-20 18:32:56.425965 (Thread-1): Began running node model.dbt_learn.dates
2021-01-20 18:32:56.427409 (Thread-1): 19:32:56 | 1 of 1 START incremental model dbt.dates............................. [RUN]
2021-01-20 18:32:56.427725 (Thread-1): Acquiring new snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:56.427862 (Thread-1): Compiling model.dbt_learn.dates
2021-01-20 18:32:56.451945 (Thread-1): Writing injected SQL for node "model.dbt_learn.dates"
2021-01-20 18:32:56.452535 (Thread-1): finished collecting timing info
2021-01-20 18:32:56.503148 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:56.503328 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
WHERE d_date <= current_date


  and d_date > (select max(d_date) from analytics.dbt.dates)

      );
2021-01-20 18:32:56.503429 (Thread-1): Opening a new connection, currently in state closed
2021-01-20 18:32:58.795828 (Thread-1): SQL status: SUCCESS 1 in 2.29 seconds
2021-01-20 18:32:58.807776 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:58.807943 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
2021-01-20 18:32:59.013015 (Thread-1): SQL status: SUCCESS 28 in 0.20 seconds
2021-01-20 18:32:59.019089 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:59.019215 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:32:59.281736 (Thread-1): SQL status: SUCCESS 28 in 0.26 seconds
2021-01-20 18:32:59.287030 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:59.287204 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

    describe table analytics.dbt.dates
2021-01-20 18:32:59.481846 (Thread-1): SQL status: SUCCESS 28 in 0.19 seconds
2021-01-20 18:32:59.508278 (Thread-1): Writing runtime SQL for node "model.dbt_learn.dates"
2021-01-20 18:32:59.511098 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:59.511201 (Thread-1): On model.dbt_learn.dates: BEGIN
2021-01-20 18:32:59.694820 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2021-01-20 18:32:59.695065 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:32:59.695218 (Thread-1): On model.dbt_learn.dates: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "dbt_learn", "target_name": "dev", "node_id": "model.dbt_learn.dates"} */

        
        
    

    

    merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
2021-01-20 18:33:00.329121 (Thread-1): SQL status: SUCCESS 0 in 0.63 seconds
2021-01-20 18:33:00.330292 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:33:00.330477 (Thread-1): Using snowflake connection "model.dbt_learn.dates".
2021-01-20 18:33:00.330579 (Thread-1): On model.dbt_learn.dates: COMMIT
2021-01-20 18:33:00.582970 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2021-01-20 18:33:00.610295 (Thread-1): finished collecting timing info
2021-01-20 18:33:00.610688 (Thread-1): On model.dbt_learn.dates: Close
2021-01-20 18:33:00.939292 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27f76588-e65e-4a5c-b0d2-9ca2faf9421a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137bb100>]}
2021-01-20 18:33:00.940962 (Thread-1): 19:33:00 | 1 of 1 OK created incremental model dbt.dates........................ [SUCCESS 0 in 4.51s]
2021-01-20 18:33:00.941179 (Thread-1): Finished running node model.dbt_learn.dates
2021-01-20 18:33:00.943408 (MainThread): Acquiring new snowflake connection "master".
2021-01-20 18:33:00.943834 (MainThread): Using snowflake connection "master".
2021-01-20 18:33:00.943974 (MainThread): On master: BEGIN
2021-01-20 18:33:00.944136 (MainThread): Opening a new connection, currently in state closed
2021-01-20 18:33:02.140134 (MainThread): SQL status: SUCCESS 1 in 1.20 seconds
2021-01-20 18:33:02.140396 (MainThread): On master: COMMIT
2021-01-20 18:33:02.140596 (MainThread): Using snowflake connection "master".
2021-01-20 18:33:02.140716 (MainThread): On master: COMMIT
2021-01-20 18:33:02.426762 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2021-01-20 18:33:02.427055 (MainThread): On master: Close
2021-01-20 18:33:02.715193 (MainThread): 19:33:02 | 
2021-01-20 18:33:02.715382 (MainThread): 19:33:02 | Finished running 1 incremental model in 11.67s.
2021-01-20 18:33:02.715531 (MainThread): Connection 'master' was properly closed.
2021-01-20 18:33:02.715625 (MainThread): Connection 'model.dbt_learn.dates' was properly closed.
2021-01-20 18:33:02.720235 (MainThread): 
2021-01-20 18:33:02.720427 (MainThread): Completed successfully
2021-01-20 18:33:02.720562 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-01-20 18:33:02.720754 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11362baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11362bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11362b160>]}
2021-01-20 18:33:02.720973 (MainThread): Flushing usage events
